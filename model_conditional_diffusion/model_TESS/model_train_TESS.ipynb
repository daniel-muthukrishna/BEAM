{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "29a3f9eb-ba1b-4631-a844-95fd8a88b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This script does conditional image generation on MNIST, using a diffusion model\n",
    "\n",
    "This code is modified from,\n",
    "https://github.com/cloneofsimo/minDiffusion\n",
    "\n",
    "Diffusion model is based on DDPM,\n",
    "https://arxiv.org/abs/2006.11239\n",
    "\n",
    "The conditioning idea is taken from 'Classifier-Free Diffusion Guidance',\n",
    "https://arxiv.org/abs/2207.12598\n",
    "\n",
    "This technique also features in ImageGen 'Photorealistic Text-to-Image Diffusion Modelswith Deep Language Understanding',\n",
    "https://arxiv.org/abs/2205.11487\n",
    "\n",
    "'''\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a9f0963-b378-4348-9001-8069ea204a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConvBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels: int, out_channels: int, is_res: bool = False\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        '''\n",
    "        standard ResNet style convolutional block\n",
    "        '''\n",
    "        self.same_channels = in_channels==out_channels\n",
    "        self.is_res = is_res\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.is_res:\n",
    "            x1 = self.conv1(x)\n",
    "            x2 = self.conv2(x1)\n",
    "            # this adds on correct residual in case channels have increased\n",
    "            if self.same_channels:\n",
    "                out = x + x2\n",
    "            else:\n",
    "                out = x1 + x2 \n",
    "            return out / 1.414\n",
    "        else:\n",
    "            x1 = self.conv1(x)\n",
    "            x2 = self.conv2(x1)\n",
    "            return x2\n",
    "\n",
    "\n",
    "class UnetDown(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UnetDown, self).__init__()\n",
    "        '''\n",
    "        process and downscale the image feature maps\n",
    "        '''\n",
    "        layers = [ResidualConvBlock(in_channels, out_channels), nn.MaxPool2d(2)]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class UnetUp(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UnetUp, self).__init__()\n",
    "        '''\n",
    "        process and upscale the image feature maps\n",
    "        '''\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, 2, 2),\n",
    "            ResidualConvBlock(out_channels, out_channels),\n",
    "            ResidualConvBlock(out_channels, out_channels),\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = torch.cat((x, skip), 1)\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EmbedFC(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim):\n",
    "        super(EmbedFC, self).__init__()\n",
    "        '''\n",
    "        generic one layer FC NN for embedding things  \n",
    "        '''\n",
    "        self.input_dim = input_dim\n",
    "        layers = [\n",
    "            nn.Linear(input_dim, emb_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(emb_dim, emb_dim),\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_dim)\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class ContextUnet(nn.Module):\n",
    "    # def __init__(self, in_channels, n_feat = 256, n_classes=10):\n",
    "    def __init__(self, in_channels, n_feat = 256):\n",
    "        super(ContextUnet, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.n_feat = n_feat\n",
    "\n",
    "        self.init_conv = ResidualConvBlock(in_channels, n_feat, is_res=True)\n",
    "\n",
    "        self.down1 = UnetDown(n_feat, n_feat)\n",
    "        self.down2 = UnetDown(n_feat, 2 * n_feat)\n",
    "        \n",
    "        self.to_vec = nn.Sequential(nn.AvgPool2d(4), nn.GELU())\n",
    "\n",
    "        self.timeembed1 = EmbedFC(1, 2*n_feat)\n",
    "        self.timeembed2 = EmbedFC(1, 1*n_feat)\n",
    "        self.timeembed1 = EmbedFC(1, 2*n_feat)\n",
    "        self.timeembed2 = EmbedFC(1, 1*n_feat)\n",
    "        self.contextembed1 = EmbedFC(12, 2*n_feat)\n",
    "        self.contextembed2 = EmbedFC(12, 1*n_feat)\n",
    "\n",
    "        self.up0 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2 * n_feat, 2 * n_feat, 4, 4), # otherwise just have 2*n_feat\n",
    "            nn.GroupNorm(8, 2 * n_feat),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.up1 = UnetUp(4 * n_feat, n_feat)\n",
    "        self.up2 = UnetUp(2 * n_feat, n_feat)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(2 * n_feat, n_feat, 3, 1, 1),\n",
    "            nn.GroupNorm(8, n_feat),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_feat, self.in_channels, 3, 1, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, c, t, context_mask):\n",
    "\n",
    "        # x is (noisy) image, c is context label, t is timestep, \n",
    "        # context_mask says which samples to block the context on\n",
    "\n",
    "        x = self.init_conv(x)\n",
    "        down1 = self.down1(x)\n",
    "        down2 = self.down2(down1)\n",
    "        hiddenvec = self.to_vec(down2)\n",
    "\n",
    "        c = c.reshape((c.shape[0], 12))\n",
    "        \n",
    "        # mask out context if context_mask == 1\n",
    "        context_mask = context_mask.reshape((x.shape[0], 12))\n",
    "        context_mask = (-1*(1-context_mask)) # need to flip 0 <-> 1\n",
    "        c = c * context_mask\n",
    "\n",
    "        # embed context, time step\n",
    "        cemb1 = self.contextembed1(c).view(-1, self.n_feat * 2, 1, 1)\n",
    "        temb1 = self.timeembed1(t).view(-1, self.n_feat * 2, 1, 1)\n",
    "        cemb2 = self.contextembed2(c).view(-1, self.n_feat, 1, 1)\n",
    "        temb2 = self.timeembed2(t).view(-1, self.n_feat, 1, 1)\n",
    "\n",
    "        # could concatenate the context embedding here instead of adaGN\n",
    "        # hiddenvec = torch.cat((hiddenvec, temb1, cemb1), 1)\n",
    "\n",
    "        up1 = self.up0(hiddenvec)\n",
    "        # up2 = self.up1(up1, down2) # if want to avoid add and multiply embeddings\n",
    "        up2 = self.up1(cemb1*up1+ temb1, down2)  # add and multiply embeddings\n",
    "        up3 = self.up2(cemb2*up2+ temb2, down1)\n",
    "        out = self.out(torch.cat((up3, x), 1))\n",
    "        return out\n",
    "\n",
    "\n",
    "def ddpm_schedules(beta1, beta2, T):\n",
    "    \"\"\"\n",
    "    Returns pre-computed schedules for DDPM sampling, training process.\n",
    "    \"\"\"\n",
    "    assert beta1 < beta2 < 1.0, \"beta1 and beta2 must be in (0, 1)\"\n",
    "\n",
    "    beta_t = (beta2 - beta1) * torch.arange(0, T + 1, dtype=torch.float32) / T + beta1\n",
    "    sqrt_beta_t = torch.sqrt(beta_t)\n",
    "    alpha_t = 1 - beta_t\n",
    "    log_alpha_t = torch.log(alpha_t)\n",
    "    alphabar_t = torch.cumsum(log_alpha_t, dim=0).exp()\n",
    "\n",
    "    sqrtab = torch.sqrt(alphabar_t)\n",
    "    oneover_sqrta = 1 / torch.sqrt(alpha_t)\n",
    "\n",
    "    sqrtmab = torch.sqrt(1 - alphabar_t)\n",
    "    mab_over_sqrtmab_inv = (1 - alpha_t) / sqrtmab\n",
    "\n",
    "    return {\n",
    "        \"alpha_t\": alpha_t,  # \\alpha_t\n",
    "        \"oneover_sqrta\": oneover_sqrta,  # 1/\\sqrt{\\alpha_t}\n",
    "        \"sqrt_beta_t\": sqrt_beta_t,  # \\sqrt{\\beta_t}\n",
    "        \"alphabar_t\": alphabar_t,  # \\bar{\\alpha_t}\n",
    "        \"sqrtab\": sqrtab,  # \\sqrt{\\bar{\\alpha_t}}\n",
    "        \"sqrtmab\": sqrtmab,  # \\sqrt{1-\\bar{\\alpha_t}}\n",
    "        \"mab_over_sqrtmab\": mab_over_sqrtmab_inv,  # (1-\\alpha_t)/\\sqrt{1-\\bar{\\alpha_t}}\n",
    "    }\n",
    "\n",
    "\n",
    "class DDPM(nn.Module):\n",
    "    def __init__(self, nn_model, betas, n_T, device, drop_prob=0.1):\n",
    "        super(DDPM, self).__init__()\n",
    "        self.nn_model = nn_model.to(device)\n",
    "\n",
    "        # register_buffer allows accessing dictionary produced by ddpm_schedules\n",
    "        # e.g. can access self.sqrtab later\n",
    "        for k, v in ddpm_schedules(betas[0], betas[1], n_T).items():\n",
    "            self.register_buffer(k, v)\n",
    "\n",
    "        self.n_T = n_T\n",
    "        self.device = device\n",
    "        self.drop_prob = drop_prob\n",
    "        self.loss_mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        \"\"\"\n",
    "        this method is used in training, so samples t and noise randomly\n",
    "        \"\"\"\n",
    "        _ts = torch.randint(1, self.n_T+1, (x.shape[0],)).to(self.device)  # t ~ Uniform(0, n_T)\n",
    "        noise = torch.randn_like(x)  # eps ~ N(0, 1)\n",
    "\n",
    "        x_t = (\n",
    "            self.sqrtab[_ts, None].reshape((x.shape[0], 1, 1, 1)) * x\n",
    "            + self.sqrtmab[_ts, None].reshape((x.shape[0], 1, 1, 1)) * noise\n",
    "        )  # This is the x_t, which is sqrt(alphabar) x_0 + sqrt(1-alphabar) * eps\n",
    "        # We should predict the \"error term\" from this x_t. Loss is what we return.\n",
    "\n",
    "        # dropout context with some probability\n",
    "        context_mask = torch.bernoulli(torch.zeros_like(c)+self.drop_prob).to(self.device)\n",
    "        \n",
    "        # return MSE between added noise, and our predicted noise\n",
    "        return self.loss_mse(noise, self.nn_model(x_t, c, _ts / self.n_T, context_mask))\n",
    "\n",
    "    def sample(self, n_sample, size, device, guide_w = 0.0):\n",
    "        '''\n",
    "        the c_i, context, is a random 1x12 vector. It is not real data. This function will\n",
    "        not give good preditions. Look to sample_c for better results\n",
    "        '''\n",
    "        \n",
    "        # we follow the guidance sampling scheme described in 'Classifier-Free Diffusion Guidance'\n",
    "        # to make the fwd passes efficient, we concat two versions of the dataset,\n",
    "        # one with context_mask=0 and the other context_mask=1\n",
    "        # we then mix the outputs with the guidance scale, w\n",
    "        # where w>0 means more guidance\n",
    "\n",
    "        x_i = torch.randn(n_sample, *size).to(device)  # x_T ~ N(0, 1), sample initial noise\n",
    "        c_i = torch.rand((n_sample, 1, 12)).to(device) # context for us just cycles throught the mnist labels\n",
    "\n",
    "        # don't drop context at test time\n",
    "        context_mask = torch.zeros_like(c_i).to(device)\n",
    "\n",
    "        # double the batch\n",
    "        c_i = c_i.repeat(2, 1, 1)\n",
    "        context_mask = context_mask.repeat(2, 1, 1)\n",
    "        context_mask[n_sample:] = 1. # makes second half of batch context free\n",
    "\n",
    "        x_i_store = [] # keep track of generated steps in case want to plot something \n",
    "        print()\n",
    "        for i in range(self.n_T, 0, -1):\n",
    "            print(f'sampling timestep {i}',end='\\r')\n",
    "            t_is = torch.tensor([i / self.n_T]).to(device)\n",
    "            t_is = t_is.repeat(n_sample,1,1,1)\n",
    "\n",
    "            # double batch\n",
    "            x_i = x_i.repeat(2,1,1,1)\n",
    "            t_is = t_is.repeat(2,1,1,1)\n",
    "\n",
    "            z = torch.randn(n_sample, *size).to(device) if i > 1 else 0\n",
    "\n",
    "            # split predictions and compute weighting\n",
    "            eps = self.nn_model(x_i, c_i, t_is, context_mask)\n",
    "            eps1 = eps[:n_sample]\n",
    "            eps2 = eps[n_sample:]\n",
    "            \n",
    "            eps = (1+guide_w)*eps1 - guide_w*eps2\n",
    "            x_i = x_i[:n_sample]\n",
    "            x_i = (\n",
    "                self.oneover_sqrta[i] * (x_i - eps * self.mab_over_sqrtmab[i])\n",
    "                + self.sqrt_beta_t[i] * z\n",
    "            )\n",
    "            if i%20==0 or i==self.n_T or i<8:\n",
    "                x_i_store.append(x_i.detach().cpu().numpy())\n",
    "        \n",
    "        x_i_store = np.array(x_i_store)\n",
    "        return x_i, x_i_store\n",
    "\n",
    "\n",
    "    def sample_c(self, c_i, n_sample, size, device):\n",
    "        '''\n",
    "        this is different than the function sample above\n",
    "        this always uses classifer guidance for diffusion, so no need to concat 2 versions of \n",
    "        dataset or have a guidance scale w. Also context_mask=0 always since no mask used\n",
    "\n",
    "        taking n_sample samples of EACH datapoint. There are n_datapoint datapoints\n",
    "        '''\n",
    "        n_datapoint = c_i.shape[0]\n",
    "\n",
    "        x_i = torch.randn(n_datapoint*n_sample, *size).to(device)  # x_T ~ N(0, 1), sample initial noise\n",
    "        \n",
    "        # repeat c_i n_sample times to make up a row\n",
    "        c_i = torch.cat([c_i[idx:idx+1].repeat(n_sample, 1, 1) for idx in range(n_datapoint)]).to(device)\n",
    "        \n",
    "        # don't drop context at test time. To include context make context_mask all 0's\n",
    "        context_mask = torch.zeros_like(c_i).to(device)\n",
    "\n",
    "        x_i_store = [] # keep track of generated steps in case want to plot something \n",
    "        print()\n",
    "        for i in range(self.n_T, 0, -1):\n",
    "            print(f'sampling timestep {i}',end='\\r')\n",
    "            t_is = torch.tensor([i / self.n_T]).to(device)\n",
    "            t_is = t_is.repeat(n_datapoint*n_sample,1,1,1)\n",
    "\n",
    "            z = torch.randn(n_datapoint*n_sample, *size).to(device) if i > 1 else 0\n",
    "\n",
    "            # compute weighting\n",
    "            eps = self.nn_model(x_i, c_i, t_is, context_mask)\n",
    "            \n",
    "            x_i = (\n",
    "                self.oneover_sqrta[i] * (x_i - eps * self.mab_over_sqrtmab[i])\n",
    "                + self.sqrt_beta_t[i] * z\n",
    "            )\n",
    "            if i%20==0 or i==self.n_T or i<8:\n",
    "                x_i_store.append(x_i.detach().cpu().numpy())\n",
    "        \n",
    "        x_i_store = np.array(x_i_store)\n",
    "        return x_i, x_i_store\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6048c5b5-c52a-4577-9c5a-5120c880bf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25960\n",
      "torch.Size([1, 12])\n",
      "torch.Size([1, 16, 16])\n",
      "00006869\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# @title TESS Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class TESSDataset(Dataset):\n",
    "    def __init__(self, angle_filename):\n",
    "        \n",
    "        # get data\n",
    "        angle_folder = \"/pdo/users/jlupoiii/TESS/data/angles/\"\n",
    "        ccd_folder = \"/pdo/users/jlupoiii/TESS/data/ccds_background_subtracted/\"\n",
    "\n",
    "        # data matrices\n",
    "        X = []\n",
    "        Y = []\n",
    "        ffi_nums = []\n",
    "\n",
    "        self.angles_dic = pickle.load(open(angle_folder+angle_filename, \"rb\"))\n",
    "\n",
    "        # self.ffi_num_to_orbit_dic = pickle.load(open(angle_folder+'ffi_num_to_orbit_dic.pkl', \"rb\"))\n",
    "\n",
    "        for filename in os.listdir(ccd_folder):\n",
    "            if len(filename) < 40 or filename[27] != '3': continue\n",
    "\n",
    "            image_arr = pickle.load(open(ccd_folder+filename, \"rb\"))\n",
    "            ffi_num = filename[18:18+8]\n",
    "            try:\n",
    "                angles = self.angles_dic[ffi_num]\n",
    "                # print('Got ffi number', ffi_num)\n",
    "            except:\n",
    "                # print('Could not find ffi with number:', ffi_num)\n",
    "                continue\n",
    "                \n",
    "            X.append(np.array([angles['1/ED'], angles['1/MD'], angles['1/ED^2'], angles['1/MD^2'], angles['Eel'], angles['Eaz'], angles['Mel'], angles['Maz'], angles['E3el'], angles['E3az'], angles['M3el'], angles['M3az']]))\n",
    "            Y.append(image_arr.flatten())\n",
    "            ffi_nums.append(ffi_num)\n",
    "        \n",
    "        self.data = [Image.fromarray(x) for x in X]\n",
    "        self.labels = [Image.fromarray(y) for y in Y]\n",
    "        self.ffi_nums = ffi_nums\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        angles_image = self.data[idx]\n",
    "        ffi_image = self.labels[idx]\n",
    "        ffi_num = self.ffi_nums[idx]\n",
    "        orbit = self.angles_dic[ffi_num][\"orbit\"]\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            lambda s: s.reshape(1, 12)\n",
    "        ])\n",
    "        target_transform = transforms.Compose([\n",
    "            lambda s: np.array(s),\n",
    "            lambda s: s.reshape((16,16)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "        angles_image = transform(angles_image)\n",
    "        ffi_image = target_transform(ffi_image)\n",
    "\n",
    "        # X: 1x12 vector of angles and distances\n",
    "        # Y: 16x16 image\n",
    "        return {\"x\":angles_image, \"y\":ffi_image, \"ffi_num\": ffi_num, \"orbit\": orbit}\n",
    "\n",
    "\n",
    "# MAKE DATASET\n",
    "\n",
    "# we are calculating Y GIVEN X\n",
    "tess_dataset = TESSDataset('angles_O11-54_data_dic.pkl')\n",
    "print(len(tess_dataset))\n",
    "print(tess_dataset[1]['x'].shape)\n",
    "print(tess_dataset[1]['y'].shape)\n",
    "print(tess_dataset[1]['ffi_num'])\n",
    "print(tess_dataset[1]['orbit'])\n",
    "\n",
    "# # # plt.plot(tess_dataset[1]['x'][0])\n",
    "# # print('x:', tess_dataset[1]['x'][0])\n",
    "\n",
    "# # plt.imshow(tess_dataset[1]['y'][0], vmin=0, vmax=1)\n",
    "# # plt.colorbar()\n",
    "# # plt.show()\n",
    "# # plt.close()\n",
    "\n",
    "# # # displays all datapoints\n",
    "# # idx = 0\n",
    "# # for i in range(len(tess_dataset)):\n",
    "# #     print('------')\n",
    "# #     print(idx)\n",
    "# #     idx += 1\n",
    "# #     print('x:', tess_dataset[i]['x'][0])\n",
    "# #     plt.imshow(tess_dataset[i]['y'][0], vmin=0, vmax=1)\n",
    "# #     plt.colorbar()\n",
    "# #     plt.show()\n",
    "# #     plt.close()\n",
    "\n",
    "# print('x:', tess_dataset[9]['x'][0])\n",
    "# plt.imshow(tess_dataset[9]['y'][0], vmin=0, vmax=1)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f333afb2-c52a-4d54-8637-a839401bb875",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0117: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 52.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saved image at model_TESS_O11-54_new/image_ep0.pdf\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0089: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 49.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0059: 100%|█████████████████████████| 1622/1622 [00:34<00:00, 47.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0058: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 49.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0049: 100%|█████████████████████████| 1622/1622 [00:33<00:00, 48.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0031: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 52.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0032: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 53.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0038: 100%|█████████████████████████| 1622/1622 [00:33<00:00, 49.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0030: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0026: 100%|█████████████████████████| 1622/1622 [00:26<00:00, 61.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0031: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0038: 100%|█████████████████████████| 1622/1622 [00:28<00:00, 56.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0024: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0034: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 50.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0023: 100%|█████████████████████████| 1622/1622 [00:29<00:00, 55.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0023: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0024: 100%|█████████████████████████| 1622/1622 [00:33<00:00, 48.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0024: 100%|█████████████████████████| 1622/1622 [00:29<00:00, 54.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0021: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 53.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0021: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 50.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0028: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 52.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0014: 100%|█████████████████████████| 1622/1622 [00:28<00:00, 56.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0020: 100%|█████████████████████████| 1622/1622 [00:28<00:00, 56.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0016: 100%|█████████████████████████| 1622/1622 [00:28<00:00, 57.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0016: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 50.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0023: 100%|█████████████████████████| 1622/1622 [00:29<00:00, 54.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saved image at model_TESS_O11-54_new/image_ep25.pdf\n",
      "epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0019: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0016: 100%|█████████████████████████| 1622/1622 [00:29<00:00, 54.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0019: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 53.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0026: 100%|█████████████████████████| 1622/1622 [00:26<00:00, 60.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0012: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 50.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0019: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 49.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0014: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 49.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0026: 100%|█████████████████████████| 1622/1622 [00:33<00:00, 48.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0014: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0017: 100%|█████████████████████████| 1622/1622 [00:29<00:00, 55.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0012: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 50.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0015: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 53.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0016: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 49.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0014: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 50.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0013: 100%|█████████████████████████| 1622/1622 [00:28<00:00, 56.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0022: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 50.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0019: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0015: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 54.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0012: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 54.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0023: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0013: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 52.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0013: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 52.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0015: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 53.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0020: 100%|█████████████████████████| 1622/1622 [00:29<00:00, 54.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0011: 100%|█████████████████████████| 1622/1622 [00:29<00:00, 54.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saved image at model_TESS_O11-54_new/image_ep50.pdf\n",
      "epoch 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0012: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 52.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0012: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 50.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0015: 100%|█████████████████████████| 1622/1622 [00:28<00:00, 57.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0012: 100%|█████████████████████████| 1622/1622 [00:34<00:00, 46.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0010: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 52.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0011: 100%|█████████████████████████| 1622/1622 [00:27<00:00, 58.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0014: 100%|█████████████████████████| 1622/1622 [00:27<00:00, 59.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0015: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0010: 100%|█████████████████████████| 1622/1622 [00:33<00:00, 48.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0011: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 52.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0010: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 49.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0011: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 50.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0019: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 50.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0010: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 53.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0010: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 52.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0013: 100%|█████████████████████████| 1622/1622 [00:33<00:00, 48.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0010: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 50.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0010: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0008: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 50.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0009: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 50.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0013: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0009: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 49.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0010: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0013: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0009: 100%|█████████████████████████| 1622/1622 [00:29<00:00, 54.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saved image at model_TESS_O11-54_new/image_ep75.pdf\n",
      "epoch 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0008: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0015: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 49.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0009: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 49.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0009: 100%|█████████████████████████| 1622/1622 [00:33<00:00, 48.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0008: 100%|█████████████████████████| 1622/1622 [00:33<00:00, 47.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0012: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0008: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 49.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0008: 100%|█████████████████████████| 1622/1622 [00:33<00:00, 47.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0009: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 52.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0007: 100%|█████████████████████████| 1622/1622 [00:33<00:00, 49.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0009: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 53.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0007: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 52.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0009: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 52.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0006: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 50.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0007: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0024: 100%|█████████████████████████| 1622/1622 [00:33<00:00, 48.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0013: 100%|█████████████████████████| 1622/1622 [00:33<00:00, 48.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0006: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 53.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0005: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 49.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0007: 100%|█████████████████████████| 1622/1622 [00:28<00:00, 56.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0005: 100%|█████████████████████████| 1622/1622 [00:34<00:00, 47.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0011: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 50.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0007: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0010: 100%|█████████████████████████| 1622/1622 [00:33<00:00, 48.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0008: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 53.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saved image at model_TESS_O11-54_new/image_ep100.pdf\n",
      "epoch 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0009: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 52.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0009: 100%|█████████████████████████| 1622/1622 [00:28<00:00, 57.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0010: 100%|█████████████████████████| 1622/1622 [00:29<00:00, 54.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0009: 100%|█████████████████████████| 1622/1622 [00:29<00:00, 54.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0008: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 52.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0008: 100%|█████████████████████████| 1622/1622 [00:33<00:00, 48.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0009: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 53.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0012: 100%|█████████████████████████| 1622/1622 [00:34<00:00, 46.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0008: 100%|█████████████████████████| 1622/1622 [00:33<00:00, 48.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0010: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 53.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0008: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 50.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0009: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0007: 100%|█████████████████████████| 1622/1622 [00:32<00:00, 50.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0008: 100%|█████████████████████████| 1622/1622 [00:33<00:00, 48.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0008: 100%|█████████████████████████| 1622/1622 [00:27<00:00, 59.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0008: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 52.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0006: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 53.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0006: 100%|█████████████████████████| 1622/1622 [00:26<00:00, 60.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0006: 100%|█████████████████████████| 1622/1622 [00:29<00:00, 54.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0009: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0006: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0010: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0008: 100%|█████████████████████████| 1622/1622 [00:24<00:00, 67.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0006: 100%|█████████████████████████| 1622/1622 [00:28<00:00, 56.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0006: 100%|█████████████████████████| 1622/1622 [00:29<00:00, 54.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0004: 100%|█████████████████████████| 1622/1622 [00:25<00:00, 62.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0005:  45%|███████████▊              | 738/1622 [00:13<00:17, 51.59it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.0006: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 52.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0005: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0004: 100%|█████████████████████████| 1622/1622 [00:26<00:00, 61.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0004: 100%|█████████████████████████| 1622/1622 [00:27<00:00, 58.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0004: 100%|█████████████████████████| 1622/1622 [00:26<00:00, 60.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0004:  39%|██████████▏               | 633/1622 [00:09<00:18, 54.08it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.0005: 100%|█████████████████████████| 1622/1622 [00:24<00:00, 65.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0004: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0005: 100%|█████████████████████████| 1622/1622 [00:28<00:00, 56.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0004:  69%|█████████████████▏       | 1119/1622 [00:21<00:10, 47.58it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.0004: 100%|█████████████████████████| 1622/1622 [00:27<00:00, 59.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0004: 100%|█████████████████████████| 1622/1622 [00:31<00:00, 51.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0003: 100%|█████████████████████████| 1622/1622 [00:27<00:00, 59.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0004: 100%|█████████████████████████| 1622/1622 [00:26<00:00, 60.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saved image at model_TESS_O11-54_new/image_ep275.pdf\n",
      "epoch 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0003: 100%|█████████████████████████| 1622/1622 [00:29<00:00, 55.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0004:   5%|█▎                         | 81/1622 [00:02<00:30, 51.04it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "loss: 0.0004: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 53.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0004: 100%|█████████████████████████| 1622/1622 [00:30<00:00, 53.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0004: 100%|█████████████████████████| 1622/1622 [00:29<00:00, 54.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.0004:  59%|███████████████▎          | 953/1622 [00:19<00:13, 51.01it/s]"
     ]
    }
   ],
   "source": [
    "def train_TESS(save_dir):\n",
    "    # hardcoding these here\n",
    "    n_epoch = 300\n",
    "    batch_size = 16\n",
    "    n_T = 600 # 400\n",
    "    device = \"cuda:0\"\n",
    "    n_feat = 256 # 128 ok, 256 better (but slower)\n",
    "    lrate = 1e-4\n",
    "    save_model = True\n",
    "    # save_dir = './model_O13/'\n",
    "    dataset_filename = \"angles_O11-54_data_dic.pkl\"\n",
    "    ws_test = [0.0, 0.5, 2.0] # strength of generative guidance. Not used in sample_c()\n",
    "\n",
    "    ddpm = DDPM(nn_model=ContextUnet(in_channels=1, n_feat=n_feat), betas=(1e-4, 0.02), n_T=n_T, device=device, drop_prob=0.1)\n",
    "    ddpm.to(device)\n",
    "\n",
    "    # optionally load a model\n",
    "    # ddpm.load_state_dict(torch.load(\"./data/diffusion_outputs/ddpm_unet01_mnist_9.pth\"))\n",
    "\n",
    "    dataset = TESSDataset(dataset_filename)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=5, drop_last=True)\n",
    "    optim = torch.optim.Adam(ddpm.parameters(), lr=lrate)\n",
    "\n",
    "    loss_history = []\n",
    "    \n",
    "    for ep in range(n_epoch):\n",
    "        print(f'epoch {ep}')\n",
    "        ddpm.train()\n",
    "\n",
    "        # linear lrate decay\n",
    "        optim.param_groups[0]['lr'] = lrate*(1-ep/n_epoch)\n",
    "\n",
    "        pbar = tqdm(dataloader)\n",
    "        loss_ema = None\n",
    "\n",
    "        for data_dic in pbar:\n",
    "            optim.zero_grad()\n",
    "            x = data_dic['y'].to(device)\n",
    "            c = data_dic['x'].to(device)\n",
    "            ffi_nums = data_dic['ffi_num']\n",
    "            orbits = data_dic['orbit']\n",
    "            \n",
    "            # FOR THE GIFS MAKE SURE THEY ARE CAPPED AT 0 TO 1. THATS WHY I CANT SEE THEM\n",
    "\n",
    "            loss = ddpm(x, c)\n",
    "            loss.backward()\n",
    "            if loss_ema is None:\n",
    "                loss_ema = loss.item()\n",
    "            else:\n",
    "                loss_ema = 0.95 * loss_ema + 0.05 * loss.item()\n",
    "            pbar.set_description(f\"loss: {loss_ema:.4f}\")\n",
    "            optim.step()\n",
    "\n",
    "        loss_history.append(loss_ema)\n",
    "        \n",
    "        # for eval, save an image of rows of datapoint predictions. The first column are the real\n",
    "        # images and the rest are predictions\n",
    "        ddpm.eval()\n",
    "        with torch.no_grad():\n",
    "            # want each row to be for one datapoint, and for there to be n_sample columns\n",
    "            # want the first column to be the real image\n",
    "            \n",
    "            n_datapoint = 10\n",
    "            n_sample = 5\n",
    "            if ep%25==0 or ep == int(n_epoch-1):\n",
    "                # choose the first n_datapoint datapoints to do predictions on\n",
    "                # The dataloader has shuffle=True so these datapoints are always random\n",
    "                x_real = x[:n_datapoint]\n",
    "                c_real = c[:n_datapoint]\n",
    "                ffi_nums_real = ffi_nums[:n_datapoint]\n",
    "                orbits_real = orbits[:n_datapoint]\n",
    "                \n",
    "                x_gen, x_gen_store = ddpm.sample_c(c_real, n_sample, (1, 16, 16), device)\n",
    "                x_all = torch.Tensor().to(device)\n",
    "                for i in range(n_datapoint):\n",
    "                    x_all = torch.cat([x_all, x_real[i:i+1], x_gen[i*n_sample:(i+1)*n_sample]])\n",
    "\n",
    "                fig, axes = plt.subplots(n_datapoint, n_sample+1, figsize=(15, 30))\n",
    "                plt.subplots_adjust(top=1.7)\n",
    "                for idx in range(x_all.shape[0]):\n",
    "                    image = x_all[idx, 0, :, :].cpu().detach().numpy()\n",
    "                    axes[idx//(n_sample+1), idx%(n_sample+1)].imshow(image, cmap='gray', vmin=0, vmax=1)\n",
    "                    axes[idx//(n_sample+1), idx%(n_sample+1)].axis('off')\n",
    "\n",
    "                # set labels for sampled columns\n",
    "                for i in range(n_sample):\n",
    "                    axes[0, i+1].set_title(f\"Sample {i+1} \\n \", fontsize=12)\n",
    "\n",
    "                # set labels for each datapoint\n",
    "                for j in range(n_datapoint):\n",
    "                    data_title = f\"O{orbits_real[j]} , ffi {ffi_nums_real[j]}\"\n",
    "                    if j==0: data_title = f\"Original\\n{data_title}\"\n",
    "                    axes[j, 0].set_title(data_title, fontsize=12)\n",
    "\n",
    "                # Sets title for whole figure\n",
    "                fig.suptitle(f\"Predictions for epoch {ep}\", fontsize = 25)\n",
    "\n",
    "                # save images\n",
    "                plt.tight_layout()\n",
    "                fig.savefig(save_dir + f\"image_ep{ep}.pdf\")\n",
    "                print('saved image at ' + save_dir + f\"image_ep{ep}.pdf\")\n",
    "                plt.close()\n",
    "                \n",
    "\n",
    "                # save loss graph\n",
    "                plt.plot(loss_history)\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.ylabel('MSE Loss')\n",
    "                plt.title('MSE Loss over Epochs')\n",
    "                plt.savefig(os.path.join(save_dir, 'loss_graph.png'))\n",
    "                plt.close()\n",
    "\n",
    "                # # create gif of images evolving over time, based on x_gen_store\n",
    "                # fig, axs = plt.subplots(nrows=int(n_datapoint), ncols=n_sample,sharex=True,sharey=True, figsize=(3, 8))# ,figsize=(8,3))\n",
    "                # def animate_diff(i, x_gen_store):\n",
    "                    \n",
    "                #     print('max and min', np.max(x_gen_store), np.min(x_gen_store))\n",
    "                    \n",
    "                #     # x_gen_store_clipped = np.clip(x_gen_store, 0, 1)\n",
    "                    \n",
    "                #     print(f'gif animating frame {i} of {x_gen_store.shape[0]}', end='\\r')\n",
    "                #     plots = []\n",
    "                #     for row in range(n_datapoint):\n",
    "                #         for col in range(n_sample):\n",
    "                #             axs[row, col].clear()\n",
    "                #             axs[row, col].set_xticks([])\n",
    "                #             axs[row, col].set_yticks([])\n",
    "                #             # plots.append(axs[row, col].imshow(x_gen_store[i,(row*10)+col,0],cmap='gray'))\n",
    "                #             plots.append(axs[row, col].imshow(-x_gen_store[i,(row*n_sample)+col,0],cmap='gray',vmin=0, vmax=1))\n",
    "                #     return plots\n",
    "                # # ani = FuncAnimation(fig, animate_diff, fargs=[x_gen_store],  interval=200, blit=False, repeat=True, frames=x_gen_store.shape[0])    \n",
    "                # ani = FuncAnimation(fig, animate_diff, fargs=[np.clip(x_gen_store, 0, 1)],  interval=200, blit=False, repeat=True, frames=x_gen_store.shape[0]) \n",
    "                # ani.save(save_dir + f\"gif_ep{ep}.gif\", dpi=100, writer=PillowWriter(fps=5))\n",
    "                # print('saved gif at ' + save_dir + f\"gif_ep{ep}.gif\")\n",
    "        \n",
    "        # optionally save model\n",
    "        if save_model and ep == int(n_epoch-1):\n",
    "            torch.save(ddpm.state_dict(), save_dir + f\"model_{ep}.pth\")\n",
    "            print('saved model at ' + save_dir + f\"model_{ep}.pth\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    save_dir = 'model_TESS_O11-54_new/'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    train_TESS(save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cefcf10-d779-42e5-a506-fceaf6c1e51c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440a3d30-d874-4a54-b284-3b8b76e5af93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff5c9b1-6dae-4e9d-b792-ba41872ee732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
