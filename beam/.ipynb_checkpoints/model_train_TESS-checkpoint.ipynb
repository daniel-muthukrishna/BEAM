{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29a3f9eb-ba1b-4631-a844-95fd8a88b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This script does conditional image generation on MNIST, using a diffusion model\n",
    "\n",
    "This code is modified from,\n",
    "https://github.com/cloneofsimo/minDiffusion\n",
    "\n",
    "Diffusion model is based on DDPM,\n",
    "https://arxiv.org/abs/2006.11239\n",
    "\n",
    "The conditioning idea is taken from 'Classifier-Free Diffusion Guidance',\n",
    "https://arxiv.org/abs/2207.12598\n",
    "\n",
    "This technique also features in ImageGen 'Photorealistic Text-to-Image Diffusion Modelswith Deep Language Understanding',\n",
    "https://arxiv.org/abs/2205.11487\n",
    "\n",
    "'''\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a9f0963-b378-4348-9001-8069ea204a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConvBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels: int, out_channels: int, is_res: bool = False\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        '''\n",
    "        standard ResNet style convolutional block\n",
    "        '''\n",
    "        self.same_channels = in_channels==out_channels\n",
    "        self.is_res = is_res\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.is_res:\n",
    "            x1 = self.conv1(x)\n",
    "            x2 = self.conv2(x1)\n",
    "            # this adds on correct residual in case channels have increased\n",
    "            if self.same_channels:\n",
    "                out = x + x2\n",
    "            else:\n",
    "                out = x1 + x2 \n",
    "            return out / 1.414\n",
    "        else:\n",
    "            x1 = self.conv1(x)\n",
    "            x2 = self.conv2(x1)\n",
    "            return x2\n",
    "\n",
    "\n",
    "class UnetDown(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UnetDown, self).__init__()\n",
    "        '''\n",
    "        process and downscale the image feature maps\n",
    "        '''\n",
    "        layers = [ResidualConvBlock(in_channels, out_channels), nn.MaxPool2d(2)]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class UnetUp(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UnetUp, self).__init__()\n",
    "        '''\n",
    "        process and upscale the image feature maps\n",
    "        '''\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, 2, 2),\n",
    "            ResidualConvBlock(out_channels, out_channels),\n",
    "            ResidualConvBlock(out_channels, out_channels),\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = torch.cat((x, skip), 1)\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EmbedFC(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim):\n",
    "        super(EmbedFC, self).__init__()\n",
    "        '''\n",
    "        generic one layer FC NN for embedding things  \n",
    "        '''\n",
    "        self.input_dim = input_dim\n",
    "        layers = [\n",
    "            nn.Linear(input_dim, emb_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(emb_dim, emb_dim),\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_dim)\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class ContextUnet(nn.Module):\n",
    "    # def __init__(self, in_channels, n_feat = 256, n_classes=10):\n",
    "    def __init__(self, in_channels, n_feat = 256):\n",
    "        super(ContextUnet, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.n_feat = n_feat\n",
    "\n",
    "        self.init_conv = ResidualConvBlock(in_channels, n_feat, is_res=True)\n",
    "\n",
    "        self.down1 = UnetDown(n_feat, n_feat)\n",
    "        self.down2 = UnetDown(n_feat, 2 * n_feat)\n",
    "        \n",
    "        self.to_vec = nn.Sequential(nn.AvgPool2d(4), nn.GELU())\n",
    "\n",
    "        self.timeembed1 = EmbedFC(1, 2*n_feat)\n",
    "        self.timeembed2 = EmbedFC(1, 1*n_feat)\n",
    "        self.timeembed1 = EmbedFC(1, 2*n_feat)\n",
    "        self.timeembed2 = EmbedFC(1, 1*n_feat)\n",
    "        self.contextembed1 = EmbedFC(12, 2*n_feat)\n",
    "        self.contextembed2 = EmbedFC(12, 1*n_feat)\n",
    "\n",
    "        self.up0 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2 * n_feat, 2 * n_feat, 4, 4), # otherwise just have 2*n_feat\n",
    "            nn.GroupNorm(8, 2 * n_feat),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.up1 = UnetUp(4 * n_feat, n_feat)\n",
    "        self.up2 = UnetUp(2 * n_feat, n_feat)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(2 * n_feat, n_feat, 3, 1, 1),\n",
    "            nn.GroupNorm(8, n_feat),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_feat, self.in_channels, 3, 1, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, c, t, context_mask):\n",
    "\n",
    "        # x is (noisy) image, c is context label, t is timestep, \n",
    "        # context_mask says which samples to block the context on\n",
    "\n",
    "        x = self.init_conv(x)\n",
    "        down1 = self.down1(x)\n",
    "        down2 = self.down2(down1)\n",
    "        hiddenvec = self.to_vec(down2)\n",
    "\n",
    "        c = c.reshape((c.shape[0], 12))\n",
    "        \n",
    "        # mask out context if context_mask == 1\n",
    "        context_mask = context_mask.reshape((x.shape[0], 12))\n",
    "        context_mask = (-1*(1-context_mask)) # need to flip 0 <-> 1\n",
    "        c = c * context_mask\n",
    "\n",
    "        # embed context, time step\n",
    "        cemb1 = self.contextembed1(c).view(-1, self.n_feat * 2, 1, 1)\n",
    "        temb1 = self.timeembed1(t).view(-1, self.n_feat * 2, 1, 1)\n",
    "        cemb2 = self.contextembed2(c).view(-1, self.n_feat, 1, 1)\n",
    "        temb2 = self.timeembed2(t).view(-1, self.n_feat, 1, 1)\n",
    "\n",
    "        # could concatenate the context embedding here instead of adaGN\n",
    "        # hiddenvec = torch.cat((hiddenvec, temb1, cemb1), 1)\n",
    "\n",
    "        up1 = self.up0(hiddenvec)\n",
    "        # up2 = self.up1(up1, down2) # if want to avoid add and multiply embeddings\n",
    "        up2 = self.up1(cemb1*up1+ temb1, down2)  # add and multiply embeddings\n",
    "        up3 = self.up2(cemb2*up2+ temb2, down1)\n",
    "        out = self.out(torch.cat((up3, x), 1))\n",
    "        return out\n",
    "\n",
    "\n",
    "def ddpm_schedules(beta1, beta2, T):\n",
    "    \"\"\"\n",
    "    Returns pre-computed schedules for DDPM sampling, training process.\n",
    "    \"\"\"\n",
    "    assert beta1 < beta2 < 1.0, \"beta1 and beta2 must be in (0, 1)\"\n",
    "\n",
    "    beta_t = (beta2 - beta1) * torch.arange(0, T + 1, dtype=torch.float32) / T + beta1\n",
    "    sqrt_beta_t = torch.sqrt(beta_t)\n",
    "    alpha_t = 1 - beta_t\n",
    "    log_alpha_t = torch.log(alpha_t)\n",
    "    alphabar_t = torch.cumsum(log_alpha_t, dim=0).exp()\n",
    "\n",
    "    sqrtab = torch.sqrt(alphabar_t)\n",
    "    oneover_sqrta = 1 / torch.sqrt(alpha_t)\n",
    "\n",
    "    sqrtmab = torch.sqrt(1 - alphabar_t)\n",
    "    mab_over_sqrtmab_inv = (1 - alpha_t) / sqrtmab\n",
    "\n",
    "    return {\n",
    "        \"alpha_t\": alpha_t,  # \\alpha_t\n",
    "        \"oneover_sqrta\": oneover_sqrta,  # 1/\\sqrt{\\alpha_t}\n",
    "        \"sqrt_beta_t\": sqrt_beta_t,  # \\sqrt{\\beta_t}\n",
    "        \"alphabar_t\": alphabar_t,  # \\bar{\\alpha_t}\n",
    "        \"sqrtab\": sqrtab,  # \\sqrt{\\bar{\\alpha_t}}\n",
    "        \"sqrtmab\": sqrtmab,  # \\sqrt{1-\\bar{\\alpha_t}}\n",
    "        \"mab_over_sqrtmab\": mab_over_sqrtmab_inv,  # (1-\\alpha_t)/\\sqrt{1-\\bar{\\alpha_t}}\n",
    "    }\n",
    "\n",
    "\n",
    "class DDPM(nn.Module):\n",
    "    def __init__(self, nn_model, betas, n_T, device, drop_prob=0.1):\n",
    "        super(DDPM, self).__init__()\n",
    "        self.nn_model = nn_model.to(device)\n",
    "\n",
    "        # register_buffer allows accessing dictionary produced by ddpm_schedules\n",
    "        # e.g. can access self.sqrtab later\n",
    "        for k, v in ddpm_schedules(betas[0], betas[1], n_T).items():\n",
    "            self.register_buffer(k, v)\n",
    "\n",
    "        self.n_T = n_T\n",
    "        self.device = device\n",
    "        self.drop_prob = drop_prob\n",
    "        self.loss_mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        \"\"\"\n",
    "        this method is used in training, so samples t and noise randomly\n",
    "        \"\"\"\n",
    "        _ts = torch.randint(1, self.n_T+1, (x.shape[0],)).to(self.device)  # t ~ Uniform(0, n_T)\n",
    "        # edit so eps ~ N(xxx, yyy)\n",
    "        noise = torch.randn_like(x)  # eps ~ N(0, 1)\n",
    "\n",
    "        x_t = (\n",
    "            self.sqrtab[_ts, None].reshape((x.shape[0], 1, 1, 1)) * x\n",
    "            + self.sqrtmab[_ts, None].reshape((x.shape[0], 1, 1, 1)) * noise\n",
    "        )  # This is the x_t, which is sqrt(alphabar) x_0 + sqrt(1-alphabar) * eps\n",
    "        # We should predict the \"error term\" from this x_t. Loss is what we return.\n",
    "\n",
    "        # dropout context with some probability\n",
    "        context_mask = torch.bernoulli(torch.zeros_like(c)+self.drop_prob).to(self.device)\n",
    "        \n",
    "        # return MSE between added noise, and our predicted noise\n",
    "        return self.loss_mse(noise, self.nn_model(x_t, c, _ts / self.n_T, context_mask))\n",
    "\n",
    "    def sample(self, n_sample, size, device, guide_w = 0.0):\n",
    "        '''\n",
    "        the c_i, context, is a random 1x12 vector. It is not real data. This function will\n",
    "        not give good preditions. Look to sample_c for better results\n",
    "        '''\n",
    "        \n",
    "        # we follow the guidance sampling scheme described in 'Classifier-Free Diffusion Guidance'\n",
    "        # to make the fwd passes efficient, we concat two versions of the dataset,\n",
    "        # one with context_mask=0 and the other context_mask=1\n",
    "        # we then mix the outputs with the guidance scale, w\n",
    "        # where w>0 means more guidance\n",
    "\n",
    "        # edit so eps ~ N(xxx, yyy)\n",
    "        x_i = torch.randn(n_sample, *size).to(device)  # x_T ~ N(0, 1), sample initial noise\n",
    "        c_i = torch.rand((n_sample, 1, 12)).to(device) # context for us just cycles throught the mnist labels\n",
    "\n",
    "        # don't drop context at test time\n",
    "        context_mask = torch.zeros_like(c_i).to(device)\n",
    "\n",
    "        # double the batch\n",
    "        c_i = c_i.repeat(2, 1, 1)\n",
    "        context_mask = context_mask.repeat(2, 1, 1)\n",
    "        context_mask[n_sample:] = 1. # makes second half of batch context free\n",
    "\n",
    "        x_i_store = [] # keep track of generated steps in case want to plot something \n",
    "        print()\n",
    "        for i in range(self.n_T, 0, -1):\n",
    "            print(f'sampling timestep {i}',end='\\r')\n",
    "            t_is = torch.tensor([i / self.n_T]).to(device)\n",
    "            t_is = t_is.repeat(n_sample,1,1,1)\n",
    "\n",
    "            # double batch\n",
    "            x_i = x_i.repeat(2,1,1,1)\n",
    "            t_is = t_is.repeat(2,1,1,1)\n",
    "\n",
    "            # edit so eps ~ N(xxx, yyy)\n",
    "            z = torch.randn(n_sample, *size).to(device) if i > 1 else 0\n",
    "\n",
    "            # split predictions and compute weighting\n",
    "            eps = self.nn_model(x_i, c_i, t_is, context_mask)\n",
    "            eps1 = eps[:n_sample]\n",
    "            eps2 = eps[n_sample:]\n",
    "            \n",
    "            eps = (1+guide_w)*eps1 - guide_w*eps2\n",
    "            x_i = x_i[:n_sample]\n",
    "            x_i = (\n",
    "                self.oneover_sqrta[i] * (x_i - eps * self.mab_over_sqrtmab[i])\n",
    "                + self.sqrt_beta_t[i] * z\n",
    "            )\n",
    "            if i%20==0 or i==self.n_T or i<8:\n",
    "                x_i_store.append(x_i.detach().cpu().numpy())\n",
    "        \n",
    "        x_i_store = np.array(x_i_store)\n",
    "        return x_i, x_i_store\n",
    "\n",
    "\n",
    "    def sample_c(self, c_i, n_sample, size, device):\n",
    "        '''\n",
    "        this is different than the function sample above\n",
    "        this always uses classifer guidance for diffusion, so no need to concat 2 versions of \n",
    "        dataset or have a guidance scale w. Also context_mask=0 always since no mask used\n",
    "\n",
    "        taking n_sample samples of EACH datapoint. There are n_datapoint datapoints\n",
    "        '''\n",
    "        n_datapoint = c_i.shape[0]\n",
    "\n",
    "        # edit so eps ~ N(xxx, yyy)\n",
    "        x_i = torch.randn(n_datapoint*n_sample, *size).to(device)  # x_T ~ N(0, 1), sample initial noise\n",
    "        \n",
    "        # repeat c_i n_sample times to make up a row\n",
    "        c_i = torch.cat([c_i[idx:idx+1].repeat(n_sample, 1, 1) for idx in range(n_datapoint)]).to(device)\n",
    "        \n",
    "        # don't drop context at test time. To include context make context_mask all 0's\n",
    "        context_mask = torch.zeros_like(c_i).to(device)\n",
    "\n",
    "        x_i_store = [] # keep track of generated steps in case want to plot something \n",
    "        print()\n",
    "        for i in range(self.n_T, 0, -1):\n",
    "            print(f'sampling timestep {i}',end='\\r')\n",
    "            t_is = torch.tensor([i / self.n_T]).to(device)\n",
    "            t_is = t_is.repeat(n_datapoint*n_sample,1,1,1)\n",
    "\n",
    "            # edit so eps ~ N(xxx, yyy)\n",
    "            z = torch.randn(n_datapoint*n_sample, *size).to(device) if i > 1 else 0\n",
    "\n",
    "            # compute weighting\n",
    "            eps = self.nn_model(x_i, c_i, t_is, context_mask)\n",
    "            \n",
    "            x_i = (\n",
    "                self.oneover_sqrta[i] * (x_i - eps * self.mab_over_sqrtmab[i])\n",
    "                + self.sqrt_beta_t[i] * z\n",
    "            )\n",
    "            if i%20==0 or i==self.n_T or i<8:\n",
    "                x_i_store.append(x_i.detach().cpu().numpy())\n",
    "        \n",
    "        x_i_store = np.array(x_i_store)\n",
    "        return x_i, x_i_store\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6048c5b5-c52a-4577-9c5a-5120c880bf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25960\n",
      "torch.Size([1, 12])\n",
      "torch.Size([1, 16, 16])\n",
      "00006869\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# @title TESS Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class TESSDataset(Dataset):\n",
    "    def __init__(self, angle_filename):\n",
    "        \n",
    "        # get data\n",
    "        angle_folder = \"/pdo/users/jlupoiii/TESS/data/angles/\"\n",
    "        ccd_folder = \"/pdo/users/jlupoiii/TESS/data/ccds_background_subtracted/\"\n",
    "\n",
    "        # data matrices\n",
    "        X = []\n",
    "        Y = []\n",
    "        ffi_nums = []\n",
    "\n",
    "        self.angles_dic = pickle.load(open(angle_folder+angle_filename, \"rb\"))\n",
    "\n",
    "        # self.ffi_num_to_orbit_dic = pickle.load(open(angle_folder+'ffi_num_to_orbit_dic.pkl', \"rb\"))\n",
    "\n",
    "        for filename in os.listdir(ccd_folder):\n",
    "            if len(filename) < 40 or filename[27] != '3': continue\n",
    "\n",
    "            image_arr = pickle.load(open(ccd_folder+filename, \"rb\"))\n",
    "            ffi_num = filename[18:18+8]\n",
    "            try:\n",
    "                angles = self.angles_dic[ffi_num]\n",
    "                # print('Got ffi number', ffi_num)\n",
    "            except:\n",
    "                # print('Could not find ffi with number:', ffi_num)\n",
    "                continue\n",
    "                \n",
    "            X.append(np.array([angles['1/ED'], angles['1/MD'], angles['1/ED^2'], angles['1/MD^2'], angles['Eel'], angles['Eaz'], angles['Mel'], angles['Maz'], angles['E3el'], angles['E3az'], angles['M3el'], angles['M3az']]))\n",
    "            Y.append(image_arr.flatten())\n",
    "            ffi_nums.append(ffi_num)\n",
    "        \n",
    "        self.data = [Image.fromarray(x) for x in X]\n",
    "        self.labels = [Image.fromarray(y) for y in Y]\n",
    "        self.ffi_nums = ffi_nums\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        angles_image = self.data[idx]\n",
    "        ffi_image = self.labels[idx]\n",
    "        ffi_num = self.ffi_nums[idx]\n",
    "        orbit = self.angles_dic[ffi_num][\"orbit\"]\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            lambda s: s.reshape(1, 12)\n",
    "        ])\n",
    "        target_transform = transforms.Compose([\n",
    "            lambda s: np.array(s),\n",
    "            lambda s: s.reshape((16,16)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "        angles_image = transform(angles_image)\n",
    "        ffi_image = target_transform(ffi_image)\n",
    "\n",
    "        # X: 1x12 vector of angles and distances\n",
    "        # Y: 16x16 image\n",
    "        return {\"x\":angles_image, \"y\":ffi_image, \"ffi_num\": ffi_num, \"orbit\": orbit}\n",
    "\n",
    "\n",
    "# MAKE DATASET\n",
    "\n",
    "# we are calculating Y GIVEN X\n",
    "tess_dataset = TESSDataset('angles_O11-54_data_dic.pkl')\n",
    "print(len(tess_dataset))\n",
    "print(tess_dataset[1]['x'].shape)\n",
    "print(tess_dataset[1]['y'].shape)\n",
    "print(tess_dataset[1]['ffi_num'])\n",
    "print(tess_dataset[1]['orbit'])\n",
    "\n",
    "# # # plt.plot(tess_dataset[1]['x'][0])\n",
    "# # print('x:', tess_dataset[1]['x'][0])\n",
    "\n",
    "# # plt.imshow(tess_dataset[1]['y'][0], vmin=0, vmax=1)\n",
    "# # plt.colorbar()\n",
    "# # plt.show()\n",
    "# # plt.close()\n",
    "\n",
    "# # # displays all datapoints\n",
    "# # idx = 0\n",
    "# # for i in range(len(tess_dataset)):\n",
    "# #     print('------')\n",
    "# #     print(idx)\n",
    "# #     idx += 1\n",
    "# #     print('x:', tess_dataset[i]['x'][0])\n",
    "# #     plt.imshow(tess_dataset[i]['y'][0], vmin=0, vmax=1)\n",
    "# #     plt.colorbar()\n",
    "# #     plt.show()\n",
    "# #     plt.close()\n",
    "\n",
    "# print('x:', tess_dataset[9]['x'][0])\n",
    "# plt.imshow(tess_dataset[9]['y'][0], vmin=0, vmax=1)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f333afb2-c52a-4d54-8637-a839401bb875",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset has 25960 datapoints\n",
      "Training dataset has 20768 datapoints\n",
      "Validation dataset has 5192 datapoints\n",
      "\n",
      "epoch 0 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0116: 100%|████████████████| 1298/1298 [00:24<00:00, 52.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0091: 100%|███████████████| 324/324 [00:02<00:00, 143.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saved image at model_TESS_11-54_train_valid_1/image_ep0_training.pdf\n",
      "\n",
      "saved image at model_TESS_11-54_train_valid_1/image_ep0_validation.pdf\n",
      "epoch 1 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0071: 100%|████████████████| 1298/1298 [00:26<00:00, 48.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0091: 100%|███████████████| 324/324 [00:02<00:00, 133.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0052: 100%|████████████████| 1298/1298 [00:26<00:00, 49.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0079: 100%|███████████████| 324/324 [00:02<00:00, 131.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0062: 100%|████████████████| 1298/1298 [00:24<00:00, 54.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0039: 100%|███████████████| 324/324 [00:02<00:00, 136.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0074: 100%|████████████████| 1298/1298 [00:25<00:00, 50.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0061: 100%|███████████████| 324/324 [00:02<00:00, 135.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0057: 100%|████████████████| 1298/1298 [00:26<00:00, 49.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0063: 100%|███████████████| 324/324 [00:02<00:00, 138.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0031: 100%|████████████████| 1298/1298 [00:26<00:00, 48.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0033: 100%|███████████████| 324/324 [00:02<00:00, 131.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0039: 100%|████████████████| 1298/1298 [00:23<00:00, 55.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0030: 100%|███████████████| 324/324 [00:02<00:00, 130.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0028: 100%|████████████████| 1298/1298 [00:26<00:00, 48.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0016: 100%|███████████████| 324/324 [00:02<00:00, 137.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0021:   2%|▍                 | 29/1298 [00:01<00:34, 37.11it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "training loss: 0.0022: 100%|████████████████| 1298/1298 [00:28<00:00, 45.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0021: 100%|███████████████| 324/324 [00:02<00:00, 129.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0023: 100%|████████████████| 1298/1298 [00:26<00:00, 49.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0020: 100%|███████████████| 324/324 [00:02<00:00, 140.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0022: 100%|████████████████| 1298/1298 [00:24<00:00, 52.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0016: 100%|███████████████| 324/324 [00:02<00:00, 130.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0018:  13%|██▏              | 168/1298 [00:04<00:22, 50.68it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "training loss: 0.0015: 100%|████████████████| 1298/1298 [00:26<00:00, 48.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0015: 100%|███████████████| 324/324 [00:02<00:00, 131.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0015: 100%|████████████████| 1298/1298 [00:26<00:00, 49.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0012: 100%|███████████████| 324/324 [00:02<00:00, 138.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0028: 100%|████████████████| 1298/1298 [00:26<00:00, 49.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0017: 100%|███████████████| 324/324 [00:02<00:00, 143.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0020: 100%|████████████████| 1298/1298 [00:27<00:00, 48.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0020: 100%|███████████████| 324/324 [00:02<00:00, 139.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0020: 100%|████████████████| 1298/1298 [00:25<00:00, 50.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0015:  77%|███████████▌   | 249/324 [00:01<00:00, 191.09it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Validation loss: 0.0008: 100%|███████████████| 324/324 [00:02<00:00, 132.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0025: 100%|████████████████| 1298/1298 [00:23<00:00, 54.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0013: 100%|███████████████| 324/324 [00:02<00:00, 137.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0016: 100%|████████████████| 1298/1298 [00:25<00:00, 50.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0008: 100%|███████████████| 324/324 [00:02<00:00, 135.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0010: 100%|████████████████| 1298/1298 [00:26<00:00, 48.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0015: 100%|███████████████| 324/324 [00:02<00:00, 135.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0014: 100%|████████████████| 1298/1298 [00:25<00:00, 51.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0012: 100%|███████████████| 324/324 [00:02<00:00, 132.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0017: 100%|████████████████| 1298/1298 [00:24<00:00, 52.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0016:  60%|█████████      | 195/324 [00:01<00:00, 188.94it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "training loss: 0.0011: 100%|████████████████| 1298/1298 [00:26<00:00, 48.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0005: 100%|███████████████| 324/324 [00:02<00:00, 135.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0010: 100%|████████████████| 1298/1298 [00:25<00:00, 50.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0008: 100%|███████████████| 324/324 [00:02<00:00, 131.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0016: 100%|████████████████| 1298/1298 [00:23<00:00, 55.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0011: 100%|███████████████| 324/324 [00:02<00:00, 132.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0014: 100%|████████████████| 1298/1298 [00:26<00:00, 48.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0011: 100%|███████████████| 324/324 [00:02<00:00, 131.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0011: 100%|████████████████| 1298/1298 [00:25<00:00, 50.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0008: 100%|███████████████| 324/324 [00:02<00:00, 136.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0009:  51%|████████▌        | 658/1298 [00:13<00:12, 49.50it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "training loss: 0.0008: 100%|████████████████| 1298/1298 [00:26<00:00, 49.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0008: 100%|███████████████| 324/324 [00:02<00:00, 136.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0010: 100%|████████████████| 1298/1298 [00:26<00:00, 49.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0006: 100%|███████████████| 324/324 [00:02<00:00, 135.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0013: 100%|████████████████| 1298/1298 [00:26<00:00, 48.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0006:  56%|████████▎      | 180/324 [00:01<00:00, 187.35it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "training loss: 0.0013: 100%|████████████████| 1298/1298 [00:25<00:00, 51.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0009: 100%|███████████████| 324/324 [00:02<00:00, 135.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0010: 100%|████████████████| 1298/1298 [00:26<00:00, 48.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0008: 100%|███████████████| 324/324 [00:02<00:00, 143.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saved image at model_TESS_11-54_train_valid_1/image_ep100_training.pdf\n",
      "\n",
      "saved image at model_TESS_11-54_train_valid_1/image_ep100_validation.pdf\n",
      "epoch 101 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0007: 100%|████████████████| 1298/1298 [00:25<00:00, 51.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0008: 100%|███████████████| 324/324 [00:02<00:00, 134.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0011: 100%|████████████████| 1298/1298 [00:26<00:00, 49.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0008: 100%|███████████████| 324/324 [00:02<00:00, 131.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 103 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0011: 100%|████████████████| 1298/1298 [00:25<00:00, 50.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 103 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0009: 100%|███████████████| 324/324 [00:02<00:00, 131.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0008:   5%|▉                 | 66/1298 [00:02<00:27, 45.03it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "training loss: 0.0008: 100%|████████████████| 1298/1298 [00:24<00:00, 53.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0009: 100%|███████████████| 324/324 [00:02<00:00, 134.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0008: 100%|████████████████| 1298/1298 [00:25<00:00, 50.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0008: 100%|███████████████| 324/324 [00:02<00:00, 136.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 121 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0008: 100%|████████████████| 1298/1298 [00:24<00:00, 52.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 121 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0005: 100%|███████████████| 324/324 [00:02<00:00, 140.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0011:  22%|███▋             | 280/1298 [00:06<00:20, 48.69it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "training loss: 0.0009: 100%|████████████████| 1298/1298 [00:26<00:00, 48.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 127 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0009: 100%|███████████████| 324/324 [00:02<00:00, 143.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0012: 100%|████████████████| 1298/1298 [00:26<00:00, 49.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0007: 100%|███████████████| 324/324 [00:02<00:00, 129.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0009: 100%|████████████████| 1298/1298 [00:24<00:00, 52.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0005: 100%|███████████████| 324/324 [00:02<00:00, 126.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0009: 100%|████████████████| 1298/1298 [00:25<00:00, 51.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0005: 100%|███████████████| 324/324 [00:02<00:00, 130.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0006:  76%|████████████▊    | 981/1298 [00:17<00:06, 48.50it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "training loss: 0.0010: 100%|████████████████| 1298/1298 [00:26<00:00, 48.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0005: 100%|███████████████| 324/324 [00:02<00:00, 124.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0005: 100%|████████████████| 1298/1298 [00:25<00:00, 50.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0005: 100%|███████████████| 324/324 [00:02<00:00, 136.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0007: 100%|████████████████| 1298/1298 [00:26<00:00, 48.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 150 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0004: 100%|███████████████| 324/324 [00:02<00:00, 128.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saved image at model_TESS_11-54_train_valid_1/image_ep150_training.pdf\n",
      "\n",
      "saved image at model_TESS_11-54_train_valid_1/image_ep150_validation.pdf\n",
      "epoch 151 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0006: 100%|████████████████| 1298/1298 [00:26<00:00, 49.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 151 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0005: 100%|███████████████| 324/324 [00:02<00:00, 139.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0007:  28%|████▊            | 364/1298 [00:08<00:19, 48.37it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "training loss: 0.0006: 100%|████████████████| 1298/1298 [00:25<00:00, 50.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0005: 100%|███████████████| 324/324 [00:02<00:00, 139.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 163 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0011: 100%|████████████████| 1298/1298 [00:26<00:00, 48.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 165 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0005: 100%|███████████████| 324/324 [00:02<00:00, 147.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0010: 100%|████████████████| 1298/1298 [00:24<00:00, 54.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0005: 100%|███████████████| 324/324 [00:02<00:00, 133.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 167 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0009:  44%|███████▌         | 575/1298 [00:12<00:14, 48.38it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "training loss: 0.0007: 100%|████████████████| 1298/1298 [00:26<00:00, 48.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 173 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0004: 100%|███████████████| 324/324 [00:02<00:00, 132.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0006: 100%|████████████████| 1298/1298 [00:23<00:00, 54.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0005: 100%|███████████████| 324/324 [00:02<00:00, 133.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 177 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0007: 100%|████████████████| 1298/1298 [00:25<00:00, 50.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 177 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0004: 100%|███████████████| 324/324 [00:02<00:00, 133.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0007:  14%|██▍              | 187/1298 [00:04<00:22, 49.97it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "training loss: 0.0007: 100%|████████████████| 1298/1298 [00:24<00:00, 52.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0004: 100%|███████████████| 324/324 [00:02<00:00, 127.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0007: 100%|████████████████| 1298/1298 [00:24<00:00, 52.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 187 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0005: 100%|███████████████| 324/324 [00:02<00:00, 125.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0007: 100%|████████████████| 1298/1298 [00:26<00:00, 49.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0006: 100%|███████████████| 324/324 [00:02<00:00, 131.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 189 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0007:  51%|████████▌        | 658/1298 [00:14<00:12, 49.48it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "training loss: 0.0005: 100%|████████████████| 1298/1298 [00:24<00:00, 53.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0003: 100%|███████████████| 324/324 [00:02<00:00, 140.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 197 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0004: 100%|████████████████| 1298/1298 [00:25<00:00, 51.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 199 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0004: 100%|███████████████| 324/324 [00:02<00:00, 130.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0007: 100%|████████████████| 1298/1298 [00:26<00:00, 49.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0005: 100%|███████████████| 324/324 [00:02<00:00, 138.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saved image at model_TESS_11-54_train_valid_1/image_ep200_training.pdf\n",
      "\n",
      "saved image at model_TESS_11-54_train_valid_1/image_ep200_validation.pdf\n",
      "epoch 201 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0005:  12%|██               | 161/1298 [00:03<00:17, 65.48it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "training loss: 0.0006: 100%|████████████████| 1298/1298 [00:24<00:00, 53.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 207 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0003: 100%|███████████████| 324/324 [00:02<00:00, 134.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 208 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0007: 100%|████████████████| 1298/1298 [00:26<00:00, 49.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 211 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0003: 100%|███████████████| 324/324 [00:02<00:00, 139.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 212 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0006:  82%|█████████████▏  | 1069/1298 [00:20<00:04, 49.14it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "training loss: 0.0004: 100%|████████████████| 1298/1298 [00:25<00:00, 51.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 219 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0003: 100%|███████████████| 324/324 [00:02<00:00, 133.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 220 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0009: 100%|████████████████| 1298/1298 [00:26<00:00, 49.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 222 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0004: 100%|███████████████| 324/324 [00:02<00:00, 131.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 223 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0005: 100%|████████████████| 1298/1298 [00:26<00:00, 49.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 223 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0003: 100%|███████████████| 324/324 [00:02<00:00, 136.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 224 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0006:  31%|█████▎           | 406/1298 [00:08<00:12, 71.47it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "training loss: 0.0006: 100%|████████████████| 1298/1298 [00:22<00:00, 57.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 230 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0004: 100%|███████████████| 324/324 [00:02<00:00, 134.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 231 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0006: 100%|████████████████| 1298/1298 [00:26<00:00, 48.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 234 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0004: 100%|███████████████| 324/324 [00:02<00:00, 136.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 235 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0005:  98%|███████████████▌| 1267/1298 [00:25<00:00, 48.78it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "training loss: 0.0007: 100%|████████████████| 1298/1298 [00:26<00:00, 48.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 242 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0009: 100%|███████████████| 324/324 [00:02<00:00, 137.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 243 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0005: 100%|████████████████| 1298/1298 [00:26<00:00, 48.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 245 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0004: 100%|███████████████| 324/324 [00:02<00:00, 133.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 246 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0005: 100%|████████████████| 1298/1298 [00:25<00:00, 51.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 246 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0002: 100%|███████████████| 324/324 [00:02<00:00, 127.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 247 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0005:  45%|███████▋         | 583/1298 [00:12<00:14, 49.37it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Validation loss: 0.0004: 100%|███████████████| 324/324 [00:02<00:00, 131.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 254 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0004: 100%|████████████████| 1298/1298 [00:25<00:00, 50.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 257 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0004: 100%|███████████████| 324/324 [00:02<00:00, 132.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 258 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0006:  96%|███████████████▍| 1252/1298 [00:24<00:00, 47.84it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "training loss: 0.0004: 100%|████████████████| 1298/1298 [00:25<00:00, 51.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 265 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0003: 100%|███████████████| 324/324 [00:02<00:00, 130.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 266 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0004: 100%|████████████████| 1298/1298 [00:26<00:00, 48.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 268 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0004: 100%|███████████████| 324/324 [00:02<00:00, 138.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 269 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0003: 100%|████████████████| 1298/1298 [00:25<00:00, 50.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 269 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0002: 100%|███████████████| 324/324 [00:02<00:00, 129.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 270 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0007:  41%|██████▉          | 533/1298 [00:11<00:15, 49.20it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "training loss: 0.0004: 100%|████████████████| 1298/1298 [00:25<00:00, 50.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 277 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0005: 100%|███████████████| 324/324 [00:02<00:00, 137.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 278 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0003: 100%|███████████████| 324/324 [00:02<00:00, 134.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 281 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0005: 100%|████████████████| 1298/1298 [00:24<00:00, 52.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 281 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0003: 100%|███████████████| 324/324 [00:02<00:00, 126.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 282 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0004:  65%|███████████      | 844/1298 [00:15<00:06, 68.12it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "training loss: 0.0004: 100%|████████████████| 1298/1298 [00:25<00:00, 50.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 290 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0002: 100%|███████████████| 324/324 [00:02<00:00, 138.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 291 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0004: 100%|████████████████| 1298/1298 [00:26<00:00, 48.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 293 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0002: 100%|███████████████| 324/324 [00:02<00:00, 131.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 294 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0006: 100%|████████████████| 1298/1298 [00:25<00:00, 50.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 294 validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0002: 100%|███████████████| 324/324 [00:02<00:00, 127.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 295 training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.0003:  41%|██████▉          | 531/1298 [00:09<00:15, 51.02it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_TESS(save_dir):\n",
    "    # hardcoding these here\n",
    "    n_epoch = 300\n",
    "    batch_size = 16\n",
    "    train_ratio = 0.8\n",
    "    n_T = 600 # 400\n",
    "    device = \"cuda:0\"\n",
    "    n_feat = 256 # 128 ok, 256 better (but slower)\n",
    "    lrate = 1e-4\n",
    "    save_model = True\n",
    "    # save_dir = './model_O13/'\n",
    "    dataset_filename = \"angles_O11-54_data_dic.pkl\"\n",
    "    # ws_test = [0.0, 0.5, 2.0] # strength of generative guidance. Not used in sample_c()\n",
    "\n",
    "    ddpm = DDPM(nn_model=ContextUnet(in_channels=1, n_feat=n_feat), betas=(1e-4, 0.02), n_T=n_T, device=device, drop_prob=0.1)\n",
    "    ddpm.to(device)\n",
    "\n",
    "    # optionally load a model\n",
    "    # ddpm.load_state_dict(torch.load(\"./data/diffusion_outputs/ddpm_unet01_mnist_9.pth\"))\n",
    "\n",
    "\n",
    "\n",
    "    full_dataset = TESSDataset(dataset_filename)\n",
    "    num_train_samples = int(train_ratio * len(full_dataset))\n",
    "    num_valid_samples = len(full_dataset) - num_train_samples\n",
    "    train_dataset, valid_dataset = random_split(full_dataset, [num_train_samples, num_valid_samples])\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=5, drop_last=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=5, drop_last=True)\n",
    "    optim = torch.optim.Adam(ddpm.parameters(), lr=lrate)\n",
    "    \n",
    "    print(f'Full dataset has {num_train_samples+num_valid_samples} datapoints')\n",
    "    print(f'Training dataset has {num_train_samples} datapoints')\n",
    "    print(f'Validation dataset has {num_valid_samples} datapoints')\n",
    "    print()\n",
    "\n",
    "    loss_history_train = []\n",
    "    loss_history_valid = []\n",
    "    \n",
    "    for ep in range(n_epoch):\n",
    "        print(f'epoch {ep} training')\n",
    "        ddpm.train()\n",
    "\n",
    "        # linear lrate decay\n",
    "        optim.param_groups[0]['lr'] = lrate*(1-ep/n_epoch)\n",
    "\n",
    "        pbar_train = tqdm(train_dataloader)\n",
    "        loss_ema_train = None\n",
    "\n",
    "        for data_dic_train in pbar_train:\n",
    "            optim.zero_grad()\n",
    "            x_train = data_dic_train['y'].to(device)\n",
    "            c_train = data_dic_train['x'].to(device)\n",
    "            ffi_nums_train = data_dic_train['ffi_num']\n",
    "            orbits_train = data_dic_train['orbit']\n",
    "            \n",
    "            # FOR THE GIFS MAKE SURE THEY ARE CAPPED AT 0 TO 1. THATS WHY I CANT SEE THEM\n",
    "\n",
    "            loss_train = ddpm(x_train, c_train)\n",
    "            loss_train.backward()\n",
    "            if loss_ema_train is None:\n",
    "                loss_ema_train = loss_train.item()\n",
    "            else:\n",
    "                loss_ema_train = 0.95 * loss_ema_train + 0.05 * loss_train.item()\n",
    "            pbar_train.set_description(f\"training loss: {loss_ema_train:.4f}\")\n",
    "            optim.step()\n",
    "\n",
    "        loss_history_train.append(loss_ema_train)\n",
    "        \n",
    "        # for eval, save an image of rows of datapoint predictions. The first column are the real\n",
    "        # images and the rest are predictions\n",
    "        ddpm.eval()\n",
    "        with torch.no_grad():\n",
    "            # calculating validation loss for the epoch\n",
    "            print(f'epoch {ep} validation')\n",
    "            pbar_valid = tqdm(valid_dataloader)\n",
    "            loss_ema_valid = None\n",
    "            for data_dic_valid in pbar_valid:\n",
    "                x_valid = data_dic_valid['y'].to(device)\n",
    "                c_valid = data_dic_valid['x'].to(device)\n",
    "                ffi_nums_valid = data_dic_valid['ffi_num']\n",
    "                orbits_valid = data_dic_valid['orbit']\n",
    "    \n",
    "                loss_valid = ddpm(x_valid, c_valid)\n",
    "                if loss_ema_valid is None:\n",
    "                    loss_ema_valid = loss_valid.item()\n",
    "                else:\n",
    "                    loss_ema_valid = 0.95 * loss_ema_valid + 0.05 * loss_valid.item()\n",
    "                pbar_valid.set_description(f\"validation loss: {loss_ema_valid:.4f}\")\n",
    "            loss_history_valid.append(loss_ema_valid)\n",
    "\n",
    "            if ep%25==0 or ep == int(n_epoch-1):\n",
    "                n_datapoint = 10\n",
    "                n_sample = 5\n",
    "                \n",
    "                def sample_save_plots(x_real, c_real, ffi_nums_real, orbits_real, train_or_valid_string):\n",
    "                    # want each row to be for one datapoint, and for there to be n_sample columns\n",
    "                    # want the first column to be the real image\n",
    "\n",
    "                    # choose the first n_datapoint datapoints to do predictions on\n",
    "                    # The dataloader has shuffle=True so these datapoints are always random\n",
    "\n",
    "                    x_gen, x_gen_store = ddpm.sample_c(c_real, n_sample, (1, 16, 16), device)\n",
    "                \n",
    "                    x_all = torch.Tensor().to(device)\n",
    "                    for i in range(n_datapoint):\n",
    "                        x_all = torch.cat([x_all, x_real[i:i+1], x_gen[i*n_sample:(i+1)*n_sample]])\n",
    "\n",
    "                    fig, axes = plt.subplots(n_datapoint, n_sample+1, figsize=(15, 30))\n",
    "                    plt.subplots_adjust(top=1.7)\n",
    "                    for idx in range(x_all.shape[0]):\n",
    "                        image = x_all[idx, 0, :, :].cpu().detach().numpy()\n",
    "                        axes[idx//(n_sample+1), idx%(n_sample+1)].imshow(image, cmap='gray', vmin=0, vmax=1)\n",
    "                        axes[idx//(n_sample+1), idx%(n_sample+1)].axis('off')\n",
    "\n",
    "                    # set labels for sampled columns\n",
    "                    for i in range(n_sample):\n",
    "                        axes[0, i+1].set_title(f\"Sample {i+1} \\n \", fontsize=12)\n",
    "\n",
    "                    # set labels for each datapoint\n",
    "                    for j in range(n_datapoint):\n",
    "                        data_title = f\"O{orbits_real[j]} , ffi {ffi_nums_real[j]}\"\n",
    "                        if j==0: data_title = f\"Original\\n{data_title}\"\n",
    "                        axes[j, 0].set_title(data_title, fontsize=12)\n",
    "\n",
    "                    # Sets title for whole figure\n",
    "                    fig.suptitle(f\"{train_or_valid_string} predictions for epoch {ep}\", fontsize = 25)\n",
    "\n",
    "                    # save images\n",
    "                    plt.tight_layout()\n",
    "                    fig.savefig(save_dir + f\"image_ep{ep}_{train_or_valid_string.lower()}.pdf\")\n",
    "                    print('saved image at ' + save_dir + f\"image_ep{ep}_{train_or_valid_string.lower()}.pdf\")\n",
    "                    plt.close()\n",
    "\n",
    "                # training set\n",
    "                x_train_real = x_train[:n_datapoint]\n",
    "                c_train_real = c_train[:n_datapoint]\n",
    "                ffi_nums_train_real = ffi_nums_train[:n_datapoint]\n",
    "                orbits_train_real = orbits_train[:n_datapoint]\n",
    "                sample_save_plots(x_train_real, c_train_real, ffi_nums_train_real, orbits_train_real, \"Training\")\n",
    "\n",
    "                # validation set\n",
    "                x_valid_real = x_valid[:n_datapoint]\n",
    "                c_valid_real = c_valid[:n_datapoint]\n",
    "                ffi_nums_valid_real = ffi_nums_valid[:n_datapoint]\n",
    "                orbits_valid_real = orbits_valid[:n_datapoint]\n",
    "                sample_save_plots(x_valid_real, c_valid_real, ffi_nums_valid_real, orbits_valid_real, \"Validation\")\n",
    "\n",
    "                # save loss graph\n",
    "                plt.plot(loss_history_valid, label=\"Validation Loss\")\n",
    "                plt.plot(loss_history_train, label=\"Training Loss\")\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.ylabel('MSE Loss')\n",
    "                plt.title('Training and Validation MSE Loss over Epochs')\n",
    "                plt.legend()\n",
    "                plt.savefig(os.path.join(save_dir, 'loss_graph.png'))\n",
    "                plt.close()\n",
    "        \n",
    "\n",
    "                # # create gif of images evolving over time, based on x_gen_store\n",
    "                # fig, axs = plt.subplots(nrows=int(n_datapoint), ncols=n_sample,sharex=True,sharey=True, figsize=(3, 8))# ,figsize=(8,3))\n",
    "                # def animate_diff(i, x_gen_store):\n",
    "                    \n",
    "                #     print('max and min', np.max(x_gen_store), np.min(x_gen_store))\n",
    "                    \n",
    "                #     # x_gen_store_clipped = np.clip(x_gen_store, 0, 1)\n",
    "                    \n",
    "                #     print(f'gif animating frame {i} of {x_gen_store.shape[0]}', end='\\r')\n",
    "                #     plots = []\n",
    "                #     for row in range(n_datapoint):\n",
    "                #         for col in range(n_sample):\n",
    "                #             axs[row, col].clear()\n",
    "                #             axs[row, col].set_xticks([])\n",
    "                #             axs[row, col].set_yticks([])\n",
    "                #             # plots.append(axs[row, col].imshow(x_gen_store[i,(row*10)+col,0],cmap='gray'))\n",
    "                #             plots.append(axs[row, col].imshow(-x_gen_store[i,(row*n_sample)+col,0],cmap='gray',vmin=0, vmax=1))\n",
    "                #     return plots\n",
    "                # # ani = FuncAnimation(fig, animate_diff, fargs=[x_gen_store],  interval=200, blit=False, repeat=True, frames=x_gen_store.shape[0])    \n",
    "                # ani = FuncAnimation(fig, animate_diff, fargs=[np.clip(x_gen_store, 0, 1)],  interval=200, blit=False, repeat=True, frames=x_gen_store.shape[0]) \n",
    "                # ani.save(save_dir + f\"gif_ep{ep}.gif\", dpi=100, writer=PillowWriter(fps=5))\n",
    "                # print('saved gif at ' + save_dir + f\"gif_ep{ep}.gif\")\n",
    "        \n",
    "        # optionally save model\n",
    "        if save_model and ep == int(n_epoch-1):\n",
    "            torch.save(ddpm.state_dict(), save_dir + f\"model_{ep}.pth\")\n",
    "            print('saved model at ' + save_dir + f\"model_{ep}.pth\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    save_dir = 'model_TESS_11-54_train_valid_1/'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    train_TESS(save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cefcf10-d779-42e5-a506-fceaf6c1e51c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440a3d30-d874-4a54-b284-3b8b76e5af93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff5c9b1-6dae-4e9d-b792-ba41872ee732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
