{"cells":[{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1397,"status":"ok","timestamp":1692391145079,"user":{"displayName":"Joseph Lupo","userId":"18192058496751055649"},"user_tz":240},"id":"Le2oZ3K9Y_P5","outputId":"c3c5c849-6dad-4335-be2b-315234309fa0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","/content/gdrive/MyDrive/Projects/TESS/model_conditional_norm_flow_horses\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","\n","# %cd /content/gdrive/MyDrive/Projects/TESS/model_conditional_norm_flow/\n","# !ls\n","import os\n","os.chdir('/content/gdrive/MyDrive/Projects/TESS/model_conditional_norm_flow_horses/')\n","! pwd"]},{"cell_type":"code","source":["# ! rm -r log*"],"metadata":{"id":"spVDjyV0zIlY","executionInfo":{"status":"ok","timestamp":1692391145080,"user_tz":240,"elapsed":9,"user":{"displayName":"Joseph Lupo","userId":"18192058496751055649"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NuLbLhJk0kI5","executionInfo":{"status":"ok","timestamp":1692391145080,"user_tz":240,"elapsed":7,"user":{"displayName":"Joseph Lupo","userId":"18192058496751055649"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","execution_count":40,"metadata":{"id":"muEgDSedZP1B","executionInfo":{"status":"ok","timestamp":1692391145081,"user_tz":240,"elapsed":7,"user":{"displayName":"Joseph Lupo","userId":"18192058496751055649"}}},"outputs":[],"source":["# @title Utils\n","import os\n","import torch\n","import numpy as np\n","\n","def split_feature(tensor, type=\"split\"):\n","    \"\"\"\n","    type = [\"split\", \"cross\"]\n","    \"\"\"\n","    C = tensor.size(1)\n","    if type == \"split\":\n","        return tensor[:, :C // 2, ...], tensor[:, C // 2:, ...]\n","    elif type == \"cross\":\n","        return tensor[:, 0::2, ...], tensor[:, 1::2, ...]\n","\n","\n","def save_model(model, optim, scheduler, dir, iteration):\n","    path = os.path.join(dir, \"checkpoint_{}.pth.tar\".format(iteration))\n","    state = {}\n","    state[\"iteration\"] = iteration\n","    state[\"modelname\"] = model.__class__.__name__\n","    state[\"model\"] = model.state_dict()\n","    state[\"optim\"] = optim.state_dict()\n","    if scheduler is not None:\n","        state[\"scheduler\"] = scheduler.state_dict()\n","    else:\n","        state[\"scheduler\"] = None\n","\n","    torch.save(state, path)\n","\n","\n","def load_state(path, cuda):\n","    if cuda:\n","        print (\"load to gpu\")\n","        state = torch.load(path)\n","    else:\n","        print (\"load to cpu\")\n","        state = torch.load(path, map_location=lambda storage, loc: storage)\n","\n","    return state\n","\n","\n","def _fast_hist(label_true, label_pred, n_class):\n","    mask = (label_true >= 0) & (label_true < n_class)\n","    hist = np.bincount(\n","        n_class * label_true[mask].astype(int) +\n","        label_pred[mask].astype(int), minlength=n_class ** 2).reshape(n_class, n_class)\n","    return hist\n","\n","def compute_accuracy(label_trues, label_preds, n_class):\n","\n","    hist = np.zeros((n_class, n_class))\n","    for lt, lp in zip(label_trues, label_preds):\n","        hist += _fast_hist(lt.flatten(), lp.flatten(), n_class)\n","    acc = np.diag(hist).sum() / hist.sum()\n","    acc_cls = np.diag(hist) / hist.sum(axis=1)\n","    acc_cls = np.nanmean(acc_cls)\n","    iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n","    mean_iu = np.nanmean(iu)\n","    freq = hist.sum(axis=1) / hist.sum()\n","    fwavacc = (freq[freq > 0] * iu[freq > 0]).sum()\n","    return acc, acc_cls, mean_iu, fwavacc\n","\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"YniaSTAaaCMQ","executionInfo":{"status":"ok","timestamp":1692391145372,"user_tz":240,"elapsed":298,"user":{"displayName":"Joseph Lupo","userId":"18192058496751055649"}}},"outputs":[],"source":["# @title Modules\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","\n","\n","class ActNorm(nn.Module):\n","\n","    def __init__(self, num_channels):\n","        super().__init__()\n","\n","        size = [1, num_channels, 1, 1]\n","\n","        bias = torch.normal(mean=torch.zeros(*size), std=torch.ones(*size)*0.05)\n","        logs = torch.normal(mean=torch.zeros(*size), std=torch.ones(*size)*0.05)\n","        self.register_parameter(\"bias\", nn.Parameter(torch.Tensor(bias), requires_grad=True))\n","        self.register_parameter(\"logs\", nn.Parameter(torch.Tensor(logs), requires_grad=True))\n","\n","\n","    def forward(self, input, logdet=0, reverse=False):\n","        dimentions = input.size(2) * input.size(3)\n","        if reverse == False:\n","            input = input + self.bias\n","            input = input * torch.exp(self.logs)\n","            dlogdet = torch.sum(self.logs) * dimentions\n","            logdet = logdet + dlogdet\n","\n","        if reverse == True:\n","            input = input * torch.exp(-self.logs)\n","            input = input - self.bias\n","            dlogdet = - torch.sum(self.logs) * dimentions\n","            logdet = logdet + dlogdet\n","\n","        return input, logdet\n","\n","\n","class Conv2dZeros(nn.Conv2d):\n","\n","    def __init__(self, in_channel, out_channel, kernel_size=[3,3], stride=[1,1]):\n","        padding = (kernel_size[0] - 1) // 2\n","        super().__init__(in_channels=in_channel, out_channels=out_channel, kernel_size=kernel_size, stride=stride, padding=padding)\n","        self.weight.data.normal_(mean=0.0, std=0.1)\n","\n","\n","\n","class Conv2dResize(nn.Conv2d):\n","\n","    def __init__(self, in_size, out_size):\n","        stride = [in_size[1]//out_size[1], in_size[2]//out_size[2]]\n","        kernel_size = Conv2dResize.compute_kernel_size(in_size, out_size, stride)\n","        super().__init__(in_channels=in_size[0], out_channels=out_size[0], kernel_size=kernel_size, stride=stride)\n","        self.weight.data.zero_()\n","\n","\n","    @staticmethod\n","    def compute_kernel_size(in_size, out_size, stride):\n","        k0 = in_size[1] - (out_size[1] - 1) * stride[0]\n","        k1 = in_size[2] - (out_size[2] - 1) * stride[1]\n","        return[k0,k1]\n","\n","\n","\n","class Conv2dNorm(nn.Conv2d):\n","\n","    def __init__(self, in_channels, out_channels, kernel_size=[3, 3], stride=[1, 1]):\n","\n","        padding = (kernel_size[0] - 1) // 2\n","        super().__init__(in_channels, out_channels, kernel_size, stride, padding)\n","        #initialize weight\n","        self.weight.data.normal_(mean=0.0, std=0.05)\n","\n","\n","\n","class CondActNorm(nn.Module):\n","\n","    def __init__(self, x_size, y_channels, x_hidden_channels, x_hidden_size):\n","        super().__init__()\n","\n","        C_x,H_x,W_x = x_size\n","\n","        # conditioning network\n","        self.x_Con = nn.Sequential(\n","            Conv2dResize(in_size=[C_x,H_x,W_x], out_size=[x_hidden_channels, H_x//2, W_x//2]),\n","            nn.ReLU(),\n","            Conv2dResize(in_size=[x_hidden_channels, H_x//2, W_x//2], out_size=[x_hidden_channels, H_x//4, W_x//4]),\n","            nn.ReLU(),\n","            Conv2dResize(in_size=[x_hidden_channels, H_x//4, W_x//4], out_size=[x_hidden_channels, H_x//8, W_x//8]),\n","            nn.ReLU()\n","        )\n","\n","        self.x_Linear = nn.Sequential(\n","            LinearZeros(x_hidden_channels*H_x*W_x//(8*8), x_hidden_size),\n","            nn.ReLU(),\n","            LinearZeros(x_hidden_size, x_hidden_size),\n","            nn.ReLU(),\n","            LinearZeros(x_hidden_size, 2*y_channels),\n","            nn.Tanh()\n","        )\n","\n","\n","    def forward(self, x, y, logdet=0, reverse=False):\n","\n","        B,C,H,W = x.size()\n","\n","        # generate weights\n","        x = self.x_Con(x)\n","        x = x.view(B, -1)\n","        x = self.x_Linear(x)\n","        x = x.view(B, -1, 1, 1)\n","\n","\n","        logs, bias = split_feature(x)\n","        dimentions = y.size(2) * y.size(3)\n","\n","\n","        if not reverse:\n","            # center and scale\n","            y = y + bias\n","            y = y * torch.exp(logs)\n","            dlogdet = dimentions * torch.sum(logs, dim=(1,2,3))\n","            logdet = logdet + dlogdet\n","        else:\n","            # scale and center\n","            y = y * torch.exp(-logs)\n","            y = y - bias\n","            dlogdet = - dimentions * torch.sum(logs, dim=(1,2,3))\n","            logdet = logdet + dlogdet\n","\n","        return y, logdet\n","\n","\n","\n","class Cond1x1Conv(nn.Module):\n","\n","    def __init__(self, x_size, x_hidden_channels, x_hidden_size, y_channels):\n","\n","        super().__init__()\n","\n","        C_x,H_x,W_x = x_size\n","\n","\n","        # conditioning network\n","        self.x_Con = nn.Sequential(\n","            Conv2dResize(in_size=[C_x,H_x,W_x], out_size=[x_hidden_channels, H_x//2, W_x//2]),\n","            nn.ReLU(),\n","            Conv2dResize(in_size=[x_hidden_channels, H_x//2, W_x//2], out_size=[x_hidden_channels, H_x//4, W_x//4]),\n","            nn.ReLU(),\n","            Conv2dResize(in_size=[x_hidden_channels, H_x//4, W_x//4], out_size=[x_hidden_channels, H_x//8, W_x//8]),\n","            nn.ReLU()\n","        )\n","\n","        self.x_Linear = nn.Sequential(\n","            LinearZeros(x_hidden_channels*H_x*W_x//(8*8), x_hidden_size),\n","            nn.ReLU(),\n","            LinearZeros(x_hidden_size, x_hidden_size),\n","            nn.ReLU(),\n","            LinearNorm(x_hidden_size, y_channels*y_channels),\n","            nn.Tanh()\n","        )\n","\n","\n","    def get_weight(self, x, y, reverse):\n","        y_channels = y.size(1)\n","        B,C,H,W = x.size()\n","\n","        x = self.x_Con(x)\n","        x = x.view(B, -1)\n","        x = self.x_Linear(x)\n","        weight = x.view(B, y_channels, y_channels)\n","\n","        dimensions = y.size(2) * y.size(3)\n","        dlogdet = torch.slogdet(weight)[1] * dimensions\n","\n","\n","        if reverse == False:\n","            weight = weight.view(B, y_channels, y_channels,1,1)\n","\n","        else:\n","            weight = torch.inverse(weight.double()).float().view(B, y_channels, y_channels,1,1)\n","\n","        return weight, dlogdet\n","\n","\n","\n","    def forward(self, x, y, logdet=None, reverse=False):\n","\n","        weight, dlogdet = self.get_weight(x, y, reverse)\n","        B,C,H,W = y.size()\n","        y = y.view(1, B*C, H, W)\n","        B_k, C_i_k, C_o_k, H_k, W_k = weight.size()\n","        assert B == B_k and C == C_i_k and C == C_o_k, \"The input and kernel dimensions are different\"\n","        weight = weight.reshape(B_k*C_i_k,C_o_k,H_k,W_k)\n","\n","        if reverse == False:\n","            z = F.conv2d(y, weight, groups=B)\n","            z = z.view(B,C,H,W)\n","            if logdet is not None:\n","                logdet = logdet + dlogdet\n","\n","            return z, logdet\n","        else:\n","            z = F.conv2d(y, weight, groups=B)\n","            z = z.view(B,C,H,W)\n","\n","            if logdet is not None:\n","                logdet = logdet - dlogdet\n","\n","            return z, logdet\n","\n","\n","class Conv2dNormy(nn.Conv2d):\n","\n","    def __init__(self, in_channels, out_channels,\n","                 kernel_size=[3, 3], stride=[1, 1]):\n","        padding = [(kernel_size[0]-1)//2, (kernel_size[1]-1)//2]\n","        super().__init__(in_channels, out_channels, kernel_size, stride,\n","                         padding, bias=False)\n","\n","        #initialize weight\n","        self.weight.data.normal_(mean=0.0, std=0.05)\n","        self.actnorm = ActNorm(out_channels)\n","\n","\n","    def forward(self, input):\n","        x = super().forward(input)\n","        x,_ = self.actnorm(x)\n","        return x\n","\n","\n","class Conv2dZerosy(nn.Conv2d):\n","\n","    def __init__(self, in_channels, out_channels,\n","                 kernel_size=[3, 3], stride=[1, 1]):\n","\n","        padding = [(kernel_size[0]-1)//2, (kernel_size[1]-1)//2]\n","        super().__init__(in_channels, out_channels, kernel_size, stride, padding)\n","\n","        self.logscale_factor = 3.0\n","        self.register_parameter(\"logs\", nn.Parameter(torch.zeros(out_channels, 1, 1)))\n","        self.register_parameter(\"newbias\", nn.Parameter(torch.zeros(out_channels, 1, 1)))\n","\n","        # init\n","        self.weight.data.zero_()\n","        self.bias.data.zero_()\n","\n","    def forward(self, input):\n","        output = super().forward(input)\n","        output = output + self.newbias\n","        output = output * torch.exp(self.logs * self.logscale_factor)\n","        return output\n","\n","\n","\n","\n","class CondAffineCoupling(nn.Module):\n","\n","    def __init__(self, x_size, y_size, hidden_channels):\n","        super().__init__()\n","\n","\n","\n","        self.resize_x = nn.Sequential(\n","            Conv2dZeros(x_size[0], 16),\n","            nn.ReLU(),\n","            Conv2dResize((16,x_size[1],x_size[2]), out_size=y_size),\n","            nn.ReLU(),\n","            Conv2dZeros(y_size[0], y_size[0]),\n","            nn.ReLU()\n","        )\n","\n","        self.f = nn.Sequential(\n","            Conv2dNormy(y_size[0]*2, hidden_channels),\n","            nn.ReLU(),\n","            Conv2dNormy(hidden_channels, hidden_channels, kernel_size=[1, 1]),\n","            nn.ReLU(),\n","            Conv2dZerosy(hidden_channels, 2*y_size[0]),\n","            nn.Tanh()\n","        )\n","\n","\n","    def forward(self, x, y, logdet=0.0, reverse=False):\n","\n","        z1, z2 = split_feature(y, \"split\")\n","        x = self.resize_x(x)\n","\n","        h = torch.cat((x,z1), dim=1)\n","        h = self.f(h)\n","        shift, scale = split_feature(h, \"cross\")\n","        scale = torch.sigmoid(scale + 2.)\n","        if reverse == False:\n","            z2 = z2 + shift\n","            z2 = z2 * scale\n","            logdet = torch.sum(torch.log(scale), dim=(1, 2, 3)) + logdet\n","\n","        if reverse == True:\n","            z2 = z2 / scale\n","            z2 = z2 - shift\n","            logdet = -torch.sum(torch.log(scale), dim=(1, 2, 3)) + logdet\n","\n","        z = torch.cat((z1, z2), dim=1)\n","\n","        return z, logdet\n","\n","\n","\n","class SqueezeLayer(nn.Module):\n","    def __init__(self, factor):\n","        super().__init__()\n","        self.factor = factor\n","\n","    def forward(self, input, logdet=None, reverse=False):\n","        if not reverse:\n","            output = SqueezeLayer.squeeze2d(input, self.factor)\n","            return output, logdet\n","        else:\n","            output = SqueezeLayer.unsqueeze2d(input, self.factor)\n","            return output, logdet\n","\n","\n","    @staticmethod\n","    def squeeze2d(input, factor=2):\n","        assert factor >= 1 and isinstance(factor, int)\n","        if factor == 1:\n","            return input\n","        B, C, H, W = input.size()\n","        assert H % factor == 0 and W % factor == 0, \"{}\".format((H, W))\n","        x = input.view(B, C, H // factor, factor, W // factor, factor)\n","        x = x.permute(0, 1, 3, 5, 2, 4).contiguous()\n","        x = x.view(B, C * factor * factor, H // factor, W // factor)\n","        return x\n","\n","\n","    @staticmethod\n","    def unsqueeze2d(input, factor=2):\n","        assert factor >= 1 and isinstance(factor, int)\n","        factor2 = factor ** 2\n","        if factor == 1:\n","            return input\n","        B, C, H, W = input.size()\n","        assert C % (factor2) == 0, \"{}\".format(C)\n","        x = input.view(B, C // factor2, factor, factor, H, W)\n","        x = x.permute(0, 1, 4, 2, 5, 3).contiguous()\n","        x = x.view(B, C // (factor2), H * factor, W * factor)\n","        return x\n","\n","\n","class Split2d(nn.Module):\n","    def __init__(self, num_channels):\n","        super().__init__()\n","\n","        self.conv = nn.Sequential(\n","            Conv2dZeros(num_channels // 2, num_channels),\n","            nn.Tanh()\n","        )\n","\n","    def split2d_prior(self, z):\n","        h = self.conv(z)\n","        return split_feature(h, \"cross\")\n","\n","    def forward(self, input, logdet=0., reverse=False, eps_std=None):\n","        if not reverse:\n","            z1, z2 = split_feature(input, \"split\")\n","            mean, logs = self.split2d_prior(z1)\n","            logdet = GaussianDiag.logp(mean, logs, z2) + logdet\n","\n","            return z1, logdet\n","        else:\n","            z1 = input\n","            mean, logs = self.split2d_prior(z1)\n","            z2 = GaussianDiag.sample(mean, logs, eps_std)\n","            z = torch.cat((z1, z2), dim=1)\n","\n","            return z, logdet\n","\n","\n","class GaussianDiag:\n","    Log2PI = float(np.log(2 * np.pi))\n","\n","    @staticmethod\n","    def likelihood(mean, logs, x):\n","        return -0.5 * (logs * 2. + ((x - mean) ** 2.) / torch.exp(logs * 2.) + GaussianDiag.Log2PI)\n","\n","    @staticmethod\n","    def logp(mean, logs, x):\n","        likelihood = GaussianDiag.likelihood(mean, logs, x)\n","        return torch.sum(likelihood, dim=(1, 2, 3))\n","\n","    @staticmethod\n","    def sample(mean, logs, eps_std=None):\n","        eps_std = eps_std or 1\n","        eps = torch.normal(mean=torch.zeros_like(mean),\n","                           std=torch.ones_like(logs) * eps_std)\n","        return mean + torch.exp(logs) * eps\n","\n","    @staticmethod\n","    def batchsample(batchsize, mean, logs, eps_std=None):\n","        eps_std = eps_std or 1\n","        sample = GaussianDiag.sample(mean, logs, eps_std)\n","        for i in range(1, batchsize):\n","            s = GaussianDiag.sample(mean, logs, eps_std)\n","            sample = torch.cat((sample, s), dim=0)\n","        return sample\n","\n","\n","\n","class LinearZeros(nn.Linear):\n","\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__(in_channels, out_channels)\n","        self.weight.data.zero_()\n","        self.bias.data.zero_()\n","\n","    def forward(self, input):\n","        output = super().forward(input)\n","        return output\n","\n","\n","class LinearNorm(nn.Linear):\n","\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__(in_channels, out_channels)\n","        self.weight.data.normal_(mean=0.0, std=0.1)\n","        self.bias.data.normal_(mean=0.0, std=0.1)\n"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"nAdwr1f0ZP3Z","executionInfo":{"status":"ok","timestamp":1692391145373,"user_tz":240,"elapsed":5,"user":{"displayName":"Joseph Lupo","userId":"18192058496751055649"}}},"outputs":[],"source":["# @title Glow Model\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","\n","class CondGlowStep(nn.Module):\n","\n","    def __init__(self, x_size, y_size, x_hidden_channels, x_hidden_size, y_hidden_channels):\n","\n","\n","        super().__init__()\n","\n","        # 1. cond-actnorm\n","        self.actnorm = CondActNorm(x_size=x_size, y_channels=y_size[0], x_hidden_channels=x_hidden_channels, x_hidden_size=x_hidden_size)\n","\n","        # 2. cond-1x1conv\n","        self.invconv = Cond1x1Conv(x_size=x_size, x_hidden_channels=x_hidden_channels, x_hidden_size=x_hidden_size, y_channels=y_size[0])\n","\n","        # 3. cond-affine\n","        self.affine = CondAffineCoupling(x_size=x_size, y_size=[y_size[0] // 2, y_size[1], y_size[2]], hidden_channels=y_hidden_channels)\n","\n","\n","    def forward(self, x, y, logdet=None, reverse=False):\n","\n","        if reverse is False:\n","            # 1. cond-actnorm\n","            y, logdet = self.actnorm(x, y, logdet, reverse=False)\n","\n","            # 2. cond-1x1conv\n","            y, logdet = self.invconv(x, y, logdet, reverse=False)\n","\n","            # 3. cond-affine\n","            y, logdet = self.affine(x, y, logdet, reverse=False)\n","\n","            # Return\n","            return y, logdet\n","\n","\n","        if reverse is True:\n","            # 3. cond-affine\n","            y, logdet = self.affine(x, y, logdet, reverse=True)\n","\n","            # 2. cond-1x1conv\n","            y, logdet = self.invconv(x, y, logdet, reverse=True)\n","\n","            # 1. cond-actnorm\n","            y, logdet = self.actnorm(x, y, logdet, reverse=True)\n","\n","            # Return\n","            return y, logdet\n","\n","\n","class CondGlow(nn.Module):\n","\n","    def __init__(self, x_size, y_size, x_hidden_channels, x_hidden_size, y_hidden_channels, K, L):\n","\n","\n","        super().__init__()\n","        self.layers = nn.ModuleList()\n","        self.output_shapes = []\n","        self.K = K\n","        self.L = L\n","        C, H, W = y_size\n","\n","        for l in range(0, L):\n","\n","            # 1. Squeeze\n","            C, H, W = C * 4, H // 2, W // 2\n","            y_size = [C,H,W]\n","            self.layers.append(SqueezeLayer(factor=2))\n","            self.output_shapes.append([-1, C, H, W])\n","\n","            # 2. K CGlowStep\n","            for k in range(0, K):\n","\n","                self.layers.append(CondGlowStep(x_size = x_size,\n","                                            y_size = y_size,\n","                                            x_hidden_channels = x_hidden_channels,\n","                                            x_hidden_size = x_hidden_size,\n","                                            y_hidden_channels = y_hidden_channels,\n","                                            )\n","                                   )\n","\n","                self.output_shapes.append([-1, C, H, W])\n","\n","            # 3. Split\n","            if l < L - 1:\n","                self.layers.append(Split2d(num_channels=C))\n","                self.output_shapes.append([-1, C // 2, H, W])\n","                C = C // 2\n","\n","\n","    def forward(self, x, y, logdet=0.0, reverse=False, eps_std=1.0):\n","        if reverse == False:\n","            return self.encode(x, y, logdet)\n","        else:\n","            return self.decode(x, y, logdet, eps_std)\n","\n","    def encode(self, x, y, logdet=0.0):\n","        for layer, shape in zip(self.layers, self.output_shapes):\n","            if isinstance(layer, Split2d) or isinstance(layer, SqueezeLayer):\n","                y, logdet = layer(y, logdet, reverse=False)\n","\n","            else:\n","                y, logdet = layer(x, y, logdet, reverse=False)\n","        return y, logdet\n","\n","    def decode(self, x, y, logdet=0.0, eps_std=1.0):\n","        for layer in reversed(self.layers):\n","            if isinstance(layer, Split2d):\n","                y, logdet = layer(y, logdet=logdet, reverse=True, eps_std=eps_std)\n","\n","            elif isinstance(layer, SqueezeLayer):\n","                y, logdet = layer(y, logdet=logdet, reverse=True)\n","\n","            else:\n","                y, logdet = layer(x, y, logdet=logdet, reverse=True)\n","\n","        return y, logdet\n","\n","\n","class CondGlowModel(nn.Module):\n","    BCE = nn.BCEWithLogitsLoss()\n","    CE = nn.CrossEntropyLoss()\n","\n","    def __init__(self, args):\n","        super().__init__()\n","        self.flow = CondGlow(x_size=args.x_size,\n","                            y_size=args.y_size,\n","                            x_hidden_channels=args.x_hidden_channels,\n","                            x_hidden_size=args.x_hidden_size,\n","                            y_hidden_channels=args.y_hidden_channels,\n","                            K=args.depth_flow,\n","                            L=args.num_levels,\n","                            )\n","\n","        self.learn_top = args.learn_top\n","\n","\n","        self.register_parameter(\"new_mean\",\n","                                nn.Parameter(torch.zeros(\n","                                    [1,\n","                                     self.flow.output_shapes[-1][1],\n","                                     self.flow.output_shapes[-1][2],\n","                                     self.flow.output_shapes[-1][3]])))\n","\n","\n","        self.register_parameter(\"new_logs\",\n","                                nn.Parameter(torch.zeros(\n","                                    [1,\n","                                     self.flow.output_shapes[-1][1],\n","                                     self.flow.output_shapes[-1][2],\n","                                     self.flow.output_shapes[-1][3]])))\n","\n","        self.n_bins = args.y_bins\n","\n","\n","    def prior(self):\n","\n","        if self.learn_top:\n","            return self.new_mean, self.new_logs\n","        else:\n","            return torch.zeros_like(self.new_mean), torch.zeros_like(self.new_mean)\n","\n","\n","    def forward(self, x=0.0, y=None, eps_std=1.0, reverse=False):\n","        if reverse == False:\n","            dimensions = y.size(1)*y.size(2)*y.size(3)\n","            logdet = torch.zeros_like(y[:, 0, 0, 0])\n","            logdet += float(-np.log(self.n_bins) * dimensions)\n","            z, objective = self.flow(x, y, logdet=logdet, reverse=False)\n","            mean, logs = self.prior()\n","            objective += GaussianDiag.logp(mean, logs, z)\n","            nll = -objective / float(np.log(2.) * dimensions)\n","            return z, nll\n","\n","        else:\n","            with torch.no_grad():\n","                mean, logs = self.prior()\n","                if y is None:\n","                    y = GaussianDiag.batchsample(x.size(0), mean, logs, eps_std)\n","                y, logdet = self.flow(x, y, eps_std=eps_std, reverse=True)\n","            return y, logdet"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"Vj8Wsh_8ZP6B","executionInfo":{"status":"ok","timestamp":1692391145373,"user_tz":240,"elapsed":4,"user":{"displayName":"Joseph Lupo","userId":"18192058496751055649"}}},"outputs":[],"source":["# @title Learner\n","import os\n","import torch\n","import datetime\n","import numpy as np\n","from torch.utils.data import DataLoader\n","import time\n","# from datasets import convert_to_img\n","# from datasets import preprocess\n","# from datasets import postprocess\n","from torchvision.utils import save_image\n","\n","\n","class Trainer(object):\n","\n","    def __init__(self, graph, optim, scheduler, trainingset, validset, args, cuda):\n","\n","        # set path and date\n","        date = str(datetime.datetime.now())\n","        date = date[:date.rfind(\":\")].replace(\"-\", \"\")\\\n","                                     .replace(\":\", \"\")\\\n","                                     .replace(\" \", \"_\")\n","        self.log_dir = os.path.join(args.log_root, \"log_\" + date)\n","        if not os.path.exists(self.log_dir):\n","            os.makedirs(self.log_dir)\n","\n","\n","        self.checkpoints_dir = os.path.join(self.log_dir, \"checkpoints\")\n","        if not os.path.exists(self.checkpoints_dir):\n","            os.makedirs(self.checkpoints_dir)\n","\n","        self.images_dir = os.path.join(self.log_dir, \"images\")\n","        if not os.path.exists(self.images_dir):\n","            os.makedirs(self.images_dir)\n","\n","        self.valid_samples_dir = os.path.join(self.log_dir, \"valid_samples\")\n","        if not os.path.exists(self.valid_samples_dir):\n","            os.makedirs(self.valid_samples_dir)\n","\n","\n","\n","        # model\n","        self.graph = graph\n","        self.optim = optim\n","        self.scheduler = scheduler\n","\n","        # gradient bound\n","        self.max_grad_clip = args.max_grad_clip\n","        self.max_grad_norm = args.max_grad_norm\n","\n","        # data\n","        self.dataset_name = args.dataset_name\n","        self.batch_size = args.batch_size\n","        self.trainingset_loader = DataLoader(trainingset,\n","                                      batch_size=self.batch_size,\n","                                      shuffle=True,\n","                                      drop_last=True)\n","\n","        self.validset_loader = DataLoader(validset,\n","                                      batch_size=self.batch_size,\n","                                      shuffle=False,\n","                                      drop_last=False)\n","\n","        self.num_epochs = args.num_epochs\n","        self.global_step = args.num_steps\n","        self.label_scale = args.label_scale\n","        self.label_bias = args.label_bias\n","        self.x_bins = args.x_bins\n","        self.y_bins = args.y_bins\n","\n","\n","        self.num_epochs = args.num_epochs\n","        self.nll_gap = args.nll_gap\n","        self.inference_gap = args.inference_gap\n","        self.checkpoints_gap = args.checkpoints_gap\n","        self.save_gap = args.save_gap\n","\n","        # device\n","        self.cuda = cuda\n","\n","    def validate(self):\n","        print (\"Start Validating\")\n","        self.graph.eval()\n","        mean_loss = list()\n","        samples = list()\n","        with torch.no_grad():\n","            for i_batch, batch in enumerate(self.validset_loader):\n","                x = batch[\"x\"]\n","                y = batch[\"y\"]\n","\n","                if self.cuda:\n","                    x = x.cuda()\n","                    y = y.cuda()\n","\n","                y = preprocess(y, self.label_scale, self.label_bias, self.y_bins, True)\n","\n","\n","                # forward\n","                z, nll = self.graph(x,y)\n","                loss = torch.mean(nll)\n","                mean_loss.append(loss.data.cpu().item())\n","\n","                # true label\n","                y_true, _ = convert_to_img(postprocess(y, self.label_scale, self.label_bias))\n","\n","                # sample\n","                batch_samples = []\n","                for b in range(len(y)):\n","                    row = []\n","                    row.append(y_true[b])\n","                    batch_samples.append(row)\n","                for i in range(0, 5):\n","                    y_sample,_ = self.graph(x, y=None, reverse=True)\n","                    y_sample = postprocess(y_sample, self.label_scale, self.label_bias)\n","                    y_sample, _ = convert_to_img(y_sample)\n","\n","                    for b in range(len(y)):\n","                        batch_samples[b].append(y_sample[b])\n","\n","                for b in range(len(y)):\n","                    samples.append(batch_samples[b])\n","\n","        # save samples\n","        output = None\n","        for i in range(0, len(samples)):\n","            row = None\n","            for b in range(0,len(samples[i])):\n","                if row is None:\n","                    row = samples[i][b]\n","                else:\n","                    row = torch.cat((row, samples[i][b]), dim=2)\n","\n","            if output is None:\n","                output = row\n","            else:\n","                output = torch.cat((output, row),dim=1)\n","\n","        save_image(output, os.path.join(self.valid_samples_dir, \"img-{}.png\".format(self.global_step)))\n","\n","        # save loss\n","        mean = np.mean(mean_loss)\n","        with open(os.path.join(self.log_dir, \"valid_NLL.txt\"), \"a\") as nll_file:\n","            nll_file.write(str(self.global_step) + \"\\t\" + \"{:.5f}\".format(mean) + \"\\n\")\n","        print (\"Finish Validating\")\n","        self.graph.train()\n","\n","\n","    def train(self):\n","\n","        self.graph.train()\n","\n","        starttime = time.time()\n","\n","        # run\n","        num_batchs = len(self.trainingset_loader)\n","        total_its = self.num_epochs * num_batchs\n","        for epoch in range(self.num_epochs):\n","            mean_nll = 0.0\n","            for _, batch in enumerate(self.trainingset_loader):\n","                self.optim.zero_grad()\n","\n","                x = batch[\"x\"]\n","                y = batch[\"y\"]\n","\n","\n","                if self.cuda:\n","                    x = x.cuda()\n","                    y = y.cuda()\n","\n","                processed_y = preprocess(y, self.label_scale, self.label_bias, self.y_bins, True)\n","                processed_x = preprocess(x, 1.0, 0.0, self.x_bins, True)\n","\n","\n","                # forward\n","                z, nll = self.graph(processed_x, processed_y)\n","\n","\n","                # loss\n","                loss = torch.mean(nll)\n","                mean_nll = mean_nll + loss.data\n","\n","                # backward\n","                self.graph.zero_grad()\n","                self.optim.zero_grad()\n","                loss.backward()\n","\n","                # operate grad\n","                if self.max_grad_clip > 0:\n","                    torch.nn.utils.clip_grad_value_(self.graph.parameters(), self.max_grad_clip)\n","                if self.max_grad_norm > 0:\n","                    torch.nn.utils.clip_grad_norm_(self.graph.parameters(), self.max_grad_norm)\n","\n","                # step\n","                self.optim.step()\n","\n","                currenttime = time.time()\n","                elapsed = currenttime - starttime\n","                print(\"Iteration: {}/{} \\t Elapsed time: {:.2f} \\t Loss:{:.5f}\".format(self.global_step, total_its, elapsed, loss.data))\n","\n","                if self.global_step % self.nll_gap == 0:\n","                    with open(os.path.join(self.log_dir, \"NLL.txt\"), \"a\") as nll_file:\n","                        nll_file.write(str(self.global_step) + \" \\t \" + \"{:.2f} \\t {:.5f}\".format(elapsed, loss.data) + \"\\n\")\n","\n","\n","\n","                # checkpoint\n","                if self.global_step % self.checkpoints_gap == 0 and self.global_step > 0:\n","                    self.validate()\n","\n","                    # samples\n","                    samples = []\n","                    for b in range(min(2, self.batch_size)):\n","                        samples.append([])\n","\n","                    for i in range(0,5):\n","                        y_sample,_ = self.graph(x, y=None, reverse=True)\n","                        y_sample = postprocess(y_sample, self.label_scale, self.label_bias)\n","                        y_sample, _ = convert_to_img(y_sample)\n","                        for b in range(self.batch_size):\n","                            samples[b].append(y_sample[b])\n","\n","                    # inverse image\n","                    y_inverse,_ = self.graph(processed_x, y=z, reverse=True)\n","                    y_inverse = postprocess(y_inverse, self.label_scale, self.label_bias)\n","                    y_inverse, _ = convert_to_img(y_inverse)\n","\n","                    # true label\n","                    y_true, _ = convert_to_img(y)\n","\n","\n","                    # save images\n","                    output = None\n","                    for b in range(0, self.batch_size):\n","                        row = torch.cat((y_true[b], y_inverse[b]), dim=2)\n","                        for i in range(0, len(samples[b])):\n","                            row = torch.cat((row, samples[b][i]),dim=2)\n","                        if output is None:\n","                            output = row\n","                        else:\n","                            output = torch.cat((output, row), dim=1)\n","\n","                    save_image(output, os.path.join(self.images_dir, \"img-{}.png\".format(self.global_step)))\n","\n","\n","\n","\n","                # save model\n","                if self.global_step % self.save_gap == 0 and self.global_step > 0:\n","                    save_model(self.graph, self.optim, self.scheduler, self.checkpoints_dir, self.global_step)\n","\n","\n","                self.global_step = self.global_step + 1\n","\n","            if self.scheduler is not None:\n","                self.scheduler.step()\n","            mean_nll = float(mean_nll / float(num_batchs))\n","            with open(os.path.join(self.log_dir, \"Epoch_NLL.txt\"), \"a\") as f:\n","                currenttime = time.time()\n","                elapsed = currenttime - starttime\n","                f.write(\"{} \\t {:.2f}\\t {:.5f}\".format(epoch, elapsed, mean_nll) + \"\\n\")\n","\n","\n","\n","\n","class Inferencer(object):\n","\n","    def __init__(self, model, dataset, args, cuda):\n","\n","        # set path and date\n","        self.out_root = args.out_root\n","        if not os.path.exists(self.out_root):\n","            os.makedirs(self.out_root)\n","\n","        # cuda\n","        self.cuda = cuda\n","\n","        # model\n","        self.model = model\n","\n","\n","        # data\n","        self.dataset_name = args.dataset_name\n","        self.batch_size = args.batch_size\n","        self.data_loader = DataLoader(dataset,\n","                                      batch_size=self.batch_size,\n","                                      shuffle=False,\n","                                      drop_last=False)\n","\n","        self.label_scale = args.label_scale\n","        self.label_bias = args.label_bias\n","        self.num_labels = args.num_labels\n","\n","\n","    def sampled_based_prediction(self, n_samples):\n","        metrics = []\n","        start = time.time()\n","        for i_batch, batch in enumerate(self.data_loader):\n","            print(f\"Batch IDs: {i_batch}\")\n","\n","            x = batch[\"x\"]\n","            y = batch[\"y\"]\n","\n","            if self.cuda:\n","                x = x.cuda()\n","                y = y.cuda()\n","\n","            sample_list = list()\n","            nll_list = list()\n","            for i in range(0, n_samples):\n","\n","                print(f\"Samples: {i}/{n_samples}\")\n","\n","                y_sample,_ = self.model(x, reverse=True)\n","                _, nll = self.model(x,y_sample)\n","                loss = torch.mean(nll)\n","                sample_list.append(y_sample)\n","                nll_list.append(loss.data.cpu().numpy())\n","\n","            sample = torch.stack(sample_list)\n","            sample = torch.mean(sample, dim=0, keepdim=False)\n","            nll = np.mean(nll_list)\n","\n","\n","            sample = postprocess(sample, self.label_scale, self.label_bias)\n","\n","            y_pred_imgs, y_pred_seg = convert_to_img(sample)\n","            y_true_imgs, y_true_seg = convert_to_img(y)\n","\n","\n","\n","            # save trues and preds\n","            output = None\n","            for i in range(0, len(y_true_imgs)):\n","                true_img = y_true_imgs[i]\n","                pred_img = y_pred_imgs[i]\n","                row = torch.cat((x[i].cpu(), true_img, pred_img), dim=1)\n","                if output is None:\n","                    output = row\n","                else:\n","                    output = torch.cat((output,row), dim=2)\n","            save_image(output, os.path.join(self.out_root, \"trues-{}.png\".format(i_batch)))\n","\n","            acc, acc_cls, mean_iu, fwavacc = compute_accuracy(y_true_seg, y_pred_seg, self.num_labels)\n","\n","\n","            with open(os.path.join(self.out_root, \"meta_list.txt\"), \"a\") as meta_file:\n","                meta_file.write(\"NLL: {:.5f}\".format(nll) + \"\\t\")\n","                meta_file.write(\"acc: {:.8f}\".format(acc) + \"\\t\")\n","                meta_file.write(\"acc_cls: {:.8f}\".format(acc_cls) + \"\\t\")\n","                meta_file.write(\"mean_iu: {:.8f}\".format(mean_iu) + \"\\t\")\n","                meta_file.write(\"fwavacc: {:.8f}\".format(fwavacc) + \"\\t\")\n","                meta_file.write(\"\\n\")\n","\n","\n","            metrics.append([acc, acc_cls, mean_iu, fwavacc])\n","        mean_metrics = np.mean(metrics, axis=0)\n","\n","        finish = time.time()\n","        elapsed = finish - start\n","\n","        with open(os.path.join(self.out_root, \"sum_meta.txt\"), \"w\") as meta_file:\n","            meta_file.write(\"time:{:.2f}\".format(elapsed) + \"\\t\")\n","            meta_file.write(\"acc: {:.8f}\".format(mean_metrics[0]) + \"\\t\")\n","            meta_file.write(\"acc_cls: {:.8f}\".format(mean_metrics[1]) + \"\\t\")\n","            meta_file.write(\"mean_iu: {:.8f}\".format(mean_metrics[2]) + \"\\t\")\n","            meta_file.write(\"fwavacc: {:.8f}\".format(mean_metrics[3]) + \"\\t\")"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"PCUq2ZvXaCKA","executionInfo":{"status":"ok","timestamp":1692391145373,"user_tz":240,"elapsed":4,"user":{"displayName":"Joseph Lupo","userId":"18192058496751055649"}}},"outputs":[],"source":["# @title Datasets\n","import os\n","import numpy as np\n","import torch\n","import PIL.Image as Image\n","from torch.utils import data\n","import torchvision.transforms as transforms\n","\n","\n","\n","def preprocess(x, scale, bias, bins, noise=False):\n","\n","    x = x / scale\n","    x = x - bias\n","\n","    if noise == True:\n","        if bins == 2:\n","            x = x + torch.zeros_like(x).uniform_(-0.5, 0.5)\n","        else:\n","            x = x + torch.zeros_like(x).uniform_(0, 1/bins)\n","    return x\n","\n","\n","def postprocess(x, scale, bias):\n","\n","    x = x + bias\n","    x = x * scale\n","    return x\n","\n","\n","def convert_to_img(y):\n","    import skimage.color\n","    import skimage.util\n","    import skimage.io\n","\n","    C = y.size(1)\n","\n","    transform = transforms.ToTensor()\n","    colors = np.array([[0,0,0],[255,255,255]])/255\n","\n","    if C == 1:\n","        seg = torch.squeeze(y, dim=1).cpu().numpy()\n","        seg = np.nan_to_num(seg)\n","        seg = np.clip(np.round(seg),a_min=0, a_max=1)\n","\n","    if C > 1:\n","        seg = torch.mean(y, dim=1, keepdim=False).cpu().numpy()\n","        seg = np.nan_to_num(seg)\n","        seg = np.clip(np.round(seg),a_min=0, a_max=1)\n","\n","    B,C,H,W = y.size()\n","    imgs = list()\n","    for i in range(B):\n","        label_i = skimage.color.label2rgb(seg[i], colors=colors)\n","        label_i = skimage.util.img_as_ubyte(label_i)\n","        imgs.append(transform(label_i))\n","    return imgs, seg\n","\n","\n","class HorseDataset(data.Dataset):\n","\n","    def __init__(self, dir, size, n_c, portion=\"train\"):\n","        self.dir = dir\n","        self.names = self.read_names(dir, portion)\n","        self.n_c = n_c\n","        self.size = size\n","\n","    def read_names(self, dir, portion):\n","\n","        path = os.path.join(dir, \"{}.txt\".format(portion))\n","        names = list()\n","        with open(path, \"r\") as f:\n","            for line in f:\n","                line = line.strip()\n","                name = {}\n","                name[\"img\"] = os.path.join(dir, os.path.join(\"images\", line))\n","                name[\"lbl\"] = os.path.join(dir, os.path.join(\"labels\", line))\n","                names.append(name)\n","        return names\n","\n","    def __len__(self):\n","        return len(self.names)\n","\n","\n","    def __getitem__(self, index):\n","\n","        # path\n","        name = self.names[index]\n","        img_path = name[\"img\"]\n","        lbl_path = name[\"lbl\"]\n","        transform = transforms.Compose([transforms.Resize(self.size), transforms.ToTensor()])\n","\n","        # img\n","        img = Image.open(img_path).convert(\"RGB\")\n","        img = transform(img)\n","\n","        # lbl\n","        lbl = Image.open(lbl_path).convert(\"L\")\n","        lbl = transform(lbl)\n","        lbl = torch.round(lbl)\n","        if self.n_c > 1:\n","            lbl = lbl.repeat(self.n_c,1,1)\n","\n","        return {\"x\":img, \"y\":lbl}"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":323101,"status":"ok","timestamp":1692391468471,"user":{"displayName":"Joseph Lupo","userId":"18192058496751055649"},"user_tz":240},"id":"ZaCPtC4urjVC","outputId":"20a4678f-2722-4660-95ae-4f73739d4118"},"outputs":[{"output_type":"stream","name":"stdout","text":["327\n"]}],"source":["# @title Horses Dataset\n","import os\n","from PIL import Image\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","\n","class WeizmannHorseDataset(Dataset):\n","    def __init__(self, root_dir, transform=None, target_transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.target_transform=target_transform\n","        self.classes = sorted(os.listdir(os.path.join(root_dir, \"horse\")))\n","\n","        self.data = []\n","        self.labels = []\n","\n","        for class_idx, class_name in enumerate(self.classes):\n","            # print(class_idx)\n","            horse_img_path = os.path.join(self.root_dir, \"horse\", class_name)\n","            mask_img_path = os.path.join(self.root_dir, \"mask\", class_name)\n","\n","            horse_image = Image.open(horse_img_path).convert('RGB')\n","            mask_image = Image.open(mask_img_path).convert('L')\n","\n","            self.data.extend([horse_image])\n","            self.labels.extend([mask_image])\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        # horse_img_path, mask_img_path = self.data[idx], self.labels[idx]\n","        # label = self.labels[idx]\n","        # horse_image = Image.open(horse_img_path).convert('RGB')\n","        # mask_image = Image.open(mask_img_path).convert('L')\n","\n","        horse_image = self.data[idx]\n","        mask_image = self.labels[idx]\n","\n","        if self.transform:\n","            horse_image = self.transform(horse_image)\n","        if self.target_transform:\n","            mask_image = self.target_transform(mask_image)\n","\n","        # return horse_image, mask_image\n","        return {\"x\":horse_image, \"y\":mask_image}\n","\n","\n","# Define the path to your dataset folder\n","dataset_root = '/content/gdrive/MyDrive/Projects/TESS/model_conditional_norm_flow_horses/weizmann_horse_db/'\n","\n","# Define any image transformations you want to apply (resize, normalization, etc.)\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","target_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.456], std=[0.225])\n","])\n","\n","# Create the dataset\n","weizmann_dataset = WeizmannHorseDataset(root_dir=dataset_root, transform=transform, target_transform=target_transform)\n","print(len(weizmann_dataset))\n","# print(weizmann_dataset.data[0])\n","\n","\n","# # Create a DataLoader for batching and shuffling\n","# batch_size = 32\n","# dataloader = DataLoader(weizmann_dataset, batch_size=batch_size, shuffle=True)\n","\n","# # Now you can iterate through the dataloader to get batches of data\n","# for horses, masks, labels in dataloader:\n","#     # Use the horses, masks, and labels for training/validation\n","#     pass\n"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"YXUnTo1hyCsd","executionInfo":{"status":"ok","timestamp":1692391468471,"user_tz":240,"elapsed":14,"user":{"displayName":"Joseph Lupo","userId":"18192058496751055649"}}},"outputs":[],"source":["# @title TESS Dataset\n","import os\n","from PIL import Image\n","import torch\n","import pickle\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","\n","class TESSDataset(Dataset):\n","    def __init__(self):\n","\n","        # self.data = []\n","        # self.labels = []\n","\n","        # get data\n","        angle_folder = \"/content/gdrive/MyDrive/Projects/TESS/data/angles/\"\n","        ccd_folder = \"/content/gdrive/MyDrive/Projects/TESS/data/ccds/\"\n","\n","        # data matrices\n","        X = []\n","        Y = []\n","        ffis = []\n","\n","        angles_dic = pickle.load(open(angle_folder+'angles_Oall_data.pkl', \"rb\"))\n","\n","        for filename in os.listdir(ccd_folder):\n","            if len(filename) < 40 or filename[27] != '3': continue\n","\n","            image_arr = pickle.load(open(ccd_folder+filename, \"rb\"))\n","            ffi_num = filename[18:18+8]\n","            try:\n","                angles = angles_dic[ffi_num]\n","                # print('Got ffi number', ffi_num)\n","            except:\n","                # print('Could not find ffi with number:', ffi_num)\n","                continue\n","            X.append(np.array([angles[10], angles[11], angles[18], angles[19], angles[22], angles[23], angles[24], angles[25]]))\n","            Y.append(image_arr.flatten())\n","            ffis.append(ffi_num)\n","\n","        # X = np.array(X)\n","        # Y = np.array(Y)\n","        # ffis = np.array(ffis)\n","        self.data = [Image.fromarray(x) for x in X]\n","        self.labels = [Image.fromarray(y) for y in Y]\n","\n","\n","        # for class_idx, class_name in enumerate(self.classes):\n","        #     # print(class_idx)\n","        #     horse_img_path = os.path.join(self.root_dir, \"horse\", class_name)\n","        #     mask_img_path = os.path.join(self.root_dir, \"mask\", class_name)\n","\n","        #     horse_image = Image.open(horse_img_path).convert('RGB')\n","        #     mask_image = Image.open(mask_img_path).convert('L')\n","\n","        #     self.data.extend([horse_image])\n","        #     self.labels.extend([mask_image])\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        # horse_img_path, mask_img_path = self.data[idx], self.labels[idx]\n","        # label = self.labels[idx]\n","        # horse_image = Image.open(horse_img_path).convert('RGB')\n","        # mask_image = Image.open(mask_img_path).convert('L')\n","\n","        ffi_image = self.data[idx]\n","        label_image = self.labels[idx]\n","\n","        transform = transforms.Compose([\n","            transforms.Resize((16, 16)),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.456], std=[0.225])\n","        ])\n","        target_transform = transforms.Compose([\n","            transforms.Resize((8, 8)),\n","            transforms.ToTensor()\n","        ])\n","\n","        ffi_image = transform(ffi_image)\n","        label_image = target_transform(label_image)\n","\n","\n","        # return horse_image, mask_image\n","        return {\"x\":ffi_image, \"y\":label_image}"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":263,"status":"ok","timestamp":1692391509548,"user":{"displayName":"Joseph Lupo","userId":"18192058496751055649"},"user_tz":240},"id":"B0ZGceEJwVrT","outputId":"eeafd597-c71e-4327-efd9-2bb16f9e6d86"},"outputs":[{"output_type":"stream","name":"stdout","text":["327\n","torch.Size([3, 224, 224])\n","torch.Size([1, 224, 224])\n"]}],"source":["weizmann_dataset.data\n","print(len(weizmann_dataset))\n","print(weizmann_dataset[1]['x'].shape)\n","print(weizmann_dataset[1]['y'].shape)"]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":3445,"status":"ok","timestamp":1692391517463,"user":{"displayName":"Joseph Lupo","userId":"18192058496751055649"},"user_tz":240},"id":"6SfJLtz_BKm_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6510664d-459e-4d9c-9a97-ad3b3f93be40"},"outputs":[{"output_type":"stream","name":"stdout","text":["3559\n","torch.Size([1, 16, 16])\n","torch.Size([1, 8, 8])\n"]}],"source":["tess_dataset = TESSDataset()\n","print(len(tess_dataset))\n","print(tess_dataset[1]['x'].shape)\n","print(tess_dataset[1]['y'].shape)"]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1692391517464,"user":{"displayName":"Joseph Lupo","userId":"18192058496751055649"},"user_tz":240},"id":"3izuR8hsVPZS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5774d3af-6a2c-4bfb-ac1f-d53c847406b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[0.0484, 0.0484, 0.0484, 0.0484, 0.0484, 0.0484, 0.0484, 0.0484],\n","         [0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910, 0.0910],\n","         [0.1259, 0.1259, 0.1259, 0.1259, 0.1259, 0.1259, 0.1259, 0.1259],\n","         [0.1383, 0.1383, 0.1383, 0.1383, 0.1383, 0.1383, 0.1383, 0.1383],\n","         [0.1303, 0.1303, 0.1303, 0.1303, 0.1303, 0.1303, 0.1303, 0.1303],\n","         [0.1291, 0.1291, 0.1291, 0.1291, 0.1291, 0.1291, 0.1291, 0.1291],\n","         [0.1127, 0.1127, 0.1127, 0.1127, 0.1127, 0.1127, 0.1127, 0.1127],\n","         [0.0825, 0.0825, 0.0825, 0.0825, 0.0825, 0.0825, 0.0825, 0.0825]]])\n"]}],"source":["print(tess_dataset[1]['y'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AY5vwap6aCOn","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8317d18b-fe25-44b0-ac05-f4a4a0ffc830"},"outputs":[{"output_type":"stream","name":"stdout","text":["number of param: 317819092\n","Iteration: 0/16300 \t Elapsed time: 12.97 \t Loss:43.46390\n","Iteration: 1/16300 \t Elapsed time: 22.09 \t Loss:43.16236\n","Iteration: 2/16300 \t Elapsed time: 29.61 \t Loss:42.94377\n","Iteration: 3/16300 \t Elapsed time: 38.45 \t Loss:42.74525\n","Iteration: 4/16300 \t Elapsed time: 45.65 \t Loss:42.56002\n","Iteration: 5/16300 \t Elapsed time: 54.22 \t Loss:42.38478\n","Iteration: 6/16300 \t Elapsed time: 62.15 \t Loss:42.21753\n"]}],"source":["# @title Train\n","import argparse\n","import torch\n","from torchvision import datasets\n","import pickle\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import TensorDataset, DataLoader\n","# import Learner\n","# import datasets\n","# import utils\n","# from CGlowModel import CondGlowModel\n","\n","\n","if __name__==\"__main__\":\n","\n","    parser = argparse.ArgumentParser(description='train c-Glow')\n","\n","    # input output path\n","    parser.add_argument(\"-d\", \"--dataset_name\", type=str, default=\"horse\")\n","    parser.add_argument(\"-r\", \"--dataset_root\", type=str, default=\"\")\n","\n","    # log root\n","    parser.add_argument(\"--log_root\", type=str, default=\"model\")\n","\n","    # C-Glow parameters\n","    parser.add_argument(\"--x_size\", type=tuple, default=(3,224,224))\n","    parser.add_argument(\"--y_size\", type=tuple, default=(1,224,224))\n","    # parser.add_argument(\"--x_size\", type=tuple, default=(1,16,16)) # SWITCH\n","    # parser.add_argument(\"--y_size\", type=tuple, default=(1,8,8))\n","    parser.add_argument(\"--x_hidden_channels\", type=int, default=128)\n","    parser.add_argument(\"--x_hidden_size\", type=int, default=64)\n","    parser.add_argument(\"--y_hidden_channels\", type=int, default=256)\n","    parser.add_argument(\"-K\", \"--depth_flow\", type=int, default=8)\n","    parser.add_argument(\"-L\", \"--num_levels\", type=int, default=3)\n","    parser.add_argument(\"--learn_top\", type=bool, default=False)\n","\n","    # Dataset preprocess parameters\n","    parser.add_argument(\"--label_scale\", type=float, default=1)\n","    parser.add_argument(\"--label_bias\", type=float, default=0.5)\n","    parser.add_argument(\"--x_bins\", type=float, default=256.0)\n","    parser.add_argument(\"--y_bins\", type=float, default=2.0)\n","\n","\n","    # Optimizer parameters\n","    parser.add_argument(\"--optimizer\", type=str, default=\"adam\")\n","    parser.add_argument(\"--lr\", type=float, default=0.0002)\n","    parser.add_argument(\"--betas\", type=tuple, default=(0.9,0.9999))\n","    parser.add_argument(\"--eps\", type=float, default=1e-8)\n","    parser.add_argument(\"--regularizer\", type=float, default=0.0)\n","    parser.add_argument(\"--num_steps\", type=int, default=0)\n","\n","    # Trainer parameters\n","    parser.add_argument(\"--num_epochs\", type=int, default=100)\n","    parser.add_argument(\"--batch_size\", type=int, default=2)\n","    parser.add_argument(\"--max_grad_clip\", type=float, default=5)\n","    parser.add_argument(\"--max_grad_norm\", type=float, default=0)\n","    parser.add_argument(\"--checkpoints_gap\", type=int, default=1000)\n","    parser.add_argument(\"--nll_gap\", type=int, default=1)\n","    parser.add_argument(\"--inference_gap\", type=int, default=1000)\n","    parser.add_argument(\"--save_gap\", type=int, default=1000)\n","\n","    # model path\n","    parser.add_argument(\"--model_path\", type=str, default=\"\")\n","\n","    # args = parser.parse_args()\n","    args = parser.parse_known_args()[0]\n","    cuda = torch.cuda.is_available()\n","\n","\n","    # FOR HORSES #\n","    # dataset\n","    dataset_root = '/content/gdrive/MyDrive/Projects/TESS/model_conditional_norm_flow_horses/weizmann_horse_db/'\n","    # Define any image transformations you want to apply (resize, normalization, etc.)\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])\n","    target_transform = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.456], std=[0.225])\n","    ])\n","\n","    # Create the dataset\n","    training_set = WeizmannHorseDataset(root_dir=dataset_root, transform=transform, target_transform=target_transform)\n","    valid_set = WeizmannHorseDataset(root_dir=dataset_root, transform=transform, target_transform=target_transform)\n","\n","\n","    # training_set = TESSDataset()\n","    # valid_set = training_set\n","\n","    model = CondGlowModel(args)\n","    if cuda:\n","        model = model.cuda()\n","\n","    # from utils import count_parameters\n","    print(\"number of param: {}\".format(count_parameters(model)))\n","\n","    # optimizer\n","    optim = torch.optim.Adam(model.parameters(), lr=args.lr,betas=args.betas, weight_decay=args.regularizer)\n","\n","    # scheduler\n","    scheduler = None\n","\n","    if args.model_path != \"\":\n","        state = load_state(args.model_path, cuda)\n","        optim.load_state_dict(state[\"optim\"])\n","        model.load_state_dict(state[\"model\"])\n","        args.steps = state[\"iteration\"] + 1\n","        if scheduler is not None and state.get(\"scheduler\", None) is not None:\n","            scheduler.load_state_dict(state[\"scheduler\"])\n","        del state\n","\n","    # begin to train\n","    trainer = Trainer(model, optim, scheduler, training_set, valid_set, args, cuda)\n","    trainer.train()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZwpE-AX1jImK","executionInfo":{"status":"aborted","timestamp":1692391468473,"user_tz":240,"elapsed":10,"user":{"displayName":"Joseph Lupo","userId":"18192058496751055649"}}},"outputs":[],"source":["trainingset_loader = DataLoader(training_set,\n","                                      batch_size=2,\n","                                      shuffle=True,\n","                                      drop_last=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-jzFkK_0aCQQ","executionInfo":{"status":"aborted","timestamp":1692391468474,"user_tz":240,"elapsed":11,"user":{"displayName":"Joseph Lupo","userId":"18192058496751055649"}}},"outputs":[],"source":["out = next(iter(trainingset_loader))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w-qLC1qulxkB","executionInfo":{"status":"aborted","timestamp":1692391468474,"user_tz":240,"elapsed":11,"user":{"displayName":"Joseph Lupo","userId":"18192058496751055649"}}},"outputs":[],"source":["out['x'].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"60VUPNjmmTJB","executionInfo":{"status":"aborted","timestamp":1692391468474,"user_tz":240,"elapsed":11,"user":{"displayName":"Joseph Lupo","userId":"18192058496751055649"}}},"outputs":[],"source":["out['y'].shape\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ch-kN_S-mpm8","executionInfo":{"status":"aborted","timestamp":1692391468475,"user_tz":240,"elapsed":11,"user":{"displayName":"Joseph Lupo","userId":"18192058496751055649"}}},"outputs":[],"source":["args"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"aborted","timestamp":1692391468475,"user":{"displayName":"Joseph Lupo","userId":"18192058496751055649"},"user_tz":240},"id":"hSKErwxzO7wt"},"outputs":[],"source":["import argparse\n","import torch\n","# import Learner\n","# import datasets\n","# import utils\n","# from CGlowModel import CondGlowModel\n","\n","\n","if __name__ == \"__main__\":\n","\n","    parser = argparse.ArgumentParser(description='predict c-Glow')\n","\n","    # model parameters\n","    parser.add_argument(\"--x_size\", type=tuple, default=(3,64,64))\n","    parser.add_argument(\"--y_size\", type=tuple, default=(3,64,64))\n","    parser.add_argument(\"--x_hidden_channels\", type=int, default=64)\n","    parser.add_argument(\"--x_hidden_size\", type=int, default=128)\n","    parser.add_argument(\"--y_hidden_channels\", type=int, default=256)\n","    parser.add_argument(\"-K\", \"--depth_flow\", type=int, default=8)\n","    parser.add_argument(\"-L\", \"--num_levels\", type=int, default=3)\n","    parser.add_argument(\"--learn_top\", type=bool, default=True)\n","\n","    # dataset\n","    parser.add_argument(\"-d\", \"--dataset_name\", type=str, default=\"horse\")\n","    parser.add_argument(\"-r\", \"--dataset_root\", type=str, default=\"\")\n","    parser.add_argument(\"--label_scale\", type=float, default=1)\n","    parser.add_argument(\"--label_bias\", type=float, default=0.5)\n","    parser.add_argument(\"--num_labels\", type=int, default=2)\n","    parser.add_argument(\"--x_bins\", type=float, default=256.0)\n","    parser.add_argument(\"--y_bins\", type=float, default=2.0)\n","\n","    # output\n","    parser.add_argument(\"-o\", \"--out_root\", type=str, default=\"inference\")\n","\n","    # model path\n","    parser.add_argument(\"--model_path\", type=str, default=\"model_path\")\n","\n","    # predictor parameters\n","    parser.add_argument(\"--batch_size\", type=int, default=10)\n","    parser.add_argument(\"--num_samples\", type=int, default=10)\n","\n","\n","    args = parser.parse_args()\n","    cuda = torch.cuda.is_available()\n","\n","    # dataset\n","    dataset = datasets.HorseDataset(args.dataset_root, (args.y_size[1], args.y_size[2]), args.y_size[0], \"test\")\n","\n","    # model\n","    model = CondGlowModel(args)\n","    state = utils.load_state(args.model_path, cuda)\n","    model.load_state_dict(state[\"model\"])\n","    del state\n","\n","    # predictor\n","    predictor = Learner.Inferencer(model, dataset, args, cuda)\n","\n","    # predict\n","    predictor.sampled_based_prediction(args.num_samples)"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}