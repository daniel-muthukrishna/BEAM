{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2242,
     "status": "ok",
     "timestamp": 1692391050462,
     "user": {
      "displayName": "Joseph Lupo",
      "userId": "18192058496751055649"
     },
     "user_tz": 240
    },
    "id": "AoYASP6SlsZe",
    "outputId": "4d279a5f-4afd-4985-f1cf-c7fa74d1dd2a"
   },
   "outputs": [],
   "source": [
    "# # only for colab\n",
    "# from google.colab import drive\n",
    "# import os\n",
    "\n",
    "# drive.mount(\"/content/gdrive\")\n",
    "# os.chdir('/content/gdrive/MyDrive/Projects/TESS/model_conditional_norm_flow/')\n",
    "# ! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1692391050463,
     "user": {
      "displayName": "Joseph Lupo",
      "userId": "18192058496751055649"
     },
     "user_tz": 240
    },
    "id": "wWai4P8Il4oq"
   },
   "outputs": [],
   "source": [
    "# ! rm -r log*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1692391050463,
     "user": {
      "displayName": "Joseph Lupo",
      "userId": "18192058496751055649"
     },
     "user_tz": 240
    },
    "id": "rkQEZJWdtZpu"
   },
   "outputs": [],
   "source": [
    "# Adapted from here: https://github.com/yolu1055/conditional-glow/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "executionInfo": {
     "elapsed": 3075,
     "status": "ok",
     "timestamp": 1692391053531,
     "user": {
      "displayName": "Joseph Lupo",
      "userId": "18192058496751055649"
     },
     "user_tz": 240
    },
    "id": "MdI9aotpm1b3"
   },
   "outputs": [],
   "source": [
    "# @title Utils\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def split_feature(tensor, type=\"split\"):\n",
    "    \"\"\"\n",
    "    type = [\"split\", \"cross\"]\n",
    "    \"\"\"\n",
    "    C = tensor.size(1)\n",
    "    if type == \"split\":\n",
    "        return tensor[:, :C // 2, ...], tensor[:, C // 2:, ...]\n",
    "    elif type == \"cross\":\n",
    "        return tensor[:, 0::2, ...], tensor[:, 1::2, ...]\n",
    "\n",
    "\n",
    "def save_model(model, optim, scheduler, dir, iteration):\n",
    "    path = os.path.join(dir, \"checkpoint_{}.pth.tar\".format(iteration))\n",
    "    state = {}\n",
    "    state[\"iteration\"] = iteration\n",
    "    state[\"modelname\"] = model.__class__.__name__\n",
    "    state[\"model\"] = model.state_dict()\n",
    "    state[\"optim\"] = optim.state_dict()\n",
    "    if scheduler is not None:\n",
    "        state[\"scheduler\"] = scheduler.state_dict()\n",
    "    else:\n",
    "        state[\"scheduler\"] = None\n",
    "\n",
    "    torch.save(state, path)\n",
    "\n",
    "\n",
    "def load_state(path, cuda):\n",
    "    if cuda:\n",
    "        print (\"load to gpu\")\n",
    "        state = torch.load(path)\n",
    "    else:\n",
    "        print (\"load to cpu\")\n",
    "        state = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "def _fast_hist(label_true, label_pred, n_class):\n",
    "    mask = (label_true >= 0) & (label_true < n_class)\n",
    "    hist = np.bincount(\n",
    "        n_class * label_true[mask].astype(int) +\n",
    "        label_pred[mask].astype(int), minlength=n_class ** 2).reshape(n_class, n_class)\n",
    "    return hist\n",
    "\n",
    "def compute_accuracy(label_trues, label_preds, n_class):\n",
    "\n",
    "    hist = np.zeros((n_class, n_class))\n",
    "    for lt, lp in zip(label_trues, label_preds):\n",
    "        hist += _fast_hist(lt.flatten(), lp.flatten(), n_class)\n",
    "    acc = np.diag(hist).sum() / hist.sum()\n",
    "    acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
    "    acc_cls = np.nanmean(acc_cls)\n",
    "    iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n",
    "    mean_iu = np.nanmean(iu)\n",
    "    freq = hist.sum(axis=1) / hist.sum()\n",
    "    fwavacc = (freq[freq > 0] * iu[freq > 0]).sum()\n",
    "    return acc, acc_cls, mean_iu, fwavacc\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1692391053531,
     "user": {
      "displayName": "Joseph Lupo",
      "userId": "18192058496751055649"
     },
     "user_tz": 240
    },
    "id": "y7lYe37Em1eN"
   },
   "outputs": [],
   "source": [
    "# @title Modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ActNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, num_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        size = [1, num_channels, 1, 1]\n",
    "\n",
    "        bias = torch.normal(mean=torch.zeros(*size), std=torch.ones(*size)*0.05)\n",
    "        logs = torch.normal(mean=torch.zeros(*size), std=torch.ones(*size)*0.05)\n",
    "        self.register_parameter(\"bias\", nn.Parameter(torch.Tensor(bias), requires_grad=True))\n",
    "        self.register_parameter(\"logs\", nn.Parameter(torch.Tensor(logs), requires_grad=True))\n",
    "\n",
    "\n",
    "    def forward(self, input, logdet=0, reverse=False):\n",
    "        dimentions = input.size(2) * input.size(3)\n",
    "        if reverse == False:\n",
    "            input = input + self.bias\n",
    "            input = input * torch.exp(self.logs)\n",
    "            dlogdet = torch.sum(self.logs) * dimentions\n",
    "            logdet = logdet + dlogdet\n",
    "\n",
    "        if reverse == True:\n",
    "            input = input * torch.exp(-self.logs)\n",
    "            input = input - self.bias\n",
    "            dlogdet = - torch.sum(self.logs) * dimentions\n",
    "            logdet = logdet + dlogdet\n",
    "\n",
    "        return input, logdet\n",
    "\n",
    "\n",
    "class Conv2dZeros(nn.Conv2d):\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, kernel_size=[3,3], stride=[1,1]):\n",
    "        padding = (kernel_size[0] - 1) // 2\n",
    "        super().__init__(in_channels=in_channel, out_channels=out_channel, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.weight.data.normal_(mean=0.0, std=0.1)\n",
    "\n",
    "\n",
    "\n",
    "class Conv2dResize(nn.Conv2d):\n",
    "\n",
    "    def __init__(self, in_size, out_size):\n",
    "\n",
    "        stride = [in_size[1]//out_size[1], in_size[2]//out_size[2]]\n",
    "        kernel_size = Conv2dResize.compute_kernel_size(in_size, out_size, stride)\n",
    "        super().__init__(in_channels=in_size[0], out_channels=out_size[0], kernel_size=kernel_size, stride=stride)\n",
    "        self.weight.data.zero_()\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_kernel_size(in_size, out_size, stride):\n",
    "        k0 = in_size[1] - (out_size[1] - 1) * stride[0]\n",
    "        k1 = in_size[2] - (out_size[2] - 1) * stride[1]\n",
    "        return[k0,k1]\n",
    "\n",
    "\n",
    "\n",
    "class Conv2dNorm(nn.Conv2d):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=[3, 3], stride=[1, 1]):\n",
    "\n",
    "        padding = (kernel_size[0] - 1) // 2\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        #initialize weight\n",
    "        self.weight.data.normal_(mean=0.0, std=0.05)\n",
    "\n",
    "\n",
    "\n",
    "class CondActNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, x_size, y_channels, x_hidden_channels, x_hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # OLD C_x,H_x,W_x = x_size\n",
    "        C_x, H_x = x_size \n",
    "\n",
    "        # OLD conditioning network\n",
    "        # self.x_Con = nn.Sequential(\n",
    "        #     Conv2dResize(in_size=[C_x,H_x,W_x], out_size=[x_hidden_channels, H_x//2, W_x//2]),\n",
    "        #     nn.ReLU(),\n",
    "        #     Conv2dResize(in_size=[x_hidden_channels, H_x//2, W_x//2], out_size=[x_hidden_channels, H_x//4, W_x//4]),\n",
    "        #     nn.ReLU(),\n",
    "        #     Conv2dResize(in_size=[x_hidden_channels, H_x//4, W_x//4], out_size=[x_hidden_channels, H_x//8, W_x//8]),\n",
    "        #     nn.ReLU()\n",
    "        # )\n",
    "\n",
    "        # NEW conditioning network\n",
    "        self.x_Linear = nn.Sequential(\n",
    "            nn.Linear(H_x, x_hidden_channels*H_x),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(x_hidden_channels*H_x, x_hidden_channels*H_x//2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(x_hidden_channels*H_x//2, x_hidden_channels*H_x//4),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(x_hidden_channels*H_x//4, x_hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(x_hidden_size, x_hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(x_hidden_size, 2*y_channels),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x, y, logdet=0, reverse=False):\n",
    "        \n",
    "        B,C,H = x.size()\n",
    "        print('xbefore', x.shape, x)\n",
    "        # generate weights\n",
    "        # x = self.x_Con(x)\n",
    "        # x = x.view(B, -1)\n",
    "        x = self.x_Linear(x)\n",
    "\n",
    "        print('xafter', x.shape, x)\n",
    "\n",
    "        x = x.view(B, -1, 1, 1)\n",
    "\n",
    "\n",
    "        logs, bias = split_feature(x)\n",
    "        dimentions = y.size(2) * y.size(3)\n",
    "\n",
    "\n",
    "        if not reverse:\n",
    "            # center and scale\n",
    "            y = y + bias\n",
    "            y = y * torch.exp(logs)\n",
    "            dlogdet = dimentions * torch.sum(logs, dim=(1,2,3))\n",
    "            logdet = logdet + dlogdet\n",
    "        else:\n",
    "            # scale and center\n",
    "            y = y * torch.exp(-logs)\n",
    "            y = y - bias\n",
    "            dlogdet = - dimentions * torch.sum(logs, dim=(1,2,3))\n",
    "            logdet = logdet + dlogdet\n",
    "\n",
    "        return y, logdet\n",
    "\n",
    "\n",
    "\n",
    "class Cond1x1Conv(nn.Module):\n",
    "\n",
    "    def __init__(self, x_size, x_hidden_channels, x_hidden_size, y_channels):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        C_x,H_x = x_size\n",
    "\n",
    "\n",
    "        # # conditioning network\n",
    "        # self.x_Con = nn.Sequential(\n",
    "        #     Conv2dResize(in_size=[C_x,H_x,W_x], out_size=[x_hidden_channels, H_x//2, W_x//2]),\n",
    "        #     nn.ReLU(),\n",
    "        #     Conv2dResize(in_size=[x_hidden_channels, H_x//2, W_x//2], out_size=[x_hidden_channels, H_x//4, W_x//4]),\n",
    "        #     nn.ReLU(),\n",
    "        #     Conv2dResize(in_size=[x_hidden_channels, H_x//4, W_x//4], out_size=[x_hidden_channels, H_x//8, W_x//8]),\n",
    "        #     nn.ReLU()\n",
    "        # )\n",
    "\n",
    "        # NEW conditioning network\n",
    "\n",
    "        self.x_Linear = nn.Sequential(\n",
    "            LinearZeros(H_x, x_hidden_channels*H_x),\n",
    "            nn.Tanh(),\n",
    "            LinearZeros(x_hidden_channels*H_x, x_hidden_channels*H_x//2),\n",
    "            nn.Tanh(),\n",
    "            LinearZeros(x_hidden_channels*H_x//2, x_hidden_channels*H_x//4),\n",
    "            nn.Tanh(),\n",
    "            LinearZeros(x_hidden_channels*H_x//4, x_hidden_size),\n",
    "            nn.Tanh(),\n",
    "            LinearZeros(x_hidden_size, x_hidden_size),\n",
    "            nn.Tanh(),\n",
    "            LinearZeros(x_hidden_size, y_channels*y_channels),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "\n",
    "    def get_weight(self, x, y, reverse):\n",
    "        y_channels = y.size(1)\n",
    "        B,C,H = x.size()\n",
    "\n",
    "        # x = self.x_Con(x)\n",
    "        # x = x.view(B, -1)\n",
    "        x = self.x_Linear(x)\n",
    "        weight = x.view(B, y_channels, y_channels)\n",
    "        \n",
    "\n",
    "        dimensions = y.size(2) * y.size(3)\n",
    "        dlogdet = torch.slogdet(weight)[1] * dimensions\n",
    "\n",
    "\n",
    "        if reverse == False:\n",
    "            weight = weight.view(B, y_channels, y_channels,1,1)\n",
    "\n",
    "        else:\n",
    "            weight = torch.inverse(weight.double()).float().view(B, y_channels, y_channels,1,1)\n",
    "\n",
    "        return weight, dlogdet\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, y, logdet=None, reverse=False):\n",
    "\n",
    "        weight, dlogdet = self.get_weight(x, y, reverse)\n",
    "        B,C,H,W = y.size()\n",
    "        y = y.view(1, B*C, H, W)\n",
    "        B_k, C_i_k, C_o_k, H_k, W_k = weight.size()\n",
    "        assert B == B_k and C == C_i_k and C == C_o_k, \"The input and kernel dimensions are different\"\n",
    "        weight = weight.reshape(B_k*C_i_k,C_o_k,H_k,W_k)\n",
    "\n",
    "        if reverse == False:\n",
    "            z = F.conv2d(y, weight, groups=B)\n",
    "            z = z.view(B,C,H,W)\n",
    "            if logdet is not None:\n",
    "                logdet = logdet + dlogdet\n",
    "\n",
    "            return z, logdet\n",
    "        else:\n",
    "            z = F.conv2d(y, weight, groups=B)\n",
    "            z = z.view(B,C,H,W)\n",
    "\n",
    "            if logdet is not None:\n",
    "                logdet = logdet - dlogdet\n",
    "\n",
    "            return z, logdet\n",
    "\n",
    "\n",
    "class Conv2dNormy(nn.Conv2d):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels,\n",
    "                 kernel_size=[3, 3], stride=[1, 1]):\n",
    "        padding = [(kernel_size[0]-1)//2, (kernel_size[1]-1)//2]\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride,\n",
    "                         padding, bias=False)\n",
    "\n",
    "        #initialize weight\n",
    "        self.weight.data.normal_(mean=0.0, std=0.05)\n",
    "        self.actnorm = ActNorm(out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = super().forward(input)\n",
    "        x,_ = self.actnorm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Conv2dZerosy(nn.Conv2d):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels,\n",
    "                 kernel_size=[3, 3], stride=[1, 1]):\n",
    "\n",
    "        padding = [(kernel_size[0]-1)//2, (kernel_size[1]-1)//2]\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, padding)\n",
    "\n",
    "        self.logscale_factor = 3.0\n",
    "        self.register_parameter(\"logs\", nn.Parameter(torch.zeros(out_channels, 1, 1)))\n",
    "        self.register_parameter(\"newbias\", nn.Parameter(torch.zeros(out_channels, 1, 1)))\n",
    "\n",
    "        # init\n",
    "        self.weight.data.zero_()\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = super().forward(input)\n",
    "        output = output + self.newbias\n",
    "        output = output * torch.exp(self.logs * self.logscale_factor)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CondAffineCoupling(nn.Module):\n",
    "\n",
    "    def __init__(self, x_size, y_size, hidden_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.resize_x = nn.Sequential(\n",
    "        #     Conv2dZeros(x_size[0], 16),\n",
    "        #     nn.ReLU(),\n",
    "        #     Conv2dResize((16,x_size[1],x_size[2]), out_size=y_size),\n",
    "        #     nn.ReLU(),\n",
    "        #     Conv2dZeros(y_size[0], y_size[0]),\n",
    "        #     nn.ReLU()\n",
    "        # )\n",
    "\n",
    "        C_x, H_x = x_size\n",
    "\n",
    "        self.resize_x = nn.Sequential(\n",
    "            LinearZeros(H_x, 32),\n",
    "            nn.Tanh(),\n",
    "            LinearZeros(32, y_size[0]*y_size[1]*y_size[2]),\n",
    "            nn.Tanh(),\n",
    "            LinearZeros(y_size[0]*y_size[1]*y_size[2], y_size[0]*y_size[1]*y_size[2]),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.f = nn.Sequential(\n",
    "            Conv2dNormy(y_size[0]*2, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            Conv2dNormy(hidden_channels, hidden_channels, kernel_size=[1, 1]),\n",
    "            nn.ReLU(),\n",
    "            Conv2dZerosy(hidden_channels, 2*y_size[0]),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y, logdet=0.0, reverse=False):\n",
    "\n",
    "        z1, z2 = split_feature(y, \"split\")\n",
    "        x = self.resize_x(x)\n",
    "        x = x.view(z1.shape)\n",
    "\n",
    "        h = torch.cat((x,z1), dim=1)\n",
    "        h = self.f(h)\n",
    "        shift, scale = split_feature(h, \"cross\")\n",
    "        scale = torch.sigmoid(scale + 2.)\n",
    "        if reverse == False:\n",
    "            z2 = z2 + shift\n",
    "            z2 = z2 * scale\n",
    "            logdet = torch.sum(torch.log(scale), dim=(1, 2, 3)) + logdet\n",
    "\n",
    "        if reverse == True:\n",
    "            z2 = z2 / scale\n",
    "            z2 = z2 - shift\n",
    "            logdet = -torch.sum(torch.log(scale), dim=(1, 2, 3)) + logdet\n",
    "\n",
    "        z = torch.cat((z1, z2), dim=1)\n",
    "\n",
    "        return z, logdet\n",
    "\n",
    "\n",
    "\n",
    "class SqueezeLayer(nn.Module):\n",
    "    def __init__(self, factor):\n",
    "        super().__init__()\n",
    "        self.factor = factor\n",
    "\n",
    "    def forward(self, input, logdet=None, reverse=False):\n",
    "        if not reverse:\n",
    "            output = SqueezeLayer.squeeze2d(input, self.factor)\n",
    "            return output, logdet\n",
    "        else:\n",
    "            output = SqueezeLayer.unsqueeze2d(input, self.factor)\n",
    "            return output, logdet\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def squeeze2d(input, factor=2):\n",
    "        assert factor >= 1 and isinstance(factor, int)\n",
    "        if factor == 1:\n",
    "            return input\n",
    "        B, C, H, W = input.size()\n",
    "        assert H % factor == 0 and W % factor == 0, \"{}\".format((H, W))\n",
    "        x = input.view(B, C, H // factor, factor, W // factor, factor)\n",
    "        x = x.permute(0, 1, 3, 5, 2, 4).contiguous()\n",
    "        x = x.view(B, C * factor * factor, H // factor, W // factor)\n",
    "        return x\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def unsqueeze2d(input, factor=2):\n",
    "        assert factor >= 1 and isinstance(factor, int)\n",
    "        factor2 = factor ** 2\n",
    "        if factor == 1:\n",
    "            return input\n",
    "        B, C, H, W = input.size()\n",
    "        assert C % (factor2) == 0, \"{}\".format(C)\n",
    "        x = input.view(B, C // factor2, factor, factor, H, W)\n",
    "        x = x.permute(0, 1, 4, 2, 5, 3).contiguous()\n",
    "        x = x.view(B, C // (factor2), H * factor, W * factor)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Split2d(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            Conv2dZeros(num_channels // 2, num_channels),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def split2d_prior(self, z):\n",
    "        h = self.conv(z)\n",
    "        return split_feature(h, \"cross\")\n",
    "\n",
    "    def forward(self, input, logdet=0., reverse=False, eps_std=None):\n",
    "        if not reverse:\n",
    "            z1, z2 = split_feature(input, \"split\")\n",
    "            mean, logs = self.split2d_prior(z1)\n",
    "            logdet = GaussianDiag.logp(mean, logs, z2) + logdet\n",
    "\n",
    "            return z1, logdet\n",
    "        else:\n",
    "            z1 = input\n",
    "            mean, logs = self.split2d_prior(z1)\n",
    "            z2 = GaussianDiag.sample(mean, logs, eps_std)\n",
    "            z = torch.cat((z1, z2), dim=1)\n",
    "\n",
    "            return z, logdet\n",
    "\n",
    "\n",
    "class GaussianDiag:\n",
    "    Log2PI = float(np.log(2 * np.pi))\n",
    "\n",
    "    @staticmethod\n",
    "    def likelihood(mean, logs, x):\n",
    "        return -0.5 * (logs * 2. + ((x - mean) ** 2.) / torch.exp(logs * 2.) + GaussianDiag.Log2PI)\n",
    "\n",
    "    @staticmethod\n",
    "    def logp(mean, logs, x):\n",
    "        likelihood = GaussianDiag.likelihood(mean, logs, x)\n",
    "        return torch.sum(likelihood, dim=(1, 2, 3))\n",
    "\n",
    "    @staticmethod\n",
    "    def sample(mean, logs, eps_std=None):\n",
    "        eps_std = eps_std or 1\n",
    "        eps = torch.normal(mean=torch.zeros_like(mean),\n",
    "                           std=torch.ones_like(logs) * eps_std)\n",
    "        return mean + torch.exp(logs) * eps\n",
    "\n",
    "    @staticmethod\n",
    "    def batchsample(batchsize, mean, logs, eps_std=None):\n",
    "        eps_std = eps_std or 1\n",
    "        sample = GaussianDiag.sample(mean, logs, eps_std)\n",
    "        for i in range(1, batchsize):\n",
    "            s = GaussianDiag.sample(mean, logs, eps_std)\n",
    "            sample = torch.cat((sample, s), dim=0)\n",
    "        return sample\n",
    "\n",
    "\n",
    "\n",
    "class LinearZeros(nn.Linear):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(in_channels, out_channels)\n",
    "        self.weight.data.zero_()\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = super().forward(input)\n",
    "        return output\n",
    "\n",
    "\n",
    "class LinearNorm(nn.Linear):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(in_channels, out_channels)\n",
    "        self.weight.data.normal_(mean=0.0, std=0.1)\n",
    "        self.bias.data.normal_(mean=0.0, std=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1692391053531,
     "user": {
      "displayName": "Joseph Lupo",
      "userId": "18192058496751055649"
     },
     "user_tz": 240
    },
    "id": "6ntChUCZnc8W"
   },
   "outputs": [],
   "source": [
    "# @title Glow Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class CondGlowStep(nn.Module):\n",
    "\n",
    "    def __init__(self, x_size, y_size, x_hidden_channels, x_hidden_size, y_hidden_channels):\n",
    "\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # 1. cond-actnorm\n",
    "        self.actnorm = CondActNorm(x_size=x_size, y_channels=y_size[0], x_hidden_channels=x_hidden_channels, x_hidden_size=x_hidden_size)\n",
    "\n",
    "        # 2. cond-1x1conv\n",
    "        self.invconv = Cond1x1Conv(x_size=x_size, x_hidden_channels=x_hidden_channels, x_hidden_size=x_hidden_size, y_channels=y_size[0])\n",
    "\n",
    "        # 3. cond-affine\n",
    "        self.affine = CondAffineCoupling(x_size=x_size, y_size=[y_size[0] // 2, y_size[1], y_size[2]], hidden_channels=y_hidden_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x, y, logdet=None, reverse=False):\n",
    "        \n",
    "        if reverse is False:\n",
    "            # 1. cond-actnorm\n",
    "            y, logdet = self.actnorm(x, y, logdet, reverse=False)\n",
    "\n",
    "            # 2. cond-1x1conv\n",
    "            y, logdet = self.invconv(x, y, logdet, reverse=False)\n",
    "\n",
    "            # 3. cond-affine\n",
    "            y, logdet = self.affine(x, y, logdet, reverse=False)\n",
    "\n",
    "            # Return\n",
    "            return y, logdet\n",
    "\n",
    "\n",
    "        if reverse is True:\n",
    "            # 3. cond-affine\n",
    "            y, logdet = self.affine(x, y, logdet, reverse=True)\n",
    "\n",
    "            # 2. cond-1x1conv\n",
    "            y, logdet = self.invconv(x, y, logdet, reverse=True)\n",
    "\n",
    "            # 1. cond-actnorm\n",
    "            y, logdet = self.actnorm(x, y, logdet, reverse=True)\n",
    "\n",
    "            # Return\n",
    "            return y, logdet\n",
    "\n",
    "\n",
    "class CondGlow(nn.Module):\n",
    "\n",
    "    def __init__(self, x_size, y_size, x_hidden_channels, x_hidden_size, y_hidden_channels, K, L):\n",
    "\n",
    "\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.output_shapes = []\n",
    "        self.K = K\n",
    "        self.L = L\n",
    "        C, H, W = y_size\n",
    "\n",
    "        for l in range(0, L):\n",
    "\n",
    "            # 1. Squeeze\n",
    "            C, H, W = C * 4, H // 2, W // 2\n",
    "            y_size = [C,H,W]\n",
    "            self.layers.append(SqueezeLayer(factor=2))\n",
    "            self.output_shapes.append([-1, C, H, W])\n",
    "\n",
    "            # 2. K CGlowStep\n",
    "            for k in range(0, K):\n",
    "\n",
    "                self.layers.append(CondGlowStep(x_size = x_size,\n",
    "                                            y_size = y_size,\n",
    "                                            x_hidden_channels = x_hidden_channels,\n",
    "                                            x_hidden_size = x_hidden_size,\n",
    "                                            y_hidden_channels = y_hidden_channels,\n",
    "                                            )\n",
    "                                   )\n",
    "\n",
    "                self.output_shapes.append([-1, C, H, W])\n",
    "\n",
    "            # 3. Split\n",
    "            if l < L - 1:\n",
    "                self.layers.append(Split2d(num_channels=C))\n",
    "                self.output_shapes.append([-1, C // 2, H, W])\n",
    "                C = C // 2\n",
    "\n",
    "\n",
    "    def forward(self, x, y, logdet=0.0, reverse=False, eps_std=1.0):\n",
    "        if reverse == False:\n",
    "            return self.encode(x, y, logdet)\n",
    "        else:\n",
    "            return self.decode(x, y, logdet, eps_std)\n",
    "\n",
    "    def encode(self, x, y, logdet=0.0):\n",
    "        for layer, shape in zip(self.layers, self.output_shapes):\n",
    "            if isinstance(layer, Split2d) or isinstance(layer, SqueezeLayer):\n",
    "                y, logdet = layer(y, logdet, reverse=False)\n",
    "\n",
    "            else:\n",
    "                y, logdet = layer(x, y, logdet, reverse=False)\n",
    "        return y, logdet\n",
    "\n",
    "    def decode(self, x, y, logdet=0.0, eps_std=1.0):\n",
    "        for layer in reversed(self.layers):\n",
    "            if isinstance(layer, Split2d):\n",
    "                y, logdet = layer(y, logdet=logdet, reverse=True, eps_std=eps_std)\n",
    "\n",
    "            elif isinstance(layer, SqueezeLayer):\n",
    "                y, logdet = layer(y, logdet=logdet, reverse=True)\n",
    "\n",
    "            else:\n",
    "                y, logdet = layer(x, y, logdet=logdet, reverse=True)\n",
    "\n",
    "        return y, logdet\n",
    "\n",
    "\n",
    "class CondGlowModel(nn.Module):\n",
    "    BCE = nn.BCEWithLogitsLoss()\n",
    "    CE = nn.CrossEntropyLoss()\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.flow = CondGlow(x_size=args.x_size,\n",
    "                            y_size=args.y_size,\n",
    "                            x_hidden_channels=args.x_hidden_channels,\n",
    "                            x_hidden_size=args.x_hidden_size,\n",
    "                            y_hidden_channels=args.y_hidden_channels,\n",
    "                            K=args.depth_flow,\n",
    "                            L=args.num_levels,\n",
    "                            )\n",
    "\n",
    "        self.learn_top = args.learn_top\n",
    "\n",
    "\n",
    "        self.register_parameter(\"new_mean\",\n",
    "                                nn.Parameter(torch.zeros(\n",
    "                                    [1,\n",
    "                                     self.flow.output_shapes[-1][1],\n",
    "                                     self.flow.output_shapes[-1][2],\n",
    "                                     self.flow.output_shapes[-1][3]])))\n",
    "\n",
    "\n",
    "        self.register_parameter(\"new_logs\",\n",
    "                                nn.Parameter(torch.zeros(\n",
    "                                    [1,\n",
    "                                     self.flow.output_shapes[-1][1],\n",
    "                                     self.flow.output_shapes[-1][2],\n",
    "                                     self.flow.output_shapes[-1][3]])))\n",
    "\n",
    "        self.n_bins = args.y_bins\n",
    "\n",
    "\n",
    "    def prior(self):\n",
    "\n",
    "        if self.learn_top:\n",
    "            return self.new_mean, self.new_logs\n",
    "        else:\n",
    "            return torch.zeros_like(self.new_mean), torch.zeros_like(self.new_logs)\n",
    "\n",
    "\n",
    "    def forward(self, x=0.0, y=None, eps_std=1.0, reverse=False):\n",
    "        if reverse == False:\n",
    "            dimensions = y.size(1)*y.size(2)*y.size(3)\n",
    "            logdet = torch.zeros_like(y[:, 0, 0, 0])\n",
    "            logdet += float(-np.log(self.n_bins) * dimensions)\n",
    "            z, objective = self.flow(x, y, logdet=logdet, reverse=False)\n",
    "            mean, logs = self.prior()\n",
    "            objective += GaussianDiag.logp(mean, logs, z)\n",
    "            nll = -objective / float(np.log(2.) * dimensions)\n",
    "            return z, nll\n",
    "\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                mean, logs = self.prior()\n",
    "                if y is None:\n",
    "                    y = GaussianDiag.batchsample(x.size(0), mean, logs, eps_std)\n",
    "                y, logdet = self.flow(x, y, eps_std=eps_std, reverse=True)\n",
    "            return y, logdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1976,
     "status": "ok",
     "timestamp": 1692391055504,
     "user": {
      "displayName": "Joseph Lupo",
      "userId": "18192058496751055649"
     },
     "user_tz": 240
    },
    "id": "7xtTbLLNndDk"
   },
   "outputs": [],
   "source": [
    "# @title Learner\n",
    "import os\n",
    "import torch\n",
    "import datetime\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "# from datasets import convert_to_img\n",
    "# from datasets import preprocess\n",
    "# from datasets import postprocess\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Trainer(object):\n",
    "\n",
    "    def __init__(self, graph, optim, scheduler, trainingset, validset, args, cuda):\n",
    "\n",
    "        # set path and date\n",
    "        date = str(datetime.datetime.now())\n",
    "        date = date[:date.rfind(\":\")].replace(\"-\", \"\")\\\n",
    "                                     .replace(\":\", \"\")\\\n",
    "                                     .replace(\" \", \"_\")\n",
    "        self.log_dir = os.path.join(args.log_root, \"log_\" + date)\n",
    "        if not os.path.exists(self.log_dir):\n",
    "            os.makedirs(self.log_dir)\n",
    "\n",
    "\n",
    "        self.checkpoints_dir = os.path.join(self.log_dir, \"checkpoints\")\n",
    "        if not os.path.exists(self.checkpoints_dir):\n",
    "            os.makedirs(self.checkpoints_dir)\n",
    "\n",
    "        self.images_dir = os.path.join(self.log_dir, \"images\")\n",
    "        if not os.path.exists(self.images_dir):\n",
    "            os.makedirs(self.images_dir)\n",
    "\n",
    "        self.valid_samples_dir = os.path.join(self.log_dir, \"valid_samples\")\n",
    "        if not os.path.exists(self.valid_samples_dir):\n",
    "            os.makedirs(self.valid_samples_dir)\n",
    "\n",
    "\n",
    "\n",
    "        # model\n",
    "        self.graph = graph\n",
    "        self.optim = optim\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "        # gradient bound\n",
    "        self.max_grad_clip = args.max_grad_clip\n",
    "        self.max_grad_norm = args.max_grad_norm\n",
    "\n",
    "        # data\n",
    "        self.dataset_name = args.dataset_name\n",
    "        self.batch_size = args.batch_size\n",
    "        self.trainingset_loader = DataLoader(trainingset,\n",
    "                                      batch_size=self.batch_size,\n",
    "                                      shuffle=True,\n",
    "                                      drop_last=True)\n",
    "\n",
    "        self.validset_loader = DataLoader(validset,\n",
    "                                      batch_size=self.batch_size,\n",
    "                                      shuffle=False,\n",
    "                                      drop_last=False)\n",
    "\n",
    "        self.num_epochs = args.num_epochs\n",
    "        self.global_step = args.num_steps\n",
    "        self.label_scale = args.label_scale\n",
    "        self.label_bias = args.label_bias\n",
    "        self.x_bins = args.x_bins\n",
    "        self.y_bins = args.y_bins\n",
    "\n",
    "\n",
    "        self.num_epochs = args.num_epochs\n",
    "        self.nll_gap = args.nll_gap\n",
    "        self.inference_gap = args.inference_gap\n",
    "        self.checkpoints_gap = args.checkpoints_gap\n",
    "        self.save_gap = args.save_gap\n",
    "\n",
    "        # device\n",
    "        self.cuda = cuda\n",
    "\n",
    "    def validate(self):\n",
    "        print (\"Start Validating\")\n",
    "        self.graph.eval()\n",
    "        mean_loss = list()\n",
    "        samples = list()\n",
    "        with torch.no_grad():\n",
    "            for i_batch, batch in enumerate(self.validset_loader):\n",
    "                x = batch[\"x\"]\n",
    "                y = batch[\"y\"]\n",
    "\n",
    "                if self.cuda:\n",
    "                    x = x.cuda()\n",
    "                    y = y.cuda()\n",
    "\n",
    "\n",
    "                # forward\n",
    "                z, nll = self.graph(x,y)\n",
    "                loss = torch.mean(nll)\n",
    "                mean_loss.append(loss.data.cpu().item())\n",
    "\n",
    "                # true label\n",
    "                y_true = y\n",
    "\n",
    "                # sample\n",
    "                batch_samples = []\n",
    "                for b in range(len(y)):\n",
    "                    row = []\n",
    "                    row.append(y_true[b])\n",
    "                    batch_samples.append(row)\n",
    "                for i in range(0, 5):\n",
    "                    y_sample,_ = self.graph(x, y=None, reverse=True)\n",
    "\n",
    "                    for b in range(len(y)):\n",
    "                        batch_samples[b].append(y_sample[b])\n",
    "\n",
    "                for b in range(len(y)):\n",
    "                    samples.append(batch_samples[b])\n",
    "\n",
    "        # save samples\n",
    "        for i in range(0, len(samples)):\n",
    "            if i < 5:\n",
    "                fig, axes = plt.subplots(1, len(samples[i]), figsize=(40, 7))\n",
    "                for b in range(0,len(samples[i])):\n",
    "                    plottitle = 'y true' if b == 0 else f'(Using only x_cond) sample {b}'\n",
    "                    axes[b].set_title(plottitle)\n",
    "                    im_pred = axes[b].imshow(samples[i][b].cpu()[0], cmap=\"gray\")\n",
    "                    fig.colorbar(im_pred, fraction=0.046, pad=0.04)\n",
    "                fig.savefig(os.path.join(self.valid_samples_dir, f\"global_step{self.global_step}_sample{i}_batch{b}.pdf\"))\n",
    "                plt.close()\n",
    "\n",
    "        # save loss\n",
    "        mean = np.mean(mean_loss)\n",
    "        with open(os.path.join(self.log_dir, \"valid_NLL.txt\"), \"a\") as nll_file:\n",
    "            nll_file.write(str(self.global_step) + \"\\t\" + \"{:.5f}\".format(mean) + \"\\n\")\n",
    "        print (\"Finish Validating\")\n",
    "        self.graph.train()\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        self.graph.train()\n",
    "\n",
    "        starttime = time.time()\n",
    "\n",
    "        # run\n",
    "        num_batchs = len(self.trainingset_loader)\n",
    "        total_its = self.num_epochs * num_batchs\n",
    "        for epoch in range(self.num_epochs):\n",
    "            mean_nll = 0.0\n",
    "            for _, batch in enumerate(self.trainingset_loader):\n",
    "                self.optim.zero_grad()\n",
    "\n",
    "                x = batch[\"x\"]\n",
    "                y = batch[\"y\"]\n",
    "\n",
    "\n",
    "                if self.cuda:\n",
    "                    x = x.cuda()\n",
    "                    y = y.cuda()\n",
    "\n",
    "                # forward\n",
    "                z, nll = self.graph(x, y)\n",
    "\n",
    "\n",
    "                # loss\n",
    "                loss = torch.mean(nll)\n",
    "                mean_nll = mean_nll + loss.data\n",
    "\n",
    "                # backward\n",
    "                self.graph.zero_grad()\n",
    "                self.optim.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                # operate grad\n",
    "                if self.max_grad_clip > 0:\n",
    "                    torch.nn.utils.clip_grad_value_(self.graph.parameters(), self.max_grad_clip)\n",
    "                if self.max_grad_norm > 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(self.graph.parameters(), self.max_grad_norm)\n",
    "\n",
    "                # step\n",
    "                self.optim.step()\n",
    "\n",
    "                currenttime = time.time()\n",
    "                elapsed = currenttime - starttime\n",
    "                print(\"Iteration: {}/{} \\t Elapsed time: {:.2f} \\t Loss:{:.5f}\".format(self.global_step, total_its, elapsed, loss.data))\n",
    "\n",
    "                if self.global_step % self.nll_gap == 0:\n",
    "                    with open(os.path.join(self.log_dir, \"NLL.txt\"), \"a\") as nll_file:\n",
    "                        nll_file.write(str(self.global_step) + \" \\t \" + \"{:.2f} \\t {:.5f}\".format(elapsed, loss.data) + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "                # checkpoint\n",
    "                if self.global_step % self.checkpoints_gap == 0 and self.global_step > 0:\n",
    "                    self.validate()\n",
    "\n",
    "                    # samples\n",
    "                    samples = []\n",
    "                    for b in range(self.batch_size):\n",
    "                        samples.append([])\n",
    "\n",
    "                    for i in range(0,5):\n",
    "                        y_sample,_ = self.graph(x, y=None, reverse=True)\n",
    "                        for b in range(self.batch_size):\n",
    "                            samples[b].append(y_sample[b])\n",
    "\n",
    "                    # inverse image\n",
    "                    y_inverse,_ = self.graph(x, y=z, reverse=True)\n",
    "\n",
    "                    # true label\n",
    "                    y_true = y\n",
    "\n",
    "\n",
    "                    # save images\n",
    "                    output = None\n",
    "                    for b in range(0, self.batch_size):\n",
    "\n",
    "                        fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "                        if b < 5:\n",
    "                            axes[0].set_title('y Truth')\n",
    "                            im_true = axes[0].imshow(y[b].cpu()[0], cmap=\"gray\")\n",
    "                            fig.colorbar(im_true, fraction=0.046, pad=0.04)\n",
    "\n",
    "                            axes[1].set_title('y inverse')\n",
    "                            im_latent = axes[1].imshow(y_inverse[b].cpu()[0], cmap=\"gray\")\n",
    "                            fig.colorbar(im_latent, fraction=0.046, pad=0.04)\n",
    "\n",
    "                            axes[2].set_title('y Prediction sample')\n",
    "                            im_pred = axes[2].imshow(samples[b][i].cpu()[0], cmap=\"gray\")\n",
    "                            fig.colorbar(im_pred, fraction=0.046, pad=0.04)\n",
    "\n",
    "                            fig.savefig(os.path.join(self.images_dir, f\"global_step-{self.global_step}_batch_{b}.pdf\"))\n",
    "                            plt.close()\n",
    "\n",
    "\n",
    "\n",
    "                # save model\n",
    "                if self.global_step % self.save_gap == 0 and self.global_step > 0:\n",
    "                    save_model(self.graph, self.optim, self.scheduler, self.checkpoints_dir, self.global_step)\n",
    "\n",
    "\n",
    "                self.global_step = self.global_step + 1\n",
    "\n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step()\n",
    "            mean_nll = float(mean_nll / float(num_batchs))\n",
    "            with open(os.path.join(self.log_dir, \"Epoch_NLL.txt\"), \"a\") as f:\n",
    "                currenttime = time.time()\n",
    "                elapsed = currenttime - starttime\n",
    "                f.write(\"{} \\t {:.2f}\\t {:.5f}\".format(epoch, elapsed, mean_nll) + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Inferencer(object):\n",
    "\n",
    "    def __init__(self, model, dataset, args, cuda):\n",
    "\n",
    "        # set path and date\n",
    "        self.out_root = args.out_root\n",
    "        if not os.path.exists(self.out_root):\n",
    "            os.makedirs(self.out_root)\n",
    "\n",
    "        # cuda\n",
    "        self.cuda = cuda\n",
    "\n",
    "        # model\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "        # data\n",
    "        self.dataset_name = args.dataset_name\n",
    "        self.batch_size = args.batch_size\n",
    "        self.data_loader = DataLoader(dataset,\n",
    "                                      batch_size=self.batch_size,\n",
    "                                      shuffle=False,\n",
    "                                      drop_last=False)\n",
    "\n",
    "        self.label_scale = args.label_scale\n",
    "        self.label_bias = args.label_bias\n",
    "        self.num_labels = args.num_labels\n",
    "        self.y_bins = args.y_bins\n",
    "        self.x_bins = args.x_bins\n",
    "\n",
    "\n",
    "    def sampled_based_prediction(self, n_samples):\n",
    "        metrics = []\n",
    "        start = time.time()\n",
    "        for i_batch, batch in enumerate(self.data_loader):\n",
    "            print(f\"Batch IDs: {i_batch}\")\n",
    "\n",
    "            x = batch[\"x\"]\n",
    "            y = batch[\"y\"]\n",
    "\n",
    "            if self.cuda:\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "\n",
    "            sample_list = list()\n",
    "            nll_list = list()\n",
    "            for i in range(0, n_samples):\n",
    "\n",
    "                print(f\"Samples: {i}/{n_samples}\")\n",
    "\n",
    "                # z, nll = self.model(x, y, reverse=False)\n",
    "                # ypred, logdet = self.model(x, z, reverse=True)\n",
    "\n",
    "                y_sample,_ = self.model(x, reverse=True)\n",
    "                _, nll = self.model(x,y_sample)\n",
    "                loss = torch.mean(nll)\n",
    "                sample_list.append(y_sample)\n",
    "                nll_list.append(loss.data.cpu().numpy())\n",
    "\n",
    "            sample = torch.stack(sample_list)\n",
    "            sample = torch.mean(sample, dim=0, keepdim=False)\n",
    "            nll = np.mean(nll_list)\n",
    "\n",
    "            y_pred_imgs = sample\n",
    "            y_true_imgs = y\n",
    "\n",
    "            # save trues and preds\n",
    "            output = []\n",
    "            for i in range(0, len(y_true_imgs)):\n",
    "                true_img = y_true_imgs[i]\n",
    "                pred_img = y_pred_imgs[i]\n",
    "                row = [x[i].cpu(), true_img, pred_img]\n",
    "                output.append(row)\n",
    "\n",
    "                fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "                axes[0].set_title('Truth')\n",
    "                im_true = axes[0].imshow(true_img.cpu()[0], cmap=\"gray\")\n",
    "                fig.colorbar(im_true, fraction=0.046, pad=0.04)\n",
    "\n",
    "                axes[1].set_title('x_cond')\n",
    "                im_latent = axes[1].imshow(x[i].cpu()[0], cmap=\"gray\")\n",
    "                fig.colorbar(im_latent, fraction=0.046, pad=0.04)\n",
    "\n",
    "                axes[2].set_title('Prediction')\n",
    "                im_pred = axes[2].imshow(pred_img.cpu()[0], cmap=\"gray\")\n",
    "                fig.colorbar(im_pred, fraction=0.046, pad=0.04)\n",
    "\n",
    "                fig.savefig(os.path.join(self.out_root, f\"batch_{i_batch}-{i}.pdf\"))\n",
    "                plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1692391055505,
     "user": {
      "displayName": "Joseph Lupo",
      "userId": "18192058496751055649"
     },
     "user_tz": 240
    },
    "id": "T9jhxCYOndFo"
   },
   "outputs": [],
   "source": [
    "# # @title Datasets\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import PIL.Image as Image\n",
    "# from torch.utils import data\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# class HorseDataset(data.Dataset):\n",
    "\n",
    "#     def __init__(self, dir, size, n_c, portion=\"train\"):\n",
    "#         self.dir = dir\n",
    "#         self.names = self.read_names(dir, portion)\n",
    "#         self.n_c = n_c\n",
    "#         self.size = size\n",
    "\n",
    "#     def read_names(self, dir, portion):\n",
    "\n",
    "#         path = os.path.join(dir, \"{}.txt\".format(portion))\n",
    "#         names = list()\n",
    "#         with open(path, \"r\") as f:\n",
    "#             for line in f:\n",
    "#                 line = line.strip()\n",
    "#                 name = {}\n",
    "#                 name[\"img\"] = os.path.join(dir, os.path.join(\"images\", line))\n",
    "#                 name[\"lbl\"] = os.path.join(dir, os.path.join(\"labels\", line))\n",
    "#                 names.append(name)\n",
    "#         return names\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.names)\n",
    "\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "\n",
    "#         # path\n",
    "#         name = self.names[index]\n",
    "#         img_path = name[\"img\"]\n",
    "#         lbl_path = name[\"lbl\"]\n",
    "#         transform = transforms.Compose([transforms.Resize(self.size), transforms.ToTensor()])\n",
    "\n",
    "#         # img\n",
    "#         img = Image.open(img_path).convert(\"RGB\")\n",
    "#         img = transform(img)\n",
    "\n",
    "#         # lbl\n",
    "#         lbl = Image.open(lbl_path).convert(\"L\")\n",
    "#         lbl = transform(lbl)\n",
    "#         lbl = torch.round(lbl)\n",
    "#         if self.n_c > 1:\n",
    "#             lbl = lbl.repeat(self.n_c,1,1)\n",
    "\n",
    "#         return {\"x\":img, \"y\":lbl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1692391055506,
     "user": {
      "displayName": "Joseph Lupo",
      "userId": "18192058496751055649"
     },
     "user_tz": 240
    },
    "id": "FR8B9zdYndHt"
   },
   "outputs": [],
   "source": [
    "# @title TESS Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class TESSDataset(Dataset):\n",
    "    def __init__(self):\n",
    "\n",
    "        # self.data = []\n",
    "        # self.labels = []\n",
    "\n",
    "        # get data\n",
    "        angle_folder = \"/pdo/users/jlupoiii/TESS/data/angles/\"\n",
    "        ccd_folder = \"/pdo/users/jlupoiii/TESS/data/ccds/\"\n",
    "\n",
    "        # data matrices\n",
    "        X = []\n",
    "        Y = []\n",
    "        ffis = []\n",
    "\n",
    "        angles_dic = pickle.load(open(angle_folder+'angles_O13_data.pkl', \"rb\"))\n",
    "\n",
    "        for filename in os.listdir(ccd_folder):\n",
    "            if len(filename) < 40 or filename[27] != '3': continue\n",
    "\n",
    "            image_arr = pickle.load(open(ccd_folder+filename, \"rb\"))\n",
    "            ffi_num = filename[18:18+8]\n",
    "            try:\n",
    "                angles = angles_dic[ffi_num]\n",
    "                # print('Got ffi number', ffi_num)\n",
    "            except:\n",
    "                # print('Could not find ffi with number:', ffi_num)\n",
    "                continue\n",
    "            X.append(np.array([angles[10], angles[11], angles[18], angles[19], angles[22], angles[23], angles[24], angles[25]]))\n",
    "            Y.append(image_arr.flatten())\n",
    "            ffis.append(ffi_num)\n",
    "\n",
    "        # X = np.array(X)\n",
    "        # Y = np.array(Y)\n",
    "        # ffis = np.array(ffis)\n",
    "        # we are calculating Y GIVEN X\n",
    "        self.data = [Image.fromarray(x) for x in X]\n",
    "        self.labels = [Image.fromarray(y) for y in Y]\n",
    "        self.ffis = ffis\n",
    "\n",
    "        # for s in self.labels:\n",
    "        #     print(s.size)\n",
    "        #     # print(np.array(s).reshape((16,16))\n",
    "            \n",
    "        #     plt.imshow(np.array(s).reshape((16,16)))\n",
    "        #     plt.show()\n",
    "        #     plt.close()\n",
    "\n",
    "\n",
    "\n",
    "        # for class_idx, class_name in enumerate(self.classes):\n",
    "        #     # print(class_idx)\n",
    "        #     horse_img_path = os.path.join(self.root_dir, \"horse\", class_name)\n",
    "        #     mask_img_path = os.path.join(self.root_dir, \"mask\", class_name)\n",
    "\n",
    "        #     horse_image = Image.open(horse_img_path).convert('RGB')\n",
    "        #     mask_image = Image.open(mask_img_path).convert('L')\n",
    "\n",
    "        #     self.data.extend([horse_image])\n",
    "        #     self.labels.extend([mask_image])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # horse_img_path, mask_img_path = self.data[idx], self.labels[idx]\n",
    "        # label = self.labels[idx]\n",
    "        # horse_image = Image.open(horse_img_path).convert('RGB')\n",
    "        # mask_image = Image.open(mask_img_path).convert('L')\n",
    "\n",
    "        angles_image = self.data[idx]\n",
    "        ffi_image = self.labels[idx]\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            # transforms.Resize((1, 8)),\n",
    "            transforms.ToTensor(),\n",
    "            lambda s: s.reshape(1, 8),\n",
    "            # transforms.Normalize(mean=[0.456], std=[0.225])\n",
    "        ])\n",
    "        target_transform = transforms.Compose([\n",
    "            lambda s: np.array(s),\n",
    "            lambda s: s.reshape((16,16)),\n",
    "            # transforms.Resize((16, 16)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "        angles_image = transform(angles_image)\n",
    "        ffi_image = target_transform(ffi_image)\n",
    "        \n",
    "        # return x=angles, y=ffis\n",
    "        # we are calculating X GIVEN Y\n",
    "        return {\"x\":angles_image, \"y\":ffi_image}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6458,
     "status": "ok",
     "timestamp": 1692391061951,
     "user": {
      "displayName": "Joseph Lupo",
      "userId": "18192058496751055649"
     },
     "user_tz": 240
    },
    "id": "4S1ymwTMm1gO",
    "outputId": "60acbfb8-8096-4873-a1f1-0f1719f8514a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693\n",
      "torch.Size([1, 8])\n",
      "torch.Size([1, 16, 16])\n",
      "x tensor([1.0840e+02, 2.5450e+02, 8.2900e+01, 2.0540e+02, 1.7007e-02, 1.4184e-02,\n",
      "        2.8923e-04, 2.0120e-04])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we are calculating Y GIVEN X\n",
    "tess_dataset = TESSDataset()\n",
    "print(len(tess_dataset))\n",
    "print(tess_dataset[1]['x'].shape)\n",
    "print(tess_dataset[1]['y'].shape)\n",
    "\n",
    "# plt.plot(tess_dataset[1]['x'][0])\n",
    "print('x', tess_dataset[1]['x'][0])\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.imshow(tess_dataset[1]['y'][0])\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjh1WU3Mm1iF",
    "outputId": "46a92afc-dfbc-403e-9731-2b7708c7725c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of param: 36000212\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[ 0.0833,  0.0511, -0.0966,  0.0854, -0.0951,  0.1154,  0.0761,\n",
      "           0.1907]],\n",
      "\n",
      "        [[ 0.0927,  0.0640, -0.0865,  0.0767, -0.0817,  0.1158,  0.0698,\n",
      "           0.1931]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[-0.0684, -0.0107, -0.1357,  0.1188, -0.0016,  0.0454,  0.0373,\n",
      "          -0.0830]],\n",
      "\n",
      "        [[-0.0855,  0.0050, -0.1252,  0.0947, -0.0177,  0.0241,  0.0182,\n",
      "          -0.0566]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[ 0.0899,  0.1323,  0.0503, -0.0416, -0.1471, -0.1442,  0.0429,\n",
      "           0.0319]],\n",
      "\n",
      "        [[ 0.0740,  0.1103,  0.0445, -0.0579, -0.1468, -0.1803,  0.0293,\n",
      "           0.0313]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[ 0.0393,  0.1566, -0.0936,  0.0145,  0.1542,  0.0809, -0.0009,\n",
      "           0.0428]],\n",
      "\n",
      "        [[ 0.0518,  0.1735, -0.1063,  0.0308,  0.1432,  0.0854, -0.0009,\n",
      "           0.0400]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[-0.0925,  0.0543,  0.0989,  0.0842,  0.0453, -0.0427,  0.0414,\n",
      "          -0.0432]],\n",
      "\n",
      "        [[-0.1001,  0.0493,  0.1109,  0.0918,  0.0315, -0.0346,  0.0167,\n",
      "          -0.0277]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[ 0.0020,  0.1837, -0.0274, -0.0242, -0.1225,  0.0549, -0.0671,\n",
      "          -0.0482]],\n",
      "\n",
      "        [[-0.0074,  0.1526, -0.0119, -0.0304, -0.1176,  0.0655, -0.0677,\n",
      "          -0.0622]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[ 0.0283, -0.0878,  0.0330, -0.0254,  0.1143, -0.0417, -0.0249,\n",
      "           0.1229]],\n",
      "\n",
      "        [[ 0.0394, -0.1138,  0.0160, -0.0349,  0.1192, -0.0644, -0.0172,\n",
      "           0.1565]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[-0.1535, -0.1001, -0.1180, -0.0428, -0.1385, -0.0887,  0.1399,\n",
      "          -0.1407]],\n",
      "\n",
      "        [[-0.1621, -0.0889, -0.1149, -0.0412, -0.1327, -0.0821,  0.1254,\n",
      "          -0.1535]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[-0.1071, -0.0387,  0.0515, -0.0005, -0.1069, -0.0117,  0.0288,\n",
      "          -0.0635, -0.0198,  0.0391, -0.0881, -0.0679, -0.0200,  0.1376,\n",
      "          -0.1574,  0.0079]],\n",
      "\n",
      "        [[-0.0692, -0.0368,  0.0694,  0.0261, -0.0918, -0.0448,  0.0470,\n",
      "          -0.0723, -0.0075,  0.0658, -0.1011, -0.0770, -0.0273,  0.1193,\n",
      "          -0.1839,  0.0306]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[ 0.0053, -0.1307,  0.0886, -0.0773,  0.0075, -0.0707,  0.1581,\n",
      "           0.0772,  0.0378,  0.1255, -0.0407, -0.1789, -0.0292, -0.2341,\n",
      "           0.0872, -0.1151]],\n",
      "\n",
      "        [[-0.0060, -0.1280,  0.1112, -0.0673,  0.0215, -0.0829,  0.1588,\n",
      "           0.0823,  0.0586,  0.1116, -0.0699, -0.1615, -0.0152, -0.2136,\n",
      "           0.0799, -0.1110]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[-0.1511,  0.0887,  0.0959, -0.0661,  0.1206,  0.0930,  0.0220,\n",
      "           0.0384, -0.0154,  0.1399,  0.1401,  0.0538,  0.1889,  0.0813,\n",
      "          -0.0911,  0.1529]],\n",
      "\n",
      "        [[-0.1342,  0.0819,  0.0950, -0.0913,  0.1249,  0.0867,  0.0051,\n",
      "           0.0350, -0.0018,  0.1400,  0.1649,  0.0486,  0.1749,  0.0868,\n",
      "          -0.1048,  0.1659]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[-0.1469,  0.0538,  0.1186, -0.0799,  0.0245, -0.0326, -0.0420,\n",
      "           0.0859,  0.0283,  0.0479, -0.2174,  0.0888,  0.0264, -0.0538,\n",
      "           0.0511,  0.1862]],\n",
      "\n",
      "        [[-0.1352,  0.0668,  0.1214, -0.0836,  0.0358,  0.0010, -0.0410,\n",
      "           0.0824,  0.0252,  0.0425, -0.1953,  0.0942,  0.0285, -0.0474,\n",
      "           0.0462,  0.1780]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[ 0.0076,  0.0598,  0.0887,  0.0322,  0.0091,  0.0874, -0.0410,\n",
      "           0.0923,  0.0385, -0.0413, -0.0655, -0.0039, -0.0186, -0.0162,\n",
      "           0.0900,  0.2239]],\n",
      "\n",
      "        [[ 0.0136,  0.0718,  0.0911,  0.0217,  0.0277,  0.0629, -0.0440,\n",
      "           0.0930,  0.0572, -0.0562, -0.0484,  0.0118, -0.0145, -0.0005,\n",
      "           0.0702,  0.2198]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[-0.0535,  0.0082, -0.0804, -0.0229, -0.0327, -0.1473,  0.0103,\n",
      "          -0.1130, -0.0628, -0.0613, -0.0058, -0.0166, -0.1110, -0.0367,\n",
      "           0.0784, -0.0543]],\n",
      "\n",
      "        [[-0.0597,  0.0214, -0.0980, -0.0262, -0.0147, -0.1653,  0.0294,\n",
      "          -0.0966, -0.0587, -0.0495, -0.0036, -0.0184, -0.1072, -0.0018,\n",
      "           0.0717, -0.0496]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[ 0.0170, -0.2187,  0.0093, -0.0433,  0.0324,  0.0519, -0.0235,\n",
      "          -0.0207,  0.0931, -0.1564, -0.0308, -0.0040, -0.1565, -0.1016,\n",
      "          -0.0410,  0.1007]],\n",
      "\n",
      "        [[ 0.0127, -0.2011, -0.0022, -0.0548,  0.0244,  0.0619, -0.0278,\n",
      "          -0.0162,  0.1219, -0.1582, -0.0471, -0.0079, -0.1799, -0.0893,\n",
      "          -0.0535,  0.1154]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[ 0.1171,  0.0674,  0.0743, -0.0075, -0.0237, -0.0756, -0.1135,\n",
      "          -0.0550, -0.1899,  0.0401, -0.1148,  0.0027, -0.0552, -0.0679,\n",
      "           0.0591, -0.1383]],\n",
      "\n",
      "        [[ 0.1241,  0.0516,  0.0672, -0.0057, -0.0336, -0.0722, -0.1301,\n",
      "          -0.0428, -0.1829,  0.0463, -0.1109, -0.0135, -0.0587, -0.0668,\n",
      "           0.0611, -0.1335]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[-0.0049,  0.0190, -0.0597, -0.0878,  0.0779, -0.0679,  0.0400,\n",
      "           0.1653,  0.0096, -0.0228, -0.0031,  0.0822,  0.0661, -0.3144,\n",
      "           0.0146, -0.0097,  0.0056, -0.0328, -0.0390,  0.0114,  0.0548,\n",
      "           0.0634, -0.1019, -0.0156, -0.0567,  0.1602,  0.1299, -0.0117,\n",
      "           0.1345, -0.0766, -0.0405, -0.0295]],\n",
      "\n",
      "        [[-0.0172,  0.0274, -0.0508, -0.0966,  0.0770, -0.0685,  0.0595,\n",
      "           0.1687,  0.0116, -0.0295, -0.0006,  0.0819,  0.0614, -0.3209,\n",
      "           0.0054,  0.0068, -0.0057, -0.0470, -0.0340,  0.0062,  0.0375,\n",
      "           0.0647, -0.1040, -0.0040, -0.0495,  0.1710,  0.1349, -0.0086,\n",
      "           0.1354, -0.0811, -0.0532, -0.0355]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[ 0.0720, -0.0525,  0.0446,  0.0057, -0.0084, -0.1050,  0.2172,\n",
      "           0.0138,  0.0959, -0.0404,  0.0834, -0.0682, -0.0545,  0.0624,\n",
      "           0.1427,  0.0155,  0.0262, -0.1130, -0.0645, -0.0289,  0.0557,\n",
      "           0.1459, -0.0330, -0.0624, -0.0343, -0.1270, -0.0683, -0.0768,\n",
      "           0.0870, -0.1086,  0.2135, -0.0074]],\n",
      "\n",
      "        [[ 0.0798, -0.0267,  0.0695,  0.0086, -0.0056, -0.1035,  0.2288,\n",
      "           0.0021,  0.1101, -0.0459,  0.0784, -0.0668, -0.0608,  0.0722,\n",
      "           0.1397,  0.0251,  0.0170, -0.1154, -0.0752, -0.0234,  0.0489,\n",
      "           0.1636, -0.0299, -0.0563, -0.0610, -0.1407, -0.0819, -0.0889,\n",
      "           0.0783, -0.1053,  0.2002, -0.0343]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[-0.0454, -0.0103, -0.0163,  0.0920,  0.0014, -0.0216, -0.1450,\n",
      "           0.1365, -0.2340, -0.0068,  0.1974,  0.1485, -0.1049, -0.1323,\n",
      "          -0.0812, -0.1064, -0.1001, -0.0498, -0.0042, -0.1820,  0.1594,\n",
      "           0.0163,  0.0035,  0.0967, -0.0132, -0.1048, -0.0693,  0.0580,\n",
      "          -0.1420,  0.0281,  0.0558,  0.0701]],\n",
      "\n",
      "        [[-0.0676, -0.0076, -0.0235,  0.1099,  0.0071, -0.0326, -0.1332,\n",
      "           0.1286, -0.2358, -0.0044,  0.1841,  0.1300, -0.1158, -0.1360,\n",
      "          -0.0961, -0.1044, -0.0819, -0.0494,  0.0196, -0.1837,  0.1444,\n",
      "           0.0163, -0.0189,  0.0983, -0.0127, -0.0983, -0.0832,  0.0604,\n",
      "          -0.1273,  0.0231,  0.0442,  0.0846]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[-4.4908e-02, -1.4246e-02, -8.5513e-02,  8.1576e-02,  8.5293e-02,\n",
      "          -1.5030e-02, -3.6354e-02,  1.6425e-01, -6.0597e-02,  3.1618e-02,\n",
      "          -1.8307e-01,  4.3572e-02, -9.1721e-02,  8.5307e-02, -5.8707e-02,\n",
      "          -2.0247e-01,  9.6903e-02,  1.9121e-02,  4.3300e-02, -1.0128e-01,\n",
      "           2.0981e-01, -2.9611e-02,  1.0675e-01,  6.2077e-02,  2.0304e-02,\n",
      "           4.9688e-03,  3.2607e-02, -1.2877e-01, -1.1932e-01,  1.2305e-01,\n",
      "          -5.3535e-02,  7.9853e-02]],\n",
      "\n",
      "        [[-4.3888e-02,  1.8235e-02, -9.4586e-02,  9.8476e-02,  9.0423e-02,\n",
      "          -1.0751e-02, -1.5608e-03,  1.7061e-01, -7.9409e-02, -8.5026e-05,\n",
      "          -1.6105e-01,  3.2691e-02, -9.3615e-02,  9.5256e-02, -5.1438e-02,\n",
      "          -2.0228e-01,  7.7762e-02,  1.2397e-02,  6.6108e-02, -1.2203e-01,\n",
      "           1.9828e-01, -2.8002e-02,  1.2491e-01,  5.5882e-02,  3.2359e-02,\n",
      "           1.9334e-02,  3.9177e-02, -9.5449e-02, -1.2494e-01,  1.4526e-01,\n",
      "          -7.0355e-02,  9.0917e-02]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[ 0.0430, -0.0371,  0.0251,  0.0665,  0.0748,  0.0936,  0.1077,\n",
      "          -0.0953,  0.1272, -0.1193, -0.0360, -0.0389, -0.1508,  0.1714,\n",
      "          -0.0456, -0.0718, -0.0539, -0.0864, -0.0179,  0.0390, -0.1306,\n",
      "          -0.1625, -0.0254, -0.0508,  0.0821, -0.1057,  0.0998, -0.0630,\n",
      "          -0.0981, -0.0219, -0.0339, -0.1060]],\n",
      "\n",
      "        [[ 0.0608, -0.0134,  0.0253,  0.0566,  0.0818,  0.1008,  0.1016,\n",
      "          -0.1073,  0.1418, -0.0883, -0.0416, -0.0453, -0.1472,  0.1683,\n",
      "          -0.0387, -0.0705, -0.0529, -0.0657, -0.0048,  0.0405, -0.1343,\n",
      "          -0.1474, -0.0037, -0.0498,  0.0820, -0.1027,  0.1152, -0.0847,\n",
      "          -0.1030, -0.0291, -0.0439, -0.1097]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[ 0.0809, -0.1865,  0.0167, -0.0421, -0.0352,  0.0776,  0.1021,\n",
      "           0.0412, -0.1917,  0.0619, -0.1697,  0.0830, -0.1161,  0.1016,\n",
      "           0.0008, -0.1150, -0.0731,  0.0152,  0.0620,  0.0167, -0.1399,\n",
      "          -0.0253,  0.0352,  0.0640,  0.1307, -0.1922, -0.0774,  0.0808,\n",
      "           0.0336, -0.0111, -0.0355, -0.1363]],\n",
      "\n",
      "        [[ 0.0810, -0.1691,  0.0079, -0.0371, -0.0394,  0.0894,  0.1016,\n",
      "           0.0461, -0.2022,  0.0511, -0.1559,  0.0861, -0.1194,  0.1130,\n",
      "          -0.0121, -0.1303, -0.0721,  0.0273,  0.0659, -0.0037, -0.1408,\n",
      "          -0.0125,  0.0179,  0.0765,  0.1160, -0.1758, -0.0815,  0.0719,\n",
      "           0.0215,  0.0013, -0.0606, -0.1237]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[-0.0119, -0.0502,  0.0076,  0.0632,  0.0161, -0.0423,  0.0793,\n",
      "          -0.0643, -0.0186, -0.1278,  0.0038,  0.0457, -0.1053,  0.0151,\n",
      "          -0.0986, -0.0942, -0.0128,  0.0399, -0.1124, -0.0108,  0.0860,\n",
      "           0.0146,  0.0920,  0.0718,  0.0313,  0.0717, -0.0329, -0.0914,\n",
      "           0.1038,  0.1224, -0.1142,  0.0658]],\n",
      "\n",
      "        [[-0.0117, -0.0588,  0.0030,  0.0507, -0.0024, -0.0495,  0.0953,\n",
      "          -0.0683, -0.0027, -0.1148, -0.0033,  0.0517, -0.0980,  0.0101,\n",
      "          -0.1085, -0.1025, -0.0090,  0.0387, -0.1129, -0.0083,  0.0905,\n",
      "           0.0006,  0.0923,  0.0805,  0.0225,  0.0811, -0.0387, -0.0737,\n",
      "           0.0752,  0.1193, -0.1291,  0.0801]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.4500e+01, 1.8450e+02, 9.1400e+01, 1.1950e+02, 2.9762e-02,\n",
      "          1.5723e-02, 8.8577e-04, 2.4722e-04]],\n",
      "\n",
      "        [[1.0430e+02, 2.2030e+02, 8.8600e+01, 1.5870e+02, 2.0367e-02,\n",
      "          1.6234e-02, 4.1480e-04, 2.6354e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[ 9.9764e-02, -8.6541e-02, -1.6751e-01, -4.5134e-02,  3.0809e-02,\n",
      "          -1.1170e-01, -7.4302e-02,  6.9440e-02, -1.0004e-01, -8.5137e-03,\n",
      "          -1.7886e-01,  1.3094e-01, -1.4032e-04,  1.7432e-03, -1.7126e-01,\n",
      "          -1.6194e-01, -2.0047e-02, -1.7100e-02, -2.9557e-02, -4.2503e-02,\n",
      "           2.1159e-01, -9.9379e-03,  4.1470e-02, -7.6079e-02,  6.1635e-03,\n",
      "          -6.7480e-02,  2.2132e-03,  9.8447e-02, -1.0021e-01,  6.7270e-02,\n",
      "           1.4682e-01,  7.2025e-02]],\n",
      "\n",
      "        [[ 1.0718e-01, -7.7366e-02, -1.6266e-01, -3.8350e-02,  1.8217e-02,\n",
      "          -9.1168e-02, -7.1472e-02,  8.1999e-02, -1.1251e-01,  3.3082e-03,\n",
      "          -1.7916e-01,  1.1611e-01,  1.7725e-02,  7.3711e-03, -1.7066e-01,\n",
      "          -1.5272e-01, -2.1672e-02, -1.1110e-02, -4.5003e-02, -2.9212e-02,\n",
      "           2.1696e-01,  3.5771e-02,  4.8713e-02, -5.5467e-02, -1.1916e-02,\n",
      "          -5.4200e-02, -1.1748e-03,  9.7946e-02, -8.6364e-02,  7.2224e-02,\n",
      "           1.5837e-01,  7.4721e-02]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "Iteration: 0/277000 \t Elapsed time: 0.19 \t Loss:inf\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[ 0.2444,  0.2047,  0.0306,  0.0616, -0.0863,  0.1214,  0.0403,\n",
      "           0.0831]],\n",
      "\n",
      "        [[ 0.3131,  0.2893,  0.0344,  0.0652, -0.1489,  0.1610,  0.0168,\n",
      "           0.1704]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[ 0.0768,  0.0396, -0.0075,  0.2608, -0.0147,  0.0247,  0.0778,\n",
      "          -0.1454]],\n",
      "\n",
      "        [[ 0.1492,  0.2047,  0.0269,  0.3040, -0.0571,  0.0157,  0.0760,\n",
      "          -0.1101]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[ 0.1784,  0.2192,  0.1071,  0.0427, -0.1707, -0.1459,  0.0393,\n",
      "           0.0918]],\n",
      "\n",
      "        [[ 0.2096,  0.2541,  0.1744,  0.1773, -0.1499, -0.2069,  0.1078,\n",
      "           0.1057]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[ 0.0885,  0.3584,  0.0279,  0.1747,  0.2226,  0.1957, -0.0938,\n",
      "           0.1802]],\n",
      "\n",
      "        [[ 0.1817,  0.4065,  0.0755,  0.1992,  0.1634,  0.2353, -0.0672,\n",
      "           0.1916]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[ 0.0238,  0.1527,  0.2844,  0.1890, -0.0128,  0.0303, -0.0161,\n",
      "          -0.1301]],\n",
      "\n",
      "        [[ 0.0643,  0.1251,  0.3233,  0.2652, -0.0574,  0.0343,  0.0018,\n",
      "          -0.1475]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[ 0.1001,  0.2432,  0.0490,  0.0723, -0.0627,  0.1652, -0.0998,\n",
      "          -0.1324]],\n",
      "\n",
      "        [[ 0.1360,  0.3468,  0.0570,  0.1489, -0.0225,  0.1878, -0.1765,\n",
      "          -0.1410]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[ 0.1447,  0.0835,  0.1747,  0.1489,  0.1329,  0.0283, -0.0209,\n",
      "           0.1549]],\n",
      "\n",
      "        [[ 0.1694,  0.0561,  0.2915,  0.2179,  0.0928,  0.0703,  0.0140,\n",
      "           0.1873]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[-0.0157,  0.0697,  0.0601,  0.0373, -0.1173, -0.0246,  0.1218,\n",
      "          -0.2354]],\n",
      "\n",
      "        [[ 0.0177,  0.1800,  0.1231,  0.0720, -0.1010, -0.0107,  0.0421,\n",
      "          -0.2831]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[-0.0324,  0.0313,  0.1683,  0.0182, -0.0046, -0.0663,  0.1466,\n",
      "          -0.0274, -0.0011,  0.0380, -0.1394, -0.1029, -0.1002,  0.0981,\n",
      "          -0.1412,  0.0472]],\n",
      "\n",
      "        [[ 0.0629,  0.1176,  0.2789,  0.0465,  0.0823,  0.0224,  0.2019,\n",
      "           0.0016, -0.0732, -0.0378, -0.0927, -0.1696, -0.1390,  0.0678,\n",
      "          -0.2293,  0.0329]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[ 0.1546, -0.0075,  0.1626, -0.0631,  0.0843, -0.0069,  0.2029,\n",
      "           0.1956,  0.1082,  0.1233, -0.1268, -0.2474, -0.1245, -0.2115,\n",
      "           0.0920, -0.0663]],\n",
      "\n",
      "        [[ 0.2264,  0.0858,  0.1711,  0.0192,  0.1278,  0.0343,  0.2391,\n",
      "           0.2266,  0.1055,  0.1917, -0.1354, -0.2287, -0.0751, -0.2577,\n",
      "           0.0200, -0.1214]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[ 0.0082,  0.1533,  0.1382,  0.0287,  0.1261,  0.2435,  0.1777,\n",
      "           0.0663, -0.0538,  0.1286,  0.1165,  0.0391,  0.2061,  0.0031,\n",
      "          -0.0392,  0.1355]],\n",
      "\n",
      "        [[ 0.1129,  0.1404,  0.1517, -0.0402,  0.1729,  0.3200,  0.2273,\n",
      "           0.0434, -0.0634,  0.1478,  0.0390,  0.0431,  0.2083,  0.0033,\n",
      "          -0.2202,  0.1506]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[-0.1035,  0.1826,  0.1370, -0.0738,  0.1666,  0.0902,  0.0565,\n",
      "           0.1236, -0.0094,  0.0008, -0.2172,  0.0712,  0.0564, -0.0489,\n",
      "           0.0960,  0.1755]],\n",
      "\n",
      "        [[-0.0698,  0.2782,  0.1737, -0.0791,  0.1609,  0.1050,  0.1320,\n",
      "           0.1713, -0.0367, -0.0155, -0.1993,  0.0279,  0.0888,  0.0386,\n",
      "           0.0860,  0.2181]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[ 0.0947,  0.1721,  0.1663,  0.0468,  0.1959,  0.1573,  0.1027,\n",
      "           0.1877,  0.0487, -0.1058, -0.0624, -0.0357, -0.0030, -0.0611,\n",
      "           0.1118,  0.2522]],\n",
      "\n",
      "        [[ 0.1388,  0.2041,  0.2438,  0.0382,  0.2344,  0.1855,  0.1266,\n",
      "           0.2183,  0.0767, -0.0939,  0.0148,  0.0030,  0.0040,  0.0128,\n",
      "           0.1666,  0.3226]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[ 0.0089,  0.1275,  0.0238,  0.1101,  0.0039, -0.1144,  0.1921,\n",
      "           0.1040, -0.0373, -0.0310, -0.0166,  0.0487, -0.1512, -0.0163,\n",
      "          -0.0582, -0.0618]],\n",
      "\n",
      "        [[-0.0192,  0.0811,  0.0109,  0.0977,  0.0418, -0.0557,  0.2504,\n",
      "           0.1171,  0.0006, -0.0445,  0.0074,  0.0036, -0.1335, -0.0337,\n",
      "          -0.0513, -0.0941]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[ 0.0412, -0.1260,  0.1368,  0.0509,  0.2439,  0.0753,  0.0327,\n",
      "           0.1020,  0.1171, -0.0825, -0.1075, -0.0306, -0.0486, -0.0009,\n",
      "           0.0412,  0.0812]],\n",
      "\n",
      "        [[ 0.0696, -0.0417,  0.1092,  0.0903,  0.2167,  0.1123,  0.0517,\n",
      "           0.1121,  0.1274, -0.0909, -0.1163, -0.0250, -0.1060,  0.0345,\n",
      "          -0.0050,  0.0940]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[ 0.2410,  0.2481,  0.1817, -0.0062,  0.0848,  0.0966, -0.0555,\n",
      "           0.1664, -0.1966, -0.0139, -0.0396,  0.0014, -0.0268, -0.1112,\n",
      "           0.0454, -0.0145]],\n",
      "\n",
      "        [[ 0.3255,  0.3502,  0.2281,  0.1262,  0.0960,  0.1033, -0.0274,\n",
      "           0.2262, -0.2840, -0.0674, -0.0133,  0.0723, -0.0365, -0.1424,\n",
      "           0.0551, -0.0507]]], device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[ 0.0200,  0.0724,  0.0138, -0.0436,  0.1407, -0.0482,  0.2282,\n",
      "           0.1936,  0.0249,  0.0476, -0.0404,  0.1569,  0.0610, -0.1852,\n",
      "           0.0621,  0.0416,  0.0470, -0.0702,  0.0757,  0.0140,  0.0715,\n",
      "          -0.0036, -0.0402, -0.0749, -0.1218,  0.1320,  0.0939,  0.1076,\n",
      "           0.1699, -0.0617, -0.0934, -0.0267]],\n",
      "\n",
      "        [[ 0.0645,  0.1347,  0.0885, -0.0443,  0.1241,  0.0023,  0.2567,\n",
      "           0.1705,  0.0911,  0.0538,  0.0215,  0.1445,  0.0692, -0.1787,\n",
      "           0.0840,  0.1193,  0.0481, -0.0855,  0.0836,  0.0236,  0.0058,\n",
      "           0.0358, -0.0510, -0.0609, -0.0492,  0.1843,  0.1141, -0.0010,\n",
      "           0.1048, -0.1001, -0.1015, -0.0345]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[ 0.2332,  0.0610,  0.1626,  0.1123,  0.1135,  0.0806,  0.2340,\n",
      "           0.0860,  0.1957, -0.0388,  0.1439,  0.1177, -0.0090, -0.0727,\n",
      "           0.1119,  0.1540,  0.0568, -0.1636,  0.0237, -0.1583,  0.0318,\n",
      "           0.2385, -0.0158, -0.0987, -0.1734, -0.2107, -0.0430, -0.0484,\n",
      "           0.1026, -0.2035,  0.1411, -0.0588]],\n",
      "\n",
      "        [[ 0.2925,  0.1711,  0.3184,  0.1073,  0.1969,  0.1090,  0.3107,\n",
      "          -0.0199,  0.2876, -0.0528,  0.1661,  0.0948,  0.0044,  0.0221,\n",
      "           0.0472,  0.1612,  0.0332, -0.1381, -0.0355, -0.2139, -0.0262,\n",
      "           0.3239,  0.0087, -0.0983, -0.2091, -0.2538, -0.0049, -0.0730,\n",
      "           0.1598, -0.1888,  0.2056, -0.0822]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[-0.0012,  0.1065, -0.0788,  0.0690,  0.1204,  0.0862, -0.1304,\n",
      "           0.1563, -0.0480,  0.0249,  0.2254,  0.1902, -0.0383, -0.0165,\n",
      "          -0.0742, -0.0726, -0.1793, -0.0388,  0.0797, -0.0924,  0.1540,\n",
      "          -0.0401,  0.0288,  0.0833,  0.1058, -0.1776, -0.1109,  0.0309,\n",
      "          -0.0468,  0.0879, -0.0154,  0.1433]],\n",
      "\n",
      "        [[ 0.0805,  0.1735, -0.0578,  0.0913,  0.1115,  0.1245, -0.0914,\n",
      "           0.1516, -0.0547,  0.0984,  0.2852,  0.1871, -0.0215,  0.0173,\n",
      "          -0.0390,  0.0302, -0.1963, -0.0343, -0.0119, -0.0716,  0.2127,\n",
      "          -0.0824, -0.0080,  0.1001,  0.1284, -0.2432, -0.0670,  0.0876,\n",
      "          -0.0417,  0.0404, -0.0237,  0.1048]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[-0.0223,  0.1456, -0.0190,  0.1759,  0.1578,  0.0969,  0.1227,\n",
      "           0.2157, -0.0320,  0.0248, -0.0144,  0.1080, -0.0165,  0.1484,\n",
      "          -0.0665, -0.0792,  0.1215, -0.1016,  0.0322, -0.1143,  0.0953,\n",
      "          -0.0373,  0.2103,  0.0512, -0.0243,  0.0447,  0.1204, -0.1500,\n",
      "          -0.1396,  0.0500, -0.0137,  0.0068]],\n",
      "\n",
      "        [[-0.0726,  0.2011,  0.0468,  0.1999,  0.1791,  0.1186,  0.1403,\n",
      "           0.3029, -0.0893,  0.0933,  0.0023,  0.0979,  0.0848,  0.1479,\n",
      "          -0.0282, -0.0651,  0.0473, -0.0688,  0.0550, -0.1602,  0.1257,\n",
      "          -0.0537,  0.2133,  0.0917, -0.0041,  0.0734,  0.1149, -0.1199,\n",
      "          -0.1411,  0.0416, -0.0683,  0.0166]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[ 0.1323, -0.0425,  0.0127,  0.0822,  0.0975,  0.1899,  0.2043,\n",
      "          -0.1054,  0.1189,  0.0913,  0.0521,  0.1261, -0.1472,  0.2190,\n",
      "           0.0903,  0.0390, -0.0351, -0.1305,  0.0443,  0.0886, -0.2076,\n",
      "          -0.0136,  0.0343,  0.0346,  0.1352, -0.1158,  0.1058, -0.1413,\n",
      "          -0.1545, -0.1600, -0.1124, -0.1996]],\n",
      "\n",
      "        [[ 0.1233,  0.0069,  0.0181,  0.1281,  0.0634,  0.2439,  0.2182,\n",
      "          -0.0659,  0.1481,  0.1460,  0.0907,  0.1081, -0.1186,  0.2764,\n",
      "           0.1114,  0.0309, -0.0200, -0.0733,  0.0050,  0.1065, -0.1650,\n",
      "          -0.0358,  0.0281, -0.0297,  0.1217, -0.1254,  0.1711, -0.1211,\n",
      "          -0.1279, -0.1462, -0.0762, -0.2107]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[ 0.1696,  0.0031, -0.0236, -0.0075,  0.0277,  0.1270,  0.2106,\n",
      "           0.0872, -0.2196,  0.1831, -0.0750,  0.1375,  0.0192,  0.1553,\n",
      "           0.0430, -0.1638, -0.0280, -0.0056,  0.0415, -0.1330, -0.2736,\n",
      "           0.0020,  0.0442,  0.0687,  0.0587, -0.2276,  0.0500,  0.1139,\n",
      "          -0.0480, -0.0708, -0.0823, -0.1651]],\n",
      "\n",
      "        [[ 0.1969,  0.0251,  0.0019,  0.0360,  0.0840,  0.2048,  0.2138,\n",
      "           0.0986, -0.1856,  0.2203, -0.0793,  0.1141,  0.0624,  0.1488,\n",
      "           0.0331, -0.0505, -0.0674, -0.0314,  0.0479, -0.1166, -0.2204,\n",
      "           0.0194,  0.0449,  0.0614,  0.0115, -0.1931,  0.0423,  0.0803,\n",
      "          -0.0655, -0.0747, -0.1717, -0.1348]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[ 0.0451, -0.0093,  0.1057,  0.1181,  0.1197, -0.0493,  0.1049,\n",
      "          -0.0156,  0.0182, -0.0668,  0.0667,  0.0855, -0.0767,  0.0916,\n",
      "          -0.0642,  0.0419, -0.0283,  0.0078, -0.1754,  0.0487,  0.0718,\n",
      "          -0.0145,  0.0631, -0.0066, -0.0510,  0.0044, -0.0559, -0.1284,\n",
      "           0.0948, -0.0047, -0.0885,  0.0458]],\n",
      "\n",
      "        [[ 0.0203,  0.0403,  0.1097,  0.0670,  0.2049,  0.0149,  0.1197,\n",
      "          -0.0458,  0.1430, -0.0219,  0.0609,  0.0847,  0.0224,  0.0709,\n",
      "          -0.0571,  0.0568, -0.0553,  0.0334, -0.1786, -0.0310,  0.0990,\n",
      "          -0.0102,  0.0337,  0.0598, -0.0898,  0.0035, -0.1100, -0.0780,\n",
      "           0.0613,  0.0368, -0.1285,  0.1277]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.4300e+01, 4.7300e+01, 9.6100e+01, 5.7200e+01, 5.1282e-02,\n",
      "          1.3387e-02, 2.6298e-03, 1.7921e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.5960e+02, 8.2200e+01, 2.1180e+02, 1.7036e-02,\n",
      "          1.3850e-02, 2.9022e-04, 1.9183e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[ 0.1275,  0.0065, -0.0738,  0.0370,  0.1120, -0.0055, -0.0183,\n",
      "           0.1896, -0.0504,  0.1312, -0.1310,  0.1981,  0.0881,  0.0382,\n",
      "          -0.0986, -0.1796, -0.0009, -0.0110, -0.0337, -0.1123,  0.1531,\n",
      "           0.0674, -0.0220, -0.0583,  0.0234, -0.0619,  0.0278,  0.1246,\n",
      "          -0.1437, -0.0250,  0.1861,  0.0611]],\n",
      "\n",
      "        [[ 0.1167,  0.0141, -0.0462,  0.0135,  0.0658,  0.0892,  0.0019,\n",
      "           0.2401,  0.0064,  0.2185, -0.0863,  0.1699,  0.1441,  0.0597,\n",
      "          -0.0613, -0.1402, -0.0764,  0.0131, -0.0590, -0.0922,  0.1432,\n",
      "           0.1078,  0.0053, -0.0805,  0.0624, -0.0847, -0.0187,  0.1259,\n",
      "          -0.1772,  0.0042,  0.2758,  0.0449]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "Iteration: 1/277000 \t Elapsed time: 0.53 \t Loss:nan\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.2200e+01, 9.5900e+01, 7.2000e+01, 2.3950e+02, 5.4348e-02,\n",
      "          1.9960e-02, 2.9537e-03, 3.9840e-04]],\n",
      "\n",
      "        [[1.0850e+02, 2.6460e+02, 8.1700e+01, 2.1760e+02, 1.7212e-02,\n",
      "          1.3587e-02, 2.9624e-04, 1.8461e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "Iteration: 2/277000 \t Elapsed time: 0.71 \t Loss:nan\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9200e+01, 1.9960e+02, 9.0800e+01, 1.3380e+02, 2.5189e-02,\n",
      "          1.6181e-02, 6.3448e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0690e+02, 2.3530e+02, 8.6100e+01, 1.7920e+02, 1.8149e-02,\n",
      "          1.5552e-02, 3.2938e-04, 2.4187e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "Iteration: 3/277000 \t Elapsed time: 0.91 \t Loss:nan\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.7700e+01, 3.0700e+01, 6.8700e+01, 2.5440e+02, 5.0251e-02,\n",
      "          2.0161e-02, 2.5252e-03, 4.0648e-04]],\n",
      "\n",
      "        [[8.7200e+01, 3.5840e+02, 7.1300e+01, 2.5970e+02, 4.0816e-02,\n",
      "          1.8149e-02, 1.6660e-03, 3.2938e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "Iteration: 4/277000 \t Elapsed time: 1.09 \t Loss:nan\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0590e+02, 2.2910e+02, 8.7200e+01, 1.7060e+02, 1.8939e-02,\n",
      "          1.5898e-02, 3.5870e-04, 2.5275e-04]],\n",
      "\n",
      "        [[7.1500e+01, 8.3100e+01, 7.0500e+01, 2.4200e+02, 5.5556e-02,\n",
      "          2.0450e-02, 3.0864e-03, 4.1820e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "Iteration: 5/277000 \t Elapsed time: 1.27 \t Loss:nan\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[8.6100e+01, 1.7000e+00, 7.0900e+01, 2.5940e+02, 4.1841e-02,\n",
      "          1.8382e-02, 1.7507e-03, 3.3791e-04]],\n",
      "\n",
      "        [[1.0740e+02, 2.3930e+02, 8.5300e+01, 1.8490e+02, 1.7762e-02,\n",
      "          1.5267e-02, 3.1549e-04, 2.3309e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "Iteration: 6/277000 \t Elapsed time: 1.50 \t Loss:nan\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0650e+02, 2.3290e+02, 8.6500e+01, 1.7600e+02, 1.8416e-02,\n",
      "          1.5699e-02, 3.3916e-04, 2.4645e-04]],\n",
      "\n",
      "        [[7.1600e+01, 7.0700e+01, 9.4400e+01, 6.5500e+01, 5.3476e-02,\n",
      "          1.3495e-02, 2.8597e-03, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "Iteration: 7/277000 \t Elapsed time: 1.68 \t Loss:nan\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.2500e+01, 1.7840e+02, 9.1500e+01, 1.1450e+02, 3.1746e-02,\n",
      "          1.5528e-02, 1.0078e-03, 2.4112e-04]],\n",
      "\n",
      "        [[1.0670e+02, 2.8630e+02, 7.9800e+01, 2.3850e+02, 1.9455e-02,\n",
      "          1.3228e-02, 3.7851e-04, 1.7497e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "Iteration: 8/277000 \t Elapsed time: 1.85 \t Loss:nan\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[7.1800e+01, 9.5200e+01, 9.3200e+01, 7.3800e+01, 5.2910e-02,\n",
      "          1.3680e-02, 2.7995e-03, 1.8714e-04]],\n",
      "\n",
      "        [[1.0730e+02, 2.3870e+02, 8.5500e+01, 1.8400e+02, 1.7825e-02,\n",
      "          1.5314e-02, 3.1774e-04, 2.3452e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "Iteration: 9/277000 \t Elapsed time: 2.03 \t Loss:nan\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.9300e+01, 2.0000e+02, 9.0800e+01, 1.3430e+02, 2.5063e-02,\n",
      "          1.6181e-02, 6.2814e-04, 2.6183e-04]],\n",
      "\n",
      "        [[1.0580e+02, 2.9260e+02, 7.9300e+01, 2.4310e+02, 2.0534e-02,\n",
      "          1.3369e-02, 4.2164e-04, 1.7873e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "Iteration: 10/277000 \t Elapsed time: 2.20 \t Loss:nan\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0850e+02, 2.6350e+02, 8.1800e+01, 2.1640e+02, 1.7153e-02,\n",
      "          1.3643e-02, 2.9421e-04, 1.8612e-04]],\n",
      "\n",
      "        [[1.0540e+02, 2.9470e+02, 7.9100e+01, 2.4450e+02, 2.0964e-02,\n",
      "          1.3423e-02, 4.3950e-04, 1.8017e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "Iteration: 11/277000 \t Elapsed time: 2.38 \t Loss:nan\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.0100e+01, 1.7150e+02, 9.1600e+01, 1.0940e+02, 3.4130e-02,\n",
      "          1.5291e-02, 1.1648e-03, 2.3380e-04]],\n",
      "\n",
      "        [[9.3400e+01, 3.3980e+02, 7.3700e+01, 2.5990e+02, 3.4130e-02,\n",
      "          1.6556e-02, 1.1648e-03, 2.7411e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "Iteration: 12/277000 \t Elapsed time: 2.56 \t Loss:nan\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[9.3900e+01, 3.3840e+02, 7.3900e+01, 2.5970e+02, 3.3670e-02,\n",
      "          1.6420e-02, 1.1337e-03, 2.6963e-04]],\n",
      "\n",
      "        [[1.0810e+02, 2.4810e+02, 8.3800e+01, 1.9700e+02, 1.7182e-02,\n",
      "          1.4641e-02, 2.9523e-04, 2.1437e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "Iteration: 13/277000 \t Elapsed time: 2.73 \t Loss:nan\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0030e+02, 2.0360e+02, 9.0500e+01, 1.3820e+02, 2.4096e-02,\n",
      "          1.6260e-02, 5.8064e-04, 2.6439e-04]],\n",
      "\n",
      "        [[7.5000e+01, 4.3700e+01, 9.6400e+01, 5.5900e+01, 5.0761e-02,\n",
      "          1.3387e-02, 2.5767e-03, 1.7921e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "Iteration: 14/277000 \t Elapsed time: 2.92 \t Loss:nan\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 8]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 16]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "xbefore torch.Size([2, 1, 8]) tensor([[[1.0770e+02, 2.7820e+02, 8.0500e+01, 2.3160e+02, 1.8315e-02,\n",
      "          1.3210e-02, 3.3544e-04, 1.7451e-04]],\n",
      "\n",
      "        [[1.0840e+02, 2.6670e+02, 8.1500e+01, 2.1990e+02, 1.7301e-02,\n",
      "          1.3495e-02, 2.9933e-04, 1.8212e-04]]], device='cuda:0')\n",
      "xafter torch.Size([2, 1, 32]) tensor([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "          nan, nan, nan, nan, nan, nan, nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 116\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39m# begin to train\u001b[39;00m\n\u001b[1;32m    115\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model, optim, scheduler, training_set, valid_set, args, cuda)\n\u001b[0;32m--> 116\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "Cell \u001b[0;32mIn[7], line 173\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    172\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> 173\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    175\u001b[0m \u001b[39m# operate grad\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_grad_clip \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# @title Train\n",
    "import argparse\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "# import Learner\n",
    "# import datasets\n",
    "# import utils\n",
    "# from CGlowModel import CondGlowModel\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='train c-Glow')\n",
    "\n",
    "    # input output path\n",
    "    parser.add_argument(\"-d\", \"--dataset_name\", type=str, default=\"horse\")\n",
    "    parser.add_argument(\"-r\", \"--dataset_root\", type=str, default=\"weizmann_horse_db\")\n",
    "\n",
    "    # log root\n",
    "    parser.add_argument(\"--log_root\", type=str, default=\"\")\n",
    "\n",
    "    # C-Glow parameters\n",
    "    # we are calculating Y GIVEN X\n",
    "    parser.add_argument(\"--x_size\", type=tuple, default=(1,8))\n",
    "    parser.add_argument(\"--y_size\", type=tuple, default=(1,16,16))\n",
    "    parser.add_argument(\"--x_hidden_channels\", type=int, default=128)\n",
    "    parser.add_argument(\"--x_hidden_size\", type=int, default=64)\n",
    "    parser.add_argument(\"--y_hidden_channels\", type=int, default=256)\n",
    "    parser.add_argument(\"-K\", \"--depth_flow\", type=int, default=8)\n",
    "    parser.add_argument(\"-L\", \"--num_levels\", type=int, default=3)\n",
    "    parser.add_argument(\"--learn_top\", type=bool, default=False)\n",
    "\n",
    "    # Dataset preprocess parameters\n",
    "    parser.add_argument(\"--label_scale\", type=float, default=1)\n",
    "    parser.add_argument(\"--label_bias\", type=float, default=0.5)\n",
    "    parser.add_argument(\"--x_bins\", type=float, default=256.0)\n",
    "    parser.add_argument(\"--y_bins\", type=float, default=2.0)\n",
    "\n",
    "\n",
    "    # Optimizer parameters\n",
    "    parser.add_argument(\"--optimizer\", type=str, default=\"adam\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.0002)\n",
    "    parser.add_argument(\"--betas\", type=tuple, default=(0.9,0.9999))\n",
    "    parser.add_argument(\"--eps\", type=float, default=1e-8)\n",
    "    parser.add_argument(\"--regularizer\", type=float, default=0.0)\n",
    "    parser.add_argument(\"--num_steps\", type=int, default=0)\n",
    "\n",
    "    # Trainer parameters\n",
    "    parser.add_argument(\"--num_epochs\", type=int, default=1000)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=2)\n",
    "    parser.add_argument(\"--max_grad_clip\", type=float, default=5)\n",
    "    parser.add_argument(\"--max_grad_norm\", type=float, default=0)\n",
    "    parser.add_argument(\"--checkpoints_gap\", type=int, default=1000)\n",
    "    parser.add_argument(\"--nll_gap\", type=int, default=1)\n",
    "    parser.add_argument(\"--inference_gap\", type=int, default=1000)\n",
    "    parser.add_argument(\"--save_gap\", type=int, default=1000)\n",
    "\n",
    "    # model path\n",
    "    parser.add_argument(\"--model_path\", type=str, default=\"\")#\"/pdo/users/jlupoiii/TESS/model_conditional_norm_flow/log_20230821_2340/checkpoints/checkpoint_4000.pth.tar\") # \"/pdo/users/jlupoiii/TESS/model_conditional_norm_flow/log_20230821_2340/checkpoints/checkpoint_4000.pth.tar\"\n",
    "\n",
    "    # args = parser.parse_args()\n",
    "    args = parser.parse_known_args()[0]\n",
    "    cuda = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "    # # HORSE DATASET\n",
    "    # dataset_root = 'weizmann_horse_db/'\n",
    "    # # Define any image transformations you want to apply (resize, normalization, etc.)\n",
    "    # transform = transforms.Compose([\n",
    "    #     transforms.Resize((64, 64)),\n",
    "    #     transforms.ToTensor(),\n",
    "    #     # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    # ])\n",
    "    # target_transform = transforms.Compose([\n",
    "    #     transforms.Resize((64, 64)),\n",
    "    #     transforms.ToTensor(),\n",
    "    #     # transforms.Normalize(mean=[0.456], std=[0.225])\n",
    "    # ])\n",
    "    # # Create the dataset\n",
    "    # training_set = WeizmannHorseDataset(root_dir=dataset_root, transform=transform, target_transform=target_transform)\n",
    "    # valid_set = WeizmannHorseDataset(root_dir=dataset_root, transform=transform, target_transform=target_transform)\n",
    "\n",
    "    # create TESS dataset\n",
    "    torch.manual_seed(42)\n",
    "    full_dataset = TESSDataset()\n",
    "    train_ratio = 0.8\n",
    "    num_train_samples = int(train_ratio * len(full_dataset))\n",
    "    num_valid_samples = len(full_dataset) - num_train_samples\n",
    "    training_set, valid_set = random_split(full_dataset, [num_train_samples, num_valid_samples])\n",
    "\n",
    "    model = CondGlowModel(args)\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    # from utils import count_parameters\n",
    "    print(\"number of param: {}\".format(count_parameters(model)))\n",
    "\n",
    "    # optimizer\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=args.lr,betas=args.betas, weight_decay=args.regularizer)\n",
    "\n",
    "    # scheduler\n",
    "    scheduler = None\n",
    "\n",
    "    if args.model_path != \"\":\n",
    "        state = load_state(args.model_path, cuda)\n",
    "        optim.load_state_dict(state[\"optim\"])\n",
    "        model.load_state_dict(state[\"model\"])\n",
    "        args.steps = state[\"iteration\"] + 1\n",
    "        if scheduler is not None and state.get(\"scheduler\", None) is not None:\n",
    "            scheduler.load_state_dict(state[\"scheduler\"])\n",
    "        del state\n",
    "        print('Realoaded model stored at', args.model_path, 'starting at step', args.steps)\n",
    "\n",
    "    # begin to train\n",
    "    trainer = Trainer(model, optim, scheduler, training_set, valid_set, args, cuda)\n",
    "    trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-pMvfdKknvWb"
   },
   "outputs": [],
   "source": [
    "# plt.imshow(y_sample.cpu()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0vt1suwnvYt"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "# import Learner\n",
    "# import datasets\n",
    "# import utils\n",
    "# from CGlowModel import CondGlowModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='predict c-Glow')\n",
    "\n",
    "    # model parameters\n",
    "    # parser.add_argument(\"--x_size\", type=tuple, default=(3,64,64))\n",
    "    # parser.add_argument(\"--y_size\", type=tuple, default=(1,64,64))\n",
    "    parser.add_argument(\"--x_size\", type=tuple, default=(1,8,8))\n",
    "    parser.add_argument(\"--y_size\", type=tuple, default=(1,16,16))\n",
    "    parser.add_argument(\"--x_hidden_channels\", type=int, default=128)\n",
    "    parser.add_argument(\"--x_hidden_size\", type=int, default=64)\n",
    "    parser.add_argument(\"--y_hidden_channels\", type=int, default=256)\n",
    "    parser.add_argument(\"-K\", \"--depth_flow\", type=int, default=8)\n",
    "    parser.add_argument(\"-L\", \"--num_levels\", type=int, default=3)\n",
    "    parser.add_argument(\"--learn_top\", type=bool, default=False)\n",
    "\n",
    "    # dataset\n",
    "    parser.add_argument(\"-d\", \"--dataset_name\", type=str, default=\"horse\")\n",
    "    parser.add_argument(\"-r\", \"--dataset_root\", type=str, default=\"\")\n",
    "    parser.add_argument(\"--label_scale\", type=float, default=1)\n",
    "    parser.add_argument(\"--label_bias\", type=float, default=0.5)\n",
    "    parser.add_argument(\"--num_labels\", type=int, default=2)\n",
    "    parser.add_argument(\"--x_bins\", type=float, default=256.0)\n",
    "    parser.add_argument(\"--y_bins\", type=float, default=2.0)\n",
    "\n",
    "    # output\n",
    "    parser.add_argument(\"-o\", \"--out_root\", type=str, default=\"out_dir\")\n",
    "\n",
    "    # model path\n",
    "    parser.add_argument(\"--model_path\", type=str, default=\"/content/gdrive/MyDrive/Projects/TESS/model_conditional_norm_flow_horses/log_20230818_1734/checkpoints/checkpoint_16000.pth.tar\")\n",
    "\n",
    "    # predictor parameters\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=10)\n",
    "    parser.add_argument(\"--num_samples\", type=int, default=10)\n",
    "\n",
    "\n",
    "    # args = parser.parse_args()\n",
    "    args = parser.parse_known_args()[0]\n",
    "    cuda = torch.cuda.is_available()\n",
    "\n",
    "    # dataset\n",
    "    dataset_root = 'weizmann_horse_db/'\n",
    "    # Define any image transformations you want to apply (resize, normalization, etc.)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    target_transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=[0.456], std=[0.225])\n",
    "    ])\n",
    "    # Create the dataset\n",
    "    training_set = WeizmannHorseDataset(root_dir=dataset_root, transform=transform, target_transform=target_transform)\n",
    "    valid_set = WeizmannHorseDataset(root_dir=dataset_root, transform=transform, target_transform=target_transform)\n",
    "    # dataset = HorseDataset(args.dataset_root, (args.y_size[1], args.y_size[2]), args.y_size[0], \"test\")\n",
    "\n",
    "    # model\n",
    "    model = CondGlowModel(args)\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "    state = load_state(args.model_path, cuda)\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    del state\n",
    "\n",
    "    # predictor\n",
    "    predictor = Inferencer(model, valid_set, args, cuda)\n",
    "\n",
    "    # predict\n",
    "    predictor.sampled_based_prediction(args.num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ofzNuC1nvaz"
   },
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "\n",
    "plt.imshow(z_sample.cpu()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwboe9J-nvdO"
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# print(torch.cuda.memory_summary(device=None, abbreviated=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wShbU0K7nvgH"
   },
   "outputs": [],
   "source": [
    "trainingset_loader = DataLoader(training_set, batch_size=2, shuffle=True, drop_last=True)\n",
    "out = next(iter(trainingset_loader))\n",
    "print(out['x'].shape)\n",
    "print(out['y'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8sZuxZDoLcj"
   },
   "outputs": [],
   "source": [
    "out['y'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKoex5akoLe7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMbQ56iI/lZFYZCaH1MfPGD",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
